[
  {
    "objectID": "index.html#опис-навчальної-дисципліни",
    "href": "index.html#опис-навчальної-дисципліни",
    "title": "Основи роботи з даними в R",
    "section": "Опис навчальної дисципліни",
    "text": "Опис навчальної дисципліни\nНавчальна дисципліна спрямована на вивчення основ практичного застосування популярної мови R для проведення статистичних досліджень в економіці.\nУ процесі вивчення курсу розглядаються теми, що стосуються теоретичних основ та практичної реалізації алгоритмів, завантаження, підготовки та обробки економічних даних.\nМісце навчальної дисципліни у підготовці здобувачів: програмні результати дисципліни використовуються під час вивчення таких навчальних дисциплін: “Алгоритми та структури даних”, “Аналіз даних в R”, “Прикладне математичне моделювання в R”, “Підготовка аналітичних звітів”. Закріплення на практиці здобутих програмних результатів відбувається під час проходження навчальної практики з курсу “Економіко-математичне моделювання”."
  },
  {
    "objectID": "index.html#мета-дисципліни",
    "href": "index.html#мета-дисципліни",
    "title": "Основи роботи з даними в R",
    "section": "Мета дисципліни",
    "text": "Мета дисципліни\nМета навчальної дисципліни – формування у студентів теоретичних знань та практичних навичок використання мови програмування R для роботи з даними та базовими структурами мови (типи даних, розгалуження, цикли, функції)."
  },
  {
    "objectID": "index.html#підтримка-проєкту",
    "href": "index.html#підтримка-проєкту",
    "title": "Основи роботи з даними в R",
    "section": "Підтримка проєкту",
    "text": "Підтримка проєкту\nМатеріали навчального посібника створено у межах проєкту “Підготовка, обробка та ефективне використання даних для наукових досліджень (на основі R)”, що підтримується Європейським союзою за програмою House of Europe."
  },
  {
    "objectID": "index.html#дотримання-принципів-доброчесності",
    "href": "index.html#дотримання-принципів-доброчесності",
    "title": "Основи роботи з даними в R",
    "section": "Дотримання принципів доброчесності",
    "text": "Дотримання принципів доброчесності\nВикладач та слухач цього курсу, як очікується, повинні дотримуватися Кодексу академічної доброчесності університету:\n\nбудь-яка робота, подана здобувачем протягом курсу, має бути його власною роботою здобувача; не вдаватися до кроків, що можуть нечесно покращити Ваші результати чи погіршити/покращити результати інших здобувачів;\nякщо буде виявлено ознаки плагіату або іншої недобросовісної академічної поведінки, то студент буде позбавлений можливості отримати передбачені бали за завдання;\nне публікувати у відкритому доступі відповіді на запитання, що використовуються в рамках курсу для оцінювання знань здобувачів;\nпід час фінальних видів контролю необхідно працювати самостійно; не дозволяється говорити або обговорювати, а також не можна копіювати документи, використовувати електронні засоби отримання інформації.\n\nПорушення академічної доброчесності під час виконання контрольних завдань призведе до втрати балів або вживання заходів, які передбачені Кодексу академічної доброчесності НаУОА.\n\n\n\n\n\n\n\nМатеріали курсу створені з використанням ряду технологій та середовищ розробки:\n\nМова R - безкоштована мова програмування для виконання досліджень у сфері статистики, машинного навчання та візуалізацї результатів.\nQuarto Book - система для публікації наукових та технічних текстів з відкритим кодом (R/Python/Julia/Observable).\nJupyterLab - середовище розробки на основі Jupyter Notebook. JupyterLab є розширеним веб-інтерфейсом для роботи з ноутбуками.\nGit/Github - система контролю версій та, відповідно, сервіс для організації зберігання коду, а також публікації статичних сторінок.\nRStudio Desktop - інтегроване середовище розробки (IDE) для мови R з відкритим кодом, що містить в собі редактор коду, консоль, планер, засоби візуалізації та можливості.\nVisual Studio Code - інтегроване середовище розробки (IDE) з відкритим кодом практично для усіх відомих технологій та мов програмування.\n\n\n\n\n\nБібілографічний опис bibtex:\n@book{yk-r-intro,\n  author       = {Юрій Клебан},\n  title        = {Вступ до програмування в R},\n  publisher    = {Zenodo},\n  year         = 2022,\n  doi          = {10.5281/zenodo.7251419},\n  url          = {https://doi.org/10.5281/zenodo.7251419}\n}"
  },
  {
    "objectID": "00-intro.html",
    "href": "00-intro.html",
    "title": "Вступ",
    "section": "",
    "text": "Фахівці спеціальності економічна кібернетика, а також фінанси та кредит у майбутньому працюватимуть з великими масивами даних, що накопичуються у даний момент і збиралися у попередні дисятиліття. Підготовка, обробка і трансформація даних у зручний формат прийняття рішень забирає все більше часу, а звичні рашіне інструменти аналізу даних, як наприклад, Microsoft Excel не мають достатньо вбудованих можливостей для виконнання задач бізнесу.\nНа даний час існує велика кількість мов програмування, що інтегруються у суспільні сфери діяльності людини та роботи технічних систем: біоінформатика, а також економіка та бізнес.\nОднією з мов програмування, що отримали широке поширення серед економістів-науковців, аналітиків та практиків математичного моделювання (machine learning) є мова програмування R(R Core Team 2020). Свою популярність ця мова програмування здобула завдяки простоті у використанні, доступності (безкоштовні як базові компоненти для написання коду, так і середовища розробки), розширюваності (кожен розробник має можливість створювати власні пакети та публікувати їх у відкритому доступі).\nОсновними задачами курсу “Вступ до прикладного програмування в R” є ознайомлення студентів з базовми конструкціями мови програмування R, вивчення способів роботи з найпоширенішими типами даних, читання інформації з різноманітних джерел. Також студенти отримують знання про можливості використання R для виконання задач аналізу даних та візуалізації.\n\n\n\n\n\nR Core Team. 2020. R: A Language and Environment for Statistical Computing. Vienna, Austria: R Foundation for Statistical Computing. https://www.R-project.org/."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Список використаних джерел",
    "section": "",
    "text": "R Core Team. 2020. R: A Language and Environment for Statistical\nComputing. Vienna, Austria: R Foundation for Statistical Computing.\nhttps://www.R-project.org/."
  },
  {
    "objectID": "10-intro.html",
    "href": "10-intro.html",
    "title": "\n1  Вступ\n",
    "section": "",
    "text": "Розглянути осноновні типи джерел даних, їх структуру та способи завантаження/вивантаження у R.\n\nЦе вбудований документ <a target=\"_blank\" href=\"https://office.com\">Microsoft Office</a> на платформі <a target=\"_blank\" href=\"https://office.com/webapps\">Office</a>."
  },
  {
    "objectID": "21-data-read.html",
    "href": "21-data-read.html",
    "title": "\n2  Презентація до лекції\n",
    "section": "",
    "text": "Розглянути осноновні типи джерел даних, їх структуру та способи завантаження/вивантаження у R.\n\nЦе вбудований документ <a target=\"_blank\" href=\"https://office.com\">Microsoft Office</a> на платформі <a target=\"_blank\" href=\"https://office.com/webapps\">Office</a>."
  },
  {
    "objectID": "22-r-csv.html",
    "href": "22-r-csv.html",
    "title": "3  CSV",
    "section": "",
    "text": "You need this packages for code execution:"
  },
  {
    "objectID": "22-r-csv.html#csv-comma-separated-values",
    "href": "22-r-csv.html#csv-comma-separated-values",
    "title": "3  Data collection and saving",
    "section": "3.1 CSV (Comma Separated Values)",
    "text": "3.1 CSV (Comma Separated Values)\nCSV - comma separated values.\n\n# lets check current working directory to write correct files path\ngetwd()\n\n'E:/Repos/Season 2022/r-book/_book/docs/data-analysis-en'\n\n\nYou can use / or \\\\ for writing correct path in R. For example:\n\npath = \"d:/projects/file.csv\"\npath = \"d:\\\\projects\\\\file.csv\"\n\nTo combine path use paste() or paste0() functions\n\nwork_dir = getwd()\nwork_dir \n\n'E:/Repos/Season 2022/r-book/_book/docs/data-analysis-en'\n\n\n\nfile_name = \"temp_file.csv\"\nfile_path = paste0(work_dir, \"/\", file_name)\nfile_path\n\n'E:/Repos/Season 2022/r-book/_book/docs/data-analysis-en/temp_file.csv'\n\n\n\nfile_path = paste(work_dir, file_name, sep = \"/\")\nfile_path\n\n'E:/Repos/Season 2022/r-book/_book/docs/data-analysis-en/temp_file.csv'\n\n\n\n3.1.1 Sample dataset description\nInformation about dataset from kaggle.com. Original file located at url: https://www.kaggle.com/radmirzosimov/telecom-users-dataset.\nAny business wants to maximize the number of customers. To achieve this goal, it is important not only to try to attract new ones, but also to retain existing ones. Retaining a client will cost the company less than attracting a new one. In addition, a new client may be weakly interested in business services and it will be difficult to work with him, while old clients already have the necessary data on interaction with the service.\nAccordingly, predicting the churn, we can react in time and try to keep the client who wants to leave. Based on the data about the services that the client uses, we can make him a special offer, trying to change his decision to leave the operator. This will make the task of retention easier to implement than the task of attracting new users, about which we do not know anything yet.\nYou are provided with a dataset from a telecommunications company. The data contains information about almost six thousand users, their demographic characteristics, the services they use, the duration of using the operator’s services, the method of payment, and the amount of payment.\nThe task is to analyze the data and predict the churn of users (to identify people who will and will not renew their contract). The work should include the following mandatory items:\n\nDescription of the data (with the calculation of basic statistics);\nResearch of dependencies and formulation of hypotheses;\nBuilding models for predicting the outflow (with justification for the choice of a particular model) 4. based on tested hypotheses and identified relationships;\nComparison of the quality of the obtained models.\n\nFields description:\n\ncustomerID - customer id\ngender - client gender (male / female)\nSeniorCitizen - is the client retired (1, 0)\nPartner - is the client married (Yes, No)\ntenure - how many months a person has been a client of the company\nPhoneService - is the telephone service connected (Yes, No)\nMultipleLines - are multiple phone lines connected (Yes, No, No phone service)\nInternetService - client’s Internet service provider (DSL, Fiber optic, No)\nOnlineSecurity - is the online security service connected (Yes, No, No internet service)\nOnlineBackup - is the online backup service activated (Yes, No, No internet service)\nDeviceProtection - does the client have equipment insurance (Yes, No, No internet service)\nTechSupport - is the technical support service connected (Yes, No, No internet service)\nStreamingTV - is the streaming TV service connected (Yes, No, No internet service)\nStreamingMovies - is the streaming cinema service activated (Yes, No, No internet service)\nContract - type of customer contract (Month-to-month, One year, Two year)\nPaperlessBilling - whether the client uses paperless billing (Yes, No)\nPaymentMethod - payment method (Electronic check, Mailed check, Bank transfer (automatic), Credit card (automatic))\nMonthlyCharges - current monthly payment\nTotalCharges - the total amount that the client paid for the services for the entire time\nChurn - whether there was a churn (Yes or No)\n\nThare are few methods for reading/writing csv in base package:\n\nread.csv(), write.csv - default data separator is ,, decimal is separator ..\nread.csv2(), write.csv2 - default data separator is ;, decimal is separator ,.\n\nBefore using any new function check it usage information with help(function_name) or ?function_name, example: ?read.csv.\nYou can read (current data set has NA values as example, there are no NA in original datase):\n\ndata <- read.csv(\"../../data/telecom_users.csv\") # default reading\nstr(data)\n\n'data.frame':   5986 obs. of  22 variables:\n $ X               : int  1869 4528 6344 6739 432 2215 5260 6001 1480 5137 ...\n $ customerID      : chr  \"7010-BRBUU\" \"9688-YGXVR\" \"9286-DOJGF\" \"6994-KERXL\" ...\n $ gender          : chr  \"Male\" \"Female\" \"Female\" \"Male\" ...\n $ SeniorCitizen   : int  0 0 1 0 0 0 0 0 0 1 ...\n $ Partner         : chr  \"Yes\" \"No\" \"Yes\" \"No\" ...\n $ Dependents      : chr  \"Yes\" \"No\" \"No\" \"No\" ...\n $ tenure          : int  72 44 38 4 2 70 33 1 39 55 ...\n $ PhoneService    : chr  \"Yes\" \"Yes\" \"Yes\" \"Yes\" ...\n $ MultipleLines   : chr  \"Yes\" \"No\" \"Yes\" \"No\" ...\n $ InternetService : chr  \"No\" \"Fiber optic\" \"Fiber optic\" \"DSL\" ...\n $ OnlineSecurity  : chr  \"No internet service\" \"No\" \"No\" \"No\" ...\n $ OnlineBackup    : chr  \"No internet service\" \"Yes\" \"No\" \"No\" ...\n $ DeviceProtection: chr  \"No internet service\" \"Yes\" \"No\" \"No\" ...\n $ TechSupport     : chr  \"No internet service\" \"No\" \"No\" \"No\" ...\n $ StreamingTV     : chr  \"No internet service\" \"Yes\" \"No\" \"No\" ...\n $ StreamingMovies : chr  \"No internet service\" \"No\" \"No\" \"Yes\" ...\n $ Contract        : chr  \"Two year\" \"Month-to-month\" \"Month-to-month\" \"Month-to-month\" ...\n $ PaperlessBilling: chr  \"No\" \"Yes\" \"Yes\" \"Yes\" ...\n $ PaymentMethod   : chr  \"Credit card (automatic)\" \"Credit card (automatic)\" \"Bank transfer (automatic)\" \"Electronic check\" ...\n $ MonthlyCharges  : chr  \"24.1\" \"88.15\" \"74.95\" \"55.9\" ...\n $ TotalCharges    : num  1735 3973 2870 238 120 ...\n $ Churn           : chr  \"No\" \"No\" \"Yes\" \"No\" ...\n\n\n\ndata <- read.csv(\"../../data/telecom_users.csv\",\n                  sep = \",\", # comma not only possibel separator\n                  dec = \".\", # decimal separator can be different\n                  na.strings = c(\"\", \"NA\", \"NULL\")) # you can define NA values\n\n\nstr(data) # chack data structure / types/ values\n\n'data.frame':   5986 obs. of  22 variables:\n $ X               : int  1869 4528 6344 6739 432 2215 5260 6001 1480 5137 ...\n $ customerID      : chr  \"7010-BRBUU\" \"9688-YGXVR\" \"9286-DOJGF\" \"6994-KERXL\" ...\n $ gender          : chr  \"Male\" \"Female\" \"Female\" \"Male\" ...\n $ SeniorCitizen   : int  0 0 1 0 0 0 0 0 0 1 ...\n $ Partner         : chr  \"Yes\" \"No\" \"Yes\" \"No\" ...\n $ Dependents      : chr  \"Yes\" \"No\" \"No\" \"No\" ...\n $ tenure          : int  72 44 38 4 2 70 33 1 39 55 ...\n $ PhoneService    : chr  \"Yes\" \"Yes\" \"Yes\" \"Yes\" ...\n $ MultipleLines   : chr  \"Yes\" \"No\" \"Yes\" \"No\" ...\n $ InternetService : chr  \"No\" \"Fiber optic\" \"Fiber optic\" \"DSL\" ...\n $ OnlineSecurity  : chr  \"No internet service\" \"No\" \"No\" \"No\" ...\n $ OnlineBackup    : chr  \"No internet service\" \"Yes\" \"No\" \"No\" ...\n $ DeviceProtection: chr  \"No internet service\" \"Yes\" \"No\" \"No\" ...\n $ TechSupport     : chr  \"No internet service\" \"No\" \"No\" \"No\" ...\n $ StreamingTV     : chr  \"No internet service\" \"Yes\" \"No\" \"No\" ...\n $ StreamingMovies : chr  \"No internet service\" \"No\" \"No\" \"Yes\" ...\n $ Contract        : chr  \"Two year\" \"Month-to-month\" \"Month-to-month\" \"Month-to-month\" ...\n $ PaperlessBilling: chr  \"No\" \"Yes\" \"Yes\" \"Yes\" ...\n $ PaymentMethod   : chr  \"Credit card (automatic)\" \"Credit card (automatic)\" \"Bank transfer (automatic)\" \"Electronic check\" ...\n $ MonthlyCharges  : num  24.1 88.2 75 55.9 53.5 ...\n $ TotalCharges    : num  1735 3973 2870 238 120 ...\n $ Churn           : chr  \"No\" \"No\" \"Yes\" \"No\" ...\n\n\n\nhead(data, 2) # top 6 rows, use n = X, for viewing top X lines\n\n\n\nA data.frame: 2 × 22\n\n    XcustomerIDgenderSeniorCitizenPartnerDependentstenurePhoneServiceMultipleLinesInternetService...DeviceProtectionTechSupportStreamingTVStreamingMoviesContractPaperlessBillingPaymentMethodMonthlyChargesTotalChargesChurn\n    <int><chr><chr><int><chr><chr><int><chr><chr><chr>...<chr><chr><chr><chr><chr><chr><chr><dbl><dbl><chr>\n\n\n    118697010-BRBUUMale  0YesYes72YesYesNo         ...No internet serviceNo internet serviceNo internet serviceNo internet serviceTwo year      No Credit card (automatic)24.101734.65No\n    245289688-YGXVRFemale0No No 44YesNo Fiber optic...Yes                No                 Yes                No                 Month-to-monthYesCredit card (automatic)88.153973.20No\n\n\n\n\n\nis.data.frame(data) # if data is data.frame\n\nTRUE\n\n\n\nanyNA(data) # if dataframe contains any NA values\n\nTRUE\n\n\n\nlapply(data, anyNA)\n#lapply(, any) #check NA by 2nd dimension - columns\n\n\n    $X\n        FALSE\n    $customerID\n        FALSE\n    $gender\n        FALSE\n    $SeniorCitizen\n        FALSE\n    $Partner\n        FALSE\n    $Dependents\n        FALSE\n    $tenure\n        FALSE\n    $PhoneService\n        FALSE\n    $MultipleLines\n        FALSE\n    $InternetService\n        FALSE\n    $OnlineSecurity\n        FALSE\n    $OnlineBackup\n        FALSE\n    $DeviceProtection\n        FALSE\n    $TechSupport\n        FALSE\n    $StreamingTV\n        FALSE\n    $StreamingMovies\n        FALSE\n    $Contract\n        FALSE\n    $PaperlessBilling\n        FALSE\n    $PaymentMethod\n        FALSE\n    $MonthlyCharges\n        TRUE\n    $TotalCharges\n        TRUE\n    $Churn\n        FALSE\n\n\n\nCheck MonthlyCharges: TRUE and TotalCharges: TRUE. These columns has NA-values.\nLet’s replace them with mean:\n\ndata[is.na(data$TotalCharges), \"TotalCharges\"] <- mean(data$TotalCharges, na.rm = T)\ndata[is.na(data$MonthlyCharges), \"MonthlyCharges\"] <- mean(data$MonthlyCharges, na.rm = T)\n\n\nany(is.na(data)) # check for NA\n\nFALSE\n\n\nYou can write data with write.csv(), write.csv2() from base package.\n\nwrite.csv(data, file = \"../../data/cleaned_data.csv\", row.names = F)\n# by default row.names = TRUE and file will contain first column with row numbers 1,2, ..., N\n\nOne more useful package is readr. Examples of using:\n\n# library(readr)\n# data <- read_csv(file = \"../../data/telecom_users.csv\")\n# data <- read_csv2(file = \"../../data/telecom_users.csv\")`"
  },
  {
    "objectID": "22-r-csv.html#ms-excel-files-xlsx",
    "href": "22-r-csv.html#ms-excel-files-xlsx",
    "title": "3  Data collection and saving",
    "section": "3.2 MS Excel files (xlsx)",
    "text": "3.2 MS Excel files (xlsx)\nThere are many packages to read/write MS Excel files. xlsx one of the most useful.\n\n# install.packages(\"xlsx\") #install before use it\n\n\nlibrary(xlsx)\n\n\nany(grepl(\"xlsx\", installed.packages())) # check if package installed\n\nTRUE\n\n\n?read.xlsx - review package functions and params\nLet’s read the data telecom_users.xlsx:\n\ndata <- read.xlsx(\"../../data/telecom_users.xlsx\", sheetIndex = 1)\n# sheetIndex = 1 - select sheet to read, or use sheetName = \"sheet1\" to read by Name\nhead(data)\n\n\n\nA data.frame: 6 × 21\n\n    customerIDgenderSeniorCitizenPartnerDependentstenurePhoneServiceMultipleLinesInternetServiceOnlineSecurity...DeviceProtectionTechSupportStreamingTVStreamingMoviesContractPaperlessBillingPaymentMethodMonthlyChargesTotalChargesChurn\n    <chr><chr><dbl><chr><chr><dbl><chr><chr><chr><chr>...<chr><chr><chr><chr><chr><chr><chr><dbl><dbl><chr>\n\n\n    17010-BRBUUMale  0YesYes72YesYes             No         No internet service...No internet serviceNo internet serviceNo internet serviceNo internet serviceTwo year      No Credit card (automatic)  24.101734.65No \n    29688-YGXVRFemale0No No 44YesNo              Fiber opticNo                 ...Yes                No                 Yes                No                 Month-to-monthYesCredit card (automatic)  88.153973.20No \n    39286-DOJGFFemale1YesNo 38YesYes             Fiber opticNo                 ...No                 No                 No                 No                 Month-to-monthYesBank transfer (automatic)74.952869.85Yes\n    46994-KERXLMale  0No No  4YesNo              DSL        No                 ...No                 No                 No                 Yes                Month-to-monthYesElectronic check         55.90 238.50No \n    52181-UAESMMale  0No No  2YesNo              DSL        Yes                ...Yes                No                 No                 No                 Month-to-monthNo Electronic check         53.45 119.50No \n    64312-GVYNHFemale0YesNo 70No No phone serviceDSL        Yes                ...Yes                Yes                No                 Yes                Two year      YesBank transfer (automatic)49.853370.20No \n\n\n\n\n\n# You can also use startRow, endRow and other params to define how much data read\ndata <- read.xlsx(\"../../data/telecom_users.xlsx\", sheetIndex = 1, endRow = 100)\nhead(data)\n\n\n\nA data.frame: 6 × 21\n\n    customerIDgenderSeniorCitizenPartnerDependentstenurePhoneServiceMultipleLinesInternetServiceOnlineSecurity...DeviceProtectionTechSupportStreamingTVStreamingMoviesContractPaperlessBillingPaymentMethodMonthlyChargesTotalChargesChurn\n    <chr><chr><dbl><chr><chr><dbl><chr><chr><chr><chr>...<chr><chr><chr><chr><chr><chr><chr><dbl><dbl><chr>\n\n\n    17010-BRBUUMale  0YesYes72YesYes             No         No internet service...No internet serviceNo internet serviceNo internet serviceNo internet serviceTwo year      No Credit card (automatic)  24.101734.65No \n    29688-YGXVRFemale0No No 44YesNo              Fiber opticNo                 ...Yes                No                 Yes                No                 Month-to-monthYesCredit card (automatic)  88.153973.20No \n    39286-DOJGFFemale1YesNo 38YesYes             Fiber opticNo                 ...No                 No                 No                 No                 Month-to-monthYesBank transfer (automatic)74.952869.85Yes\n    46994-KERXLMale  0No No  4YesNo              DSL        No                 ...No                 No                 No                 Yes                Month-to-monthYesElectronic check         55.90 238.50No \n    52181-UAESMMale  0No No  2YesNo              DSL        Yes                ...Yes                No                 No                 No                 Month-to-monthNo Electronic check         53.45 119.50No \n    64312-GVYNHFemale0YesNo 70No No phone serviceDSL        Yes                ...Yes                Yes                No                 Yes                Two year      YesBank transfer (automatic)49.853370.20No \n\n\n\n\nLet’s replace Churn values Yes/No by 1/0:\n\nhead(data$Churn)\n\n\n'No''No''Yes''No''No''No'\n\n\n\ndata$Churn <- ifelse(data$Churn == \"Yes\", 1, 0)\n\n\nhead(data$Churn)\n\n\n001000\n\n\nWrite final data to excel:\n\nwrite.xlsx(data, file = \"../../data/final_telecom_data.xlsx\")\n\n\n\n3.2.1 Task 1\nDownload from kaggle.com and read dataset Default_Fin.csv: https://www.kaggle.com/kmldas/loan-default-prediction\nDescription:\nThis is a synthetic dataset created using actual data from a financial institution. The data has been modified to remove identifiable features and the numbers transformed to ensure they do not link to original source (financial institution).\nThis is intended to be used for academic purposes for beginners who want to practice financial analytics from a simple financial dataset\n\nIndex - This is the serial number or unique identifier of the loan taker\nEmployed - This is a Boolean 1= employed 0= unemployed\nBank.Balance - Bank Balance of the loan taker\nAnnual.Salary - Annual salary of the loan taker\n\nDefaulted - This is a Boolean 1= defaulted 0= not defaulted\n\n\nCheck what columns has missing values\nCount default and non-default clients / and parts of total clients in %\nCount Employed clients\nCount Employed Default clients\nAverage salary by Employed clients\nRename columns to “id”, “empl”, “balance”, “salary”, “default”\n\n\nSolution for Task 1\n\ndata <- read.csv(\"../../data/Default_Fin.csv\")\nhead(data)\n\n\n\nA data.frame: 6 × 5\n\n    IndexEmployedBank.BalanceAnnual.SalaryDefaulted.\n    <int><int><dbl><dbl><int>\n\n\n    111 8754.36532339.560\n    220 9806.16145273.560\n    33112882.60381205.680\n    441 6351.00428453.880\n    551 9427.92461562.000\n    66011035.08 89898.720\n\n\n\n\n\n\nCheck what columns has missing values\n\n\n\nanyNA(data)\n\nFALSE\n\n\n\n\nCount default and non-default clients / and parts of total clients in %\n\n\n\ndef_count <- nrow(data[data$Defaulted. == 1, ])\nno_def_count <- nrow(data[data$Defaulted. == 0, ])\ndef_count\nno_def_count \n\n333\n\n\n9667\n\n\n\ndef_count / nrow(data) * 100 # part defaults\nno_def_count / nrow(data) * 100 # part non-defaults\n\n3.33\n\n\n96.67\n\n\n\n\nCount Employed clients\n\n\n\nempl <- data[data$Employed == 1, ]\nnrow(empl)\n\n7056\n\n\n\n\nCount Employed Default clients\n\n\n\nempl <- data[data$Employed == 1 & data$Defaulted. == 1, ]\nnrow(empl)\n\n206\n\n\n\n\nAverage salary by Employed clients\n\n\n\nempl <- data[data$Employed == 1, ]\nmean(empl$Annual.Salary)\n\n480143.43414966\n\n\n\n\nRename columns to “id”, “empl”, “balance”, “salary”, “default”:\n\n\n\ncolnames(data) <- c(\"id\", \"empl\", \"balance\", \"salary\", \"default\")\nhead(data)\n\n\n\nA data.frame: 6 × 5\n\n    idemplbalancesalarydefault\n    <int><int><dbl><dbl><int>\n\n\n    111 8754.36532339.560\n    220 9806.16145273.560\n    33112882.60381205.680\n    441 6351.00428453.880\n    551 9427.92461562.000\n    66011035.08 89898.720"
  },
  {
    "objectID": "22-r-csv.html#xml-extensible-markup-language",
    "href": "22-r-csv.html#xml-extensible-markup-language",
    "title": "3  Data collection and saving",
    "section": "3.3 XML (eXtensible Markup Language)",
    "text": "3.3 XML (eXtensible Markup Language)\nFor our example we will use data from data/employes.xml. File contains records with info:\n<RECORDS>\n   <EMPLOYEE>\n      <ID>1</ID>\n      <NAME>Rick</NAME>\n      <SALARY>623.3</SALARY>\n      <STARTDATE>1/1/2012</STARTDATE>\n      <DEPT>IT</DEPT>\n   </EMPLOYEE>\n   ...\n</RECORDS>\n\n#install.packages(\"XML\")\nlibrary(\"XML\")\n#install.packages(\"methods\")\nlibrary(\"methods\")\n\n\nresult <- xmlParse(file = \"../../data/employes.xml\")\nprint(result)\n\n<?xml version=\"1.0\"?>\n<RECORDS>\n  <EMPLOYEE>\n    <ID>1</ID>\n    <NAME>Rick</NAME>\n    <SALARY>623.3</SALARY>\n    <STARTDATE>1/1/2012</STARTDATE>\n    <DEPT>IT</DEPT>\n  </EMPLOYEE>\n  <EMPLOYEE>\n    <ID>2</ID>\n    <NAME>Dan</NAME>\n    <SALARY>515.2</SALARY>\n    <STARTDATE>9/23/2013</STARTDATE>\n    <DEPT>Operations</DEPT>\n  </EMPLOYEE>\n  <EMPLOYEE>\n    <ID>3</ID>\n    <NAME>Michelle</NAME>\n    <SALARY>611</SALARY>\n    <STARTDATE>11/15/2014</STARTDATE>\n    <DEPT>IT</DEPT>\n  </EMPLOYEE>\n  <EMPLOYEE>\n    <ID>4</ID>\n    <NAME>Ryan</NAME>\n    <SALARY>729</SALARY>\n    <STARTDATE>5/11/2014</STARTDATE>\n    <DEPT>HR</DEPT>\n  </EMPLOYEE>\n  <EMPLOYEE>\n    <ID>5</ID>\n    <NAME>Gary</NAME>\n    <SALARY>843.25</SALARY>\n    <STARTDATE>3/27/2015</STARTDATE>\n    <DEPT>Finance</DEPT>\n  </EMPLOYEE>\n  <EMPLOYEE>\n    <ID>6</ID>\n    <NAME>Nina</NAME>\n    <SALARY>578</SALARY>\n    <STARTDATE>5/21/2013</STARTDATE>\n    <DEPT>IT</DEPT>\n  </EMPLOYEE>\n  <EMPLOYEE>\n    <ID>7</ID>\n    <NAME>Simon</NAME>\n    <SALARY>632.8</SALARY>\n    <STARTDATE>7/30/2013</STARTDATE>\n    <DEPT>Operations</DEPT>\n  </EMPLOYEE>\n  <EMPLOYEE>\n    <ID>8</ID>\n    <NAME>Guru</NAME>\n    <SALARY>722.5</SALARY>\n    <STARTDATE>6/17/2014</STARTDATE>\n    <DEPT>Finance</DEPT>\n  </EMPLOYEE>\n</RECORDS>\n \n\n\n\nrootnode <- xmlRoot(result) # reading rootnode of xml document\nrootnode[[1]] # reading first record\n\n<EMPLOYEE>\n  <ID>1</ID>\n  <NAME>Rick</NAME>\n  <SALARY>623.3</SALARY>\n  <STARTDATE>1/1/2012</STARTDATE>\n  <DEPT>IT</DEPT>\n</EMPLOYEE> \n\n\n\nrootnode[[1]][[2]] # reading first record in root node and second tag, its <NAME>\n\n<NAME>Rick</NAME> \n\n\nFor us the best way is to get dataframe:\n\nxmldataframe <- xmlToDataFrame(\"../../data/employes.xml\")\nxmldataframe\n\n\n\nA data.frame: 8 × 5\n\n    IDNAMESALARYSTARTDATEDEPT\n    <chr><chr><chr><chr><chr>\n\n\n    1Rick    623.3 1/1/2012  IT        \n    2Dan     515.2 9/23/2013 Operations\n    3Michelle611   11/15/2014IT        \n    4Ryan    729   5/11/2014 HR        \n    5Gary    843.253/27/2015 Finance   \n    6Nina    578   5/21/2013 IT        \n    7Simon   632.8 7/30/2013 Operations\n    8Guru    722.5 6/17/2014 Finance"
  },
  {
    "objectID": "22-r-csv.html#api-and-json",
    "href": "22-r-csv.html#api-and-json",
    "title": "3  Data collection and saving",
    "section": "3.4 API and JSON",
    "text": "3.4 API and JSON\nJSON (JavaScript Object Notation) is a lightweight data-interchange format. It is easy for humans to read and write. It is easy for machines to parse and generate. It is based on a subset of the JavaScript Programming Language Standard.\nAPI is the acronym for Application Programming Interface, which is a software intermediary that allows two applications to talk to each other.\nOne of the most popular packages for json is jsonlite.\n\n#install.packages(\"jsonlite\")\nlibrary(jsonlite)\n\nLet’s use readinginformation about BTC and USDT crypro currencies from Binance\n\nmarket = 'BTCUSDT'\ninterval = '1h'\nlimit = 100\n\nurl <- paste0(url = \"https://api.binance.com/api/v3/klines?symbol=\", market ,\"&interval=\", interval,\"&limit=\", limit)\nprint(url) # complete request URL\n\n[1] \"https://api.binance.com/api/v3/klines?symbol=BTCUSDT&interval=1h&limit=100\"\n\n\nOn the next stage you need use fromJSON() function to get data.\nMore details about requests to Binanace at https://github.com/binance/binance-spot-api-docs/blob/master/rest-api.md#klinecandlestick-data\nIf you enter ‘url’ value at browser response is going to be like this:\n[\n  [\n    1499040000000,      // Open time\n    \"0.01634790\",       // Open\n    \"0.80000000\",       // High\n    \"0.01575800\",       // Low\n    \"0.01577100\",       // Close\n    \"148976.11427815\",  // Volume\n    1499644799999,      // Close time\n    \"2434.19055334\",    // Quote asset volume\n    308,                // Number of trades\n    \"1756.87402397\",    // Taker buy base asset volume\n    \"28.46694368\",      // Taker buy quote asset volume\n    \"17928899.62484339\" // Ignore.\n  ]\n]\n\ndata <- fromJSON(url) # get json and transform it to list()\ndata <- data[, 1:7] # let's left only 1:7 columns (from Open time to Close time)\nhead(data)\n\n\n\nA matrix: 6 × 7 of type chr\n\n    165051360000041693.5800000041750.0000000041525.0000000041610.010000001138.643370001650517199999\n    165051720000041610.0100000041699.0000000041434.4400000041462.760000001229.259360001650520799999\n    165052080000041462.7500000041600.0000000041419.2000000041522.380000001049.712440001650524399999\n    165052440000041522.3800000041940.0000000041451.0000000041855.690000001928.480910001650527999999\n    1.650528e+12 41855.6900000042050.3000000041741.1000000041922.970000002518.040900001650531599999\n    165053160000041922.9600000041971.9000000041743.9600000041803.700000001655.769930001650535199999\n\n\n\n\n\ntypeof(data) # check data type\ndata <- as.data.frame(data) # convert to dataframe\nhead(data)\n\n'character'\n\n\n\n\nA data.frame: 6 × 7\n\n    V1V2V3V4V5V6V7\n    <chr><chr><chr><chr><chr><chr><chr>\n\n\n    1165051360000041693.5800000041750.0000000041525.0000000041610.010000001138.643370001650517199999\n    2165051720000041610.0100000041699.0000000041434.4400000041462.760000001229.259360001650520799999\n    3165052080000041462.7500000041600.0000000041419.2000000041522.380000001049.712440001650524399999\n    4165052440000041522.3800000041940.0000000041451.0000000041855.690000001928.480910001650527999999\n    51.650528e+12 41855.6900000042050.3000000041741.1000000041922.970000002518.040900001650531599999\n    6165053160000041922.9600000041971.9000000041743.9600000041803.700000001655.769930001650535199999\n\n\n\n\n\n# fix columns names\ncolnames(data) <- c(\"Open_time\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\", \"Close_time\")\nhead(data) # looks better, but columns are characters still\n\n\n\nA data.frame: 6 × 7\n\n    Open_timeOpenHighLowCloseVolumeClose_time\n    <chr><chr><chr><chr><chr><chr><chr>\n\n\n    1165051360000041693.5800000041750.0000000041525.0000000041610.010000001138.643370001650517199999\n    2165051720000041610.0100000041699.0000000041434.4400000041462.760000001229.259360001650520799999\n    3165052080000041462.7500000041600.0000000041419.2000000041522.380000001049.712440001650524399999\n    4165052440000041522.3800000041940.0000000041451.0000000041855.690000001928.480910001650527999999\n    51.650528e+12 41855.6900000042050.3000000041741.1000000041922.970000002518.040900001650531599999\n    6165053160000041922.9600000041971.9000000041743.9600000041803.700000001655.769930001650535199999\n\n\n\n\n\nis.numeric(data[,1]) # check 1st column type is numeric\nis.numeric(data[,2]) # check 2nd column type is numeric\n\nFALSE\n\n\nFALSE\n\n\n\ndata <- as.data.frame(sapply(data, as.numeric)) # convert all columns to numeric\nhead(data) # good, its double now\n\n\n\nA data.frame: 6 × 7\n\n    Open_timeOpenHighLowCloseVolumeClose_time\n    <dbl><dbl><dbl><dbl><dbl><dbl><dbl>\n\n\n    11.650514e+1241693.5841750.041525.0041610.011138.6431.650517e+12\n    21.650517e+1241610.0141699.041434.4441462.761229.2591.650521e+12\n    31.650521e+1241462.7541600.041419.2041522.381049.7121.650524e+12\n    41.650524e+1241522.3841940.041451.0041855.691928.4811.650528e+12\n    51.650528e+1241855.6942050.341741.1041922.972518.0411.650532e+12\n    61.650532e+1241922.9641971.941743.9641803.701655.7701.650535e+12\n\n\n\n\nFinal stage is to convert Open_time and Close_time to dates.\n\ndata$Open_time <- as.POSIXct(data$Open_time/1e3, origin = '1970-01-01')\ndata$Close_time <- as.POSIXct(data$Close_time/1e3, origin = '1970-01-01')\n\nhead(data) \n\n\n\nA data.frame: 6 × 7\n\n    Open_timeOpenHighLowCloseVolumeClose_time\n    <dttm><dbl><dbl><dbl><dbl><dbl><dttm>\n\n\n    12022-04-21 07:00:0041693.5841750.041525.0041610.011138.6432022-04-21 07:59:59\n    22022-04-21 08:00:0041610.0141699.041434.4441462.761229.2592022-04-21 08:59:59\n    32022-04-21 09:00:0041462.7541600.041419.2041522.381049.7122022-04-21 09:59:59\n    42022-04-21 10:00:0041522.3841940.041451.0041855.691928.4812022-04-21 10:59:59\n    52022-04-21 11:00:0041855.6942050.341741.1041922.972518.0412022-04-21 11:59:59\n    62022-04-21 12:00:0041922.9641971.941743.9641803.701655.7702022-04-21 12:59:59\n\n\n\n\n\ntail(data) # check last records\n\n\n\nA data.frame: 6 × 7\n\n    Open_timeOpenHighLowCloseVolumeClose_time\n    <dttm><dbl><dbl><dbl><dbl><dbl><dttm>\n\n\n    952022-04-25 05:00:0039095.8139153.9438961.6439091.171205.51582022-04-25 05:59:59\n    962022-04-25 06:00:0039091.1739294.7639086.3739253.711443.33182022-04-25 06:59:59\n    972022-04-25 07:00:0039253.7039256.2839055.7139139.74 896.85542022-04-25 07:59:59\n    982022-04-25 08:00:0039139.7439230.5038947.4238975.221057.49002022-04-25 08:59:59\n    992022-04-25 09:00:0038975.2139057.9738590.0038636.352814.97162022-04-25 09:59:59\n    1002022-04-25 10:00:0038636.3538675.6838200.0038534.993528.23552022-04-25 10:59:59"
  },
  {
    "objectID": "22-r-csv.html#google-services",
    "href": "22-r-csv.html#google-services",
    "title": "3  Data collection and saving",
    "section": "3.5 Google Services",
    "text": "3.5 Google Services\n\n3.5.1 Google Spreadsheets\n\nTHIS CHAPTER IS UNDER CONSTRUCTION / Working with Google Spreadsheets need account authorization.\n\ngooglesheets4 is a package to work with Google Sheets from R.\n\n#install.packages(\"googlesheets4\")\nlibrary(googlesheets4)\n\nYou can read google documents after authentification on google service. There is sample code:\nread_sheet(\"https://docs.google.com/spreadsheets/d/1U6Cf_qEOhiR9AZqTqS3mbMF3zt2db48ZP5v3rkrAEJY/edit#gid=780868077\")\ngs4_deauth()\nLet’s read sample dataset gapminder. It detailed described in next paragraph.\n\n# gs4_example(\"gapminder\")\n\n\n\n\n3.5.2 Google Search Trends\nGoogle Trends is a service for analyzing search requests by many filters like region (continent, country, locality), period (year, month), information category (business, education, hobby, healthcare), information type (news, shopping, video, images) https://trends.google.com/trends/\n\n# install.packages('gtrendsR')\n# install.packages('ggplot2')\nlibrary(gtrendsR) # loading package for Google Trends queries\nlibrary(ggplot2)\n\nLet’s configure out google trends query params\n\nkeywords = c(\"Bitcoin\", \"FC Barcelona\") # search keywords\ncountry = c('AT') # search region from https://support.google.com/business/answer/6270107?hl=en\ntime = (\"2021-01-01 2021-06-01\") # period\nchannel = 'web' # search channel: google search ('news' - google news, 'images' - google images)\n\n\n# query\ntrends = gtrends(keywords, gprop = channel, geo = country, time = time, tz = \"UTC\")\n\n\ntime_trend = trends$interest_over_time\nhead(time_trend)\n\n\n\nA data.frame: 6 × 7\n\n    datehitskeywordgeotimegpropcategory\n    <dttm><chr><chr><chr><chr><chr><int>\n\n\n    12021-01-0136BitcoinAT2021-01-01 2021-06-01web0\n    22021-01-0267BitcoinAT2021-01-01 2021-06-01web0\n    32021-01-0374BitcoinAT2021-01-01 2021-06-01web0\n    42021-01-0457BitcoinAT2021-01-01 2021-06-01web0\n    52021-01-0553BitcoinAT2021-01-01 2021-06-01web0\n    62021-01-0666BitcoinAT2021-01-01 2021-06-01web0\n\n\n\n\n\nplot <- ggplot(data=time_trend, aes(x=date, y=hits, group=keyword, col=keyword)) +\n  geom_line() +\n  xlab('Time') + \n  ylab('Relative Interest') + \n  theme(legend.title = element_blank(), legend.position=\"bottom\", legend.text=element_text(size=15)) + \n  ggtitle(\"Google Search Volume\")  \n\nplot"
  },
  {
    "objectID": "22-r-csv.html#sql-with-sqlite-sample",
    "href": "22-r-csv.html#sql-with-sqlite-sample",
    "title": "3  Data collection and saving",
    "section": "3.6 SQL (with SQLite sample)",
    "text": "3.6 SQL (with SQLite sample)\nWe are going to review working with database on SQLite, becouse it allows us not to install DB-server and start working with simple file.\nFor now we will use RSQLite package.\n\n# install.packages(\"RSQLite\")\nlibrary(RSQLite)\n\n\n# let's use mtcars dataset\n\ndata(\"mtcars\") # loads the data\nhead(mtcars) # preview the data\n\n\n\nA data.frame: 6 × 11\n\n    mpgcyldisphpdratwtqsecvsamgearcarb\n    <dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl>\n\n\n    Mazda RX421.061601103.902.62016.460144\n    Mazda RX4 Wag21.061601103.902.87517.020144\n    Datsun 71022.84108 933.852.32018.611141\n    Hornet 4 Drive21.462581103.083.21519.441031\n    Hornet Sportabout18.783601753.153.44017.020032\n    Valiant18.162251052.763.46020.221031\n\n\n\n\n\nI need this code for book successful building (remove database file if exists):\n\n\n#Define the file name that will be deleted\nfn <- paste0(\"../../data/cars.sqlite\")\n#Check its existence\nif (file.exists(fn)) {\n  #Delete file if it exists\n  file.remove(fn)\n}\n\nTRUE\n\n\nNow, let’s create new:\n\n# create new db file\ndb_path = paste0(\"../../data/cars.sqlite\")\n# create connection\nconn <- dbConnect(RSQLite::SQLite(), \n                    db_path,\n                    overwrite = TRUE, append = FALSE) # for lecture content only\n\n\n# Write the mtcars dataset into a table names mtcars_data\ndbWriteTable(conn, \"cars_table\", mtcars)\n# List all the tables available in the database\ndbListTables(conn)\n\n\n'cars_table'\n\n\n\ntable_data <- dbGetQuery(conn, \"SELECT * FROM cars_table\")\nhead(table_data)\n\n\n\nA data.frame: 6 × 11\n\n    mpgcyldisphpdratwtqsecvsamgearcarb\n    <dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl>\n\n\n    121.061601103.902.62016.460144\n    221.061601103.902.87517.020144\n    322.84108 933.852.32018.611141\n    421.462581103.083.21519.441031\n    518.783601753.153.44017.020032\n    618.162251052.763.46020.221031\n\n\n\n\n\n# close connection\ndbDisconnect(conn)\n\nYou can write complex queries for many tables if you knowledge of SQL allows."
  },
  {
    "objectID": "22-r-csv.html#web-pages-html",
    "href": "22-r-csv.html#web-pages-html",
    "title": "3  Data collection and saving",
    "section": "3.7 Web-pages (HTML)",
    "text": "3.7 Web-pages (HTML)\nSometimes decision making needs scrap data from web sources and pages.\nLet’s try to parse data from Wikipedia as table.\n\n#install.packages(\"rvest\")\nlibrary(rvest) # Parsing of HTML/XML files\n\nGo to web page https://en.wikipedia.org/wiki/List_of_largest_banks and check it.\n\n# fix URL\nurl <- \"https://en.wikipedia.org/wiki/List_of_largest_banks\"\n#url <- \"data/List of largest banks - Wikipedia_.html\"\n\n\n# read html content of the page\npage <- read_html(url)\npage\n\n{html_document}\n<html class=\"client-nojs\" lang=\"en\" dir=\"ltr\">\n[1] <head>\\n<meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8 ...\n[2] <body class=\"mediawiki ltr sitedir-ltr mw-hide-empty-elt ns-0 ns-subject  ...\n\n\n\n# read all yables on page\ntables <- html_nodes(page, \"table\")\ntables\n\n{xml_nodeset (4)}\n[1] <table class=\"box-Missing_information plainlinks metadata ambox ambox-con ...\n[2] <table class=\"wikitable sortable mw-collapsible\"><tbody>\\n<tr>\\n<th data- ...\n[3] <table class=\"wikitable sortable mw-collapsible\">\\n<caption>Number of ban ...\n[4] <table class=\"wikitable sortable mw-collapsible\"><tbody>\\n<tr>\\n<th data- ...\n\n\nFor now, let’s read a table of Total Assets in US Billion\n\n# with pipe operator\n#tables[2] %>% \n #   html_table(fill = TRUE) %>% \n #   as.data.frame()\n#without pipe operator\nassets_table <- as.data.frame(html_table(tables[2], fill = TRUE))   \nhead(assets_table)\n\n\n\nA data.frame: 6 × 3\n\n    RankBank.nameTotal.assets.2020..US..billion.\n    <int><chr><chr>\n\n\n    11Industrial and Commercial Bank of China5,518.00\n    22China Construction Bank                4,400.00\n    33Agricultural Bank of China             4,300.00\n    44Bank of China                          4,200.00\n    55JPMorgan Chase                         3,831.65\n    66Mitsubishi UFJ Financial Group         3,175.21\n\n\n\n\nNext is reading data of market capitalization table (4th):\n\ncapital_table <- as.data.frame(html_table(tables[4], fill = TRUE))   \nhead(capital_table)\n\n\n\nA data.frame: 6 × 3\n\n    RankBank.nameMarket.cap.US..billion.\n    <int><chr><dbl>\n\n\n    11JPMorgan Chase                         368.78\n    22Industrial and Commercial Bank of China295.65\n    33Bank of America                        279.73\n    44Wells Fargo                            214.34\n    55China Construction Bank                207.98\n    66Agricultural Bank of China             181.49\n\n\n\n\nAnd now let’s merge() this two datasets:\n\nmerged_data <- merge(assets_table, capital_table, by = \"Bank.name\")\nhead(merged_data)\n\n\n\nA data.frame: 6 × 5\n\n    Bank.nameRank.xTotal.assets.2020..US..billion.Rank.yMarket.cap.US..billion.\n    <chr><int><chr><int><dbl>\n\n\n    1Agricultural Bank of China              34,300.00 6181.49\n    2Australia and New Zealand Banking Group48661.72  26 54.88\n    3Banco Bilbao Vizcaya Argentaria        42782.16  37 37.42\n    4Banco Bradesco                         79345.21  18 74.67\n    5Banco Santander                        161,702.6117 75.47\n    6Bank of America                         82,434.08 3279.73\n\n\n\n\n\n3.7.1 Task 3\nFrom a page https://en.wikipedia.org/wiki/List_of_largest_banks read and merge by country named tables:\n\nNumber of banks in the top 100 by total assets\nTotal market capital (US$ billion) across the top 70 banks by country\n\nSolution\n\nlibrary(rvest)\nurl <- \"https://en.wikipedia.org/wiki/List_of_largest_banks\" # got to url in other tab\n#url <- \"data/List of largest banks - Wikipedia_.html\"\npage_data <- read_html(url) # read html content\n\ntables <- html_nodes(page_data, \"table\")\nhtml_table(tables[1]) #its not needed table\n\n\n\n    \nA tibble: 1  2\n\n    X1X2\n    <lgl><chr>\n\n\n    NAThis article is missing information about Revenue and Employment. Please expand the article to include this information. Further details may exist on the talk page.  (September 2020)\n\n\n\n\n\n\n\nhtml_table(tables[3]) # thats solution for \"Number of banks in the top 100 by total assets\"\n#check the end of table. There are NA record\n# lets remove it\n\n\n\n    \nA tibble: 26  3\n\n    RankCountryNumber\n    <int><chr><int>\n\n\n    1China         19\n    2United States 11\n    3Japan          8\n    4United Kingdom 6\n    4France         6\n    4South Korea    6\n    5Canada         5\n    5Germany        5\n    6Australia      4\n    6Brazil         4\n    6Spain          4\n    7Netherlands    3\n    7Singapore      3\n    7Sweden         3\n    7Switzerland    3\n    8Italy          2\n    9India          1\n    9Austria        1\n    9Belgium        1\n    9Denmark        1\n    9Finland        1\n    9Norway         1\n    9Russia         1\n    9Qatar          1\n    9NA            NA\n    9NA            NA\n\n\n\n\n\n\n\ntable1 <- as.data.frame(html_table(tables[3]))\ntable1 <- table1[!is.na(table1$Country), ]\ntable1 # now it OK!\n\n\n\nA data.frame: 24 × 3\n\n    RankCountryNumber\n    <int><chr><int>\n\n\n    11China         19\n    22United States 11\n    33Japan          8\n    44United Kingdom 6\n    54France         6\n    64South Korea    6\n    75Canada         5\n    85Germany        5\n    96Australia      4\n    106Brazil         4\n    116Spain          4\n    127Netherlands    3\n    137Singapore      3\n    147Sweden         3\n    157Switzerland    3\n    168Italy          2\n    179India          1\n    189Austria        1\n    199Belgium        1\n    209Denmark        1\n    219Finland        1\n    229Norway         1\n    239Russia         1\n    249Qatar          1\n\n\n\n\n\n# SOlution for \"Total market capital (US$ billion) across the top 70 banks by country\"\n# compare this with table on a given page\ntable2 <- as.data.frame(html_table(tables[4]))\ntable2 # now it OK!\n\n\n\nA data.frame: 50 × 3\n\n    RankBank.nameMarket.cap.US..billion.\n    <int><chr><dbl>\n\n\n     1JPMorgan Chase                         368.78\n     2Industrial and Commercial Bank of China295.65\n     3Bank of America                        279.73\n     4Wells Fargo                            214.34\n     5China Construction Bank                207.98\n     6Agricultural Bank of China             181.49\n     7HSBC Holdings PLC                      169.47\n     8Citigroup Inc.                         163.58\n     9Bank of China                          151.15\n    10China Merchants Bank                   133.37\n    11Royal Bank of Canada                   113.80\n    12Toronto-Dominion Bank                  106.61\n    13Commonwealth Bank                       99.77\n    14HDFC Bank                              105.90\n    15U.S. Bancorp                            84.40\n    16Goldman Sachs                           78.70\n    17Banco Santander                         75.47\n    18Banco Bradesco                          74.67\n    19Morgan Stanley                          73.93\n    20Westpac                                 67.84\n    21Mitsubishi UFJ Financial Group          66.20\n    22Scotiabank                              65.48\n    23PNC Financial Services                  63.11\n    24Bank of Communications                  61.85\n    25BNP Paribas                             59.36\n    26Australia and New Zealand Banking Group 54.88\n    27National Australia Bank                 51.68\n    28Lloyds Banking Group                    51.19\n    29Sumitomo Mitsui Financial Group         49.85\n    30Bank of Montreal                        48.12\n    31UBS                                     45.92\n    32ING Group                               44.97\n    33Capital One                             43.22\n    34The Bank of New York Mellon             42.58\n    35China Minsheng Bank                     39.13\n    36China CITIC Bank                        38.55\n    37Banco Bilbao Vizcaya Argentaria         37.42\n    38Mizuho Financial Group                  36.95\n    39Intesa Sanpaolo                         36.90\n    40Credit Agricole                         34.89\n    41Canadian Imperial Bank of Commerce      34.87\n    42Royal Bank of Scotland                  33.95\n    43Barclays                                33.26\n    44Credit Suisse                           30.75\n    45Nordea                                  29.59\n    46Standard Chartered                      29.37\n    47KBC Bank                                27.40\n    48UniCredit                               26.88\n    49Societe Generale                        21.27\n    50Deutsche Bank                           15.77"
  },
  {
    "objectID": "22-r-csv.html#набори-даних",
    "href": "22-r-csv.html#набори-даних",
    "title": "3  CSV",
    "section": "3.5 Набори даних",
    "text": "3.5 Набори даних\n\nhttps://github.com/kleban/r-book-published/tree/main/datasets/telecom_users.csv\nhttps://github.com/kleban/r-book-published/tree/main/datasets/telecom_sers.xlsx\nhttps://github.com/kleban/r-book-published/tree/main/datasets/Default_Fin.csv\nhttps://github.com/kleban/r-book-published/tree/main/datasets/employes.xml"
  },
  {
    "objectID": "22-r-csv.html#references",
    "href": "22-r-csv.html#references",
    "title": "3  CSV",
    "section": "3.6 References",
    "text": "3.6 References\n\nSQLite in R. Datacamp\nTidyverse googlesheets4 0.2.0 \nBinanace spot Api Docs\nWeb Scraping in R: rvest Tutorial by Arvid Kingl"
  },
  {
    "objectID": "23-r-xml.html",
    "href": "23-r-xml.html",
    "title": "4  Data collection and saving",
    "section": "",
    "text": "This chapter contains information about data reading and writing from/to different formats: csv, xml, json, google services, sql, html.\nYou need this packages for code execution:\nThere are many data source types for data storing, reading. Let’s review and try some of them."
  },
  {
    "objectID": "23-r-xml.html#csv-comma-separated-values",
    "href": "23-r-xml.html#csv-comma-separated-values",
    "title": "4  Data collection and saving",
    "section": "4.1 CSV (Comma Separated Values)",
    "text": "4.1 CSV (Comma Separated Values)\nCSV - comma separated values.\n\n# lets check current working directory to write correct files path\ngetwd()\n\n'E:/Repos/Season 2022/r-book/_book/docs/data-analysis-en'\n\n\nYou can use / or \\\\ for writing correct path in R. For example:\n\npath = \"d:/projects/file.csv\"\npath = \"d:\\\\projects\\\\file.csv\"\n\nTo combine path use paste() or paste0() functions\n\nwork_dir = getwd()\nwork_dir \n\n'E:/Repos/Season 2022/r-book/_book/docs/data-analysis-en'\n\n\n\nfile_name = \"temp_file.csv\"\nfile_path = paste0(work_dir, \"/\", file_name)\nfile_path\n\n'E:/Repos/Season 2022/r-book/_book/docs/data-analysis-en/temp_file.csv'\n\n\n\nfile_path = paste(work_dir, file_name, sep = \"/\")\nfile_path\n\n'E:/Repos/Season 2022/r-book/_book/docs/data-analysis-en/temp_file.csv'\n\n\n\n4.1.1 Sample dataset description\nInformation about dataset from kaggle.com. Original file located at url: https://www.kaggle.com/radmirzosimov/telecom-users-dataset.\nAny business wants to maximize the number of customers. To achieve this goal, it is important not only to try to attract new ones, but also to retain existing ones. Retaining a client will cost the company less than attracting a new one. In addition, a new client may be weakly interested in business services and it will be difficult to work with him, while old clients already have the necessary data on interaction with the service.\nAccordingly, predicting the churn, we can react in time and try to keep the client who wants to leave. Based on the data about the services that the client uses, we can make him a special offer, trying to change his decision to leave the operator. This will make the task of retention easier to implement than the task of attracting new users, about which we do not know anything yet.\nYou are provided with a dataset from a telecommunications company. The data contains information about almost six thousand users, their demographic characteristics, the services they use, the duration of using the operator’s services, the method of payment, and the amount of payment.\nThe task is to analyze the data and predict the churn of users (to identify people who will and will not renew their contract). The work should include the following mandatory items:\n\nDescription of the data (with the calculation of basic statistics);\nResearch of dependencies and formulation of hypotheses;\nBuilding models for predicting the outflow (with justification for the choice of a particular model) 4. based on tested hypotheses and identified relationships;\nComparison of the quality of the obtained models.\n\nFields description:\n\ncustomerID - customer id\ngender - client gender (male / female)\nSeniorCitizen - is the client retired (1, 0)\nPartner - is the client married (Yes, No)\ntenure - how many months a person has been a client of the company\nPhoneService - is the telephone service connected (Yes, No)\nMultipleLines - are multiple phone lines connected (Yes, No, No phone service)\nInternetService - client’s Internet service provider (DSL, Fiber optic, No)\nOnlineSecurity - is the online security service connected (Yes, No, No internet service)\nOnlineBackup - is the online backup service activated (Yes, No, No internet service)\nDeviceProtection - does the client have equipment insurance (Yes, No, No internet service)\nTechSupport - is the technical support service connected (Yes, No, No internet service)\nStreamingTV - is the streaming TV service connected (Yes, No, No internet service)\nStreamingMovies - is the streaming cinema service activated (Yes, No, No internet service)\nContract - type of customer contract (Month-to-month, One year, Two year)\nPaperlessBilling - whether the client uses paperless billing (Yes, No)\nPaymentMethod - payment method (Electronic check, Mailed check, Bank transfer (automatic), Credit card (automatic))\nMonthlyCharges - current monthly payment\nTotalCharges - the total amount that the client paid for the services for the entire time\nChurn - whether there was a churn (Yes or No)\n\nThare are few methods for reading/writing csv in base package:\n\nread.csv(), write.csv - default data separator is ,, decimal is separator ..\nread.csv2(), write.csv2 - default data separator is ;, decimal is separator ,.\n\nBefore using any new function check it usage information with help(function_name) or ?function_name, example: ?read.csv.\nYou can read (current data set has NA values as example, there are no NA in original datase):\n\ndata <- read.csv(\"../../data/telecom_users.csv\") # default reading\nstr(data)\n\n'data.frame':   5986 obs. of  22 variables:\n $ X               : int  1869 4528 6344 6739 432 2215 5260 6001 1480 5137 ...\n $ customerID      : chr  \"7010-BRBUU\" \"9688-YGXVR\" \"9286-DOJGF\" \"6994-KERXL\" ...\n $ gender          : chr  \"Male\" \"Female\" \"Female\" \"Male\" ...\n $ SeniorCitizen   : int  0 0 1 0 0 0 0 0 0 1 ...\n $ Partner         : chr  \"Yes\" \"No\" \"Yes\" \"No\" ...\n $ Dependents      : chr  \"Yes\" \"No\" \"No\" \"No\" ...\n $ tenure          : int  72 44 38 4 2 70 33 1 39 55 ...\n $ PhoneService    : chr  \"Yes\" \"Yes\" \"Yes\" \"Yes\" ...\n $ MultipleLines   : chr  \"Yes\" \"No\" \"Yes\" \"No\" ...\n $ InternetService : chr  \"No\" \"Fiber optic\" \"Fiber optic\" \"DSL\" ...\n $ OnlineSecurity  : chr  \"No internet service\" \"No\" \"No\" \"No\" ...\n $ OnlineBackup    : chr  \"No internet service\" \"Yes\" \"No\" \"No\" ...\n $ DeviceProtection: chr  \"No internet service\" \"Yes\" \"No\" \"No\" ...\n $ TechSupport     : chr  \"No internet service\" \"No\" \"No\" \"No\" ...\n $ StreamingTV     : chr  \"No internet service\" \"Yes\" \"No\" \"No\" ...\n $ StreamingMovies : chr  \"No internet service\" \"No\" \"No\" \"Yes\" ...\n $ Contract        : chr  \"Two year\" \"Month-to-month\" \"Month-to-month\" \"Month-to-month\" ...\n $ PaperlessBilling: chr  \"No\" \"Yes\" \"Yes\" \"Yes\" ...\n $ PaymentMethod   : chr  \"Credit card (automatic)\" \"Credit card (automatic)\" \"Bank transfer (automatic)\" \"Electronic check\" ...\n $ MonthlyCharges  : chr  \"24.1\" \"88.15\" \"74.95\" \"55.9\" ...\n $ TotalCharges    : num  1735 3973 2870 238 120 ...\n $ Churn           : chr  \"No\" \"No\" \"Yes\" \"No\" ...\n\n\n\ndata <- read.csv(\"../../data/telecom_users.csv\",\n                  sep = \",\", # comma not only possibel separator\n                  dec = \".\", # decimal separator can be different\n                  na.strings = c(\"\", \"NA\", \"NULL\")) # you can define NA values\n\n\nstr(data) # chack data structure / types/ values\n\n'data.frame':   5986 obs. of  22 variables:\n $ X               : int  1869 4528 6344 6739 432 2215 5260 6001 1480 5137 ...\n $ customerID      : chr  \"7010-BRBUU\" \"9688-YGXVR\" \"9286-DOJGF\" \"6994-KERXL\" ...\n $ gender          : chr  \"Male\" \"Female\" \"Female\" \"Male\" ...\n $ SeniorCitizen   : int  0 0 1 0 0 0 0 0 0 1 ...\n $ Partner         : chr  \"Yes\" \"No\" \"Yes\" \"No\" ...\n $ Dependents      : chr  \"Yes\" \"No\" \"No\" \"No\" ...\n $ tenure          : int  72 44 38 4 2 70 33 1 39 55 ...\n $ PhoneService    : chr  \"Yes\" \"Yes\" \"Yes\" \"Yes\" ...\n $ MultipleLines   : chr  \"Yes\" \"No\" \"Yes\" \"No\" ...\n $ InternetService : chr  \"No\" \"Fiber optic\" \"Fiber optic\" \"DSL\" ...\n $ OnlineSecurity  : chr  \"No internet service\" \"No\" \"No\" \"No\" ...\n $ OnlineBackup    : chr  \"No internet service\" \"Yes\" \"No\" \"No\" ...\n $ DeviceProtection: chr  \"No internet service\" \"Yes\" \"No\" \"No\" ...\n $ TechSupport     : chr  \"No internet service\" \"No\" \"No\" \"No\" ...\n $ StreamingTV     : chr  \"No internet service\" \"Yes\" \"No\" \"No\" ...\n $ StreamingMovies : chr  \"No internet service\" \"No\" \"No\" \"Yes\" ...\n $ Contract        : chr  \"Two year\" \"Month-to-month\" \"Month-to-month\" \"Month-to-month\" ...\n $ PaperlessBilling: chr  \"No\" \"Yes\" \"Yes\" \"Yes\" ...\n $ PaymentMethod   : chr  \"Credit card (automatic)\" \"Credit card (automatic)\" \"Bank transfer (automatic)\" \"Electronic check\" ...\n $ MonthlyCharges  : num  24.1 88.2 75 55.9 53.5 ...\n $ TotalCharges    : num  1735 3973 2870 238 120 ...\n $ Churn           : chr  \"No\" \"No\" \"Yes\" \"No\" ...\n\n\n\nhead(data, 2) # top 6 rows, use n = X, for viewing top X lines\n\n\n\nA data.frame: 2 × 22\n\n    XcustomerIDgenderSeniorCitizenPartnerDependentstenurePhoneServiceMultipleLinesInternetService...DeviceProtectionTechSupportStreamingTVStreamingMoviesContractPaperlessBillingPaymentMethodMonthlyChargesTotalChargesChurn\n    <int><chr><chr><int><chr><chr><int><chr><chr><chr>...<chr><chr><chr><chr><chr><chr><chr><dbl><dbl><chr>\n\n\n    118697010-BRBUUMale  0YesYes72YesYesNo         ...No internet serviceNo internet serviceNo internet serviceNo internet serviceTwo year      No Credit card (automatic)24.101734.65No\n    245289688-YGXVRFemale0No No 44YesNo Fiber optic...Yes                No                 Yes                No                 Month-to-monthYesCredit card (automatic)88.153973.20No\n\n\n\n\n\nis.data.frame(data) # if data is data.frame\n\nTRUE\n\n\n\nanyNA(data) # if dataframe contains any NA values\n\nTRUE\n\n\n\nlapply(data, anyNA)\n#lapply(, any) #check NA by 2nd dimension - columns\n\n\n    $X\n        FALSE\n    $customerID\n        FALSE\n    $gender\n        FALSE\n    $SeniorCitizen\n        FALSE\n    $Partner\n        FALSE\n    $Dependents\n        FALSE\n    $tenure\n        FALSE\n    $PhoneService\n        FALSE\n    $MultipleLines\n        FALSE\n    $InternetService\n        FALSE\n    $OnlineSecurity\n        FALSE\n    $OnlineBackup\n        FALSE\n    $DeviceProtection\n        FALSE\n    $TechSupport\n        FALSE\n    $StreamingTV\n        FALSE\n    $StreamingMovies\n        FALSE\n    $Contract\n        FALSE\n    $PaperlessBilling\n        FALSE\n    $PaymentMethod\n        FALSE\n    $MonthlyCharges\n        TRUE\n    $TotalCharges\n        TRUE\n    $Churn\n        FALSE\n\n\n\nCheck MonthlyCharges: TRUE and TotalCharges: TRUE. These columns has NA-values.\nLet’s replace them with mean:\n\ndata[is.na(data$TotalCharges), \"TotalCharges\"] <- mean(data$TotalCharges, na.rm = T)\ndata[is.na(data$MonthlyCharges), \"MonthlyCharges\"] <- mean(data$MonthlyCharges, na.rm = T)\n\n\nany(is.na(data)) # check for NA\n\nFALSE\n\n\nYou can write data with write.csv(), write.csv2() from base package.\n\nwrite.csv(data, file = \"../../data/cleaned_data.csv\", row.names = F)\n# by default row.names = TRUE and file will contain first column with row numbers 1,2, ..., N\n\nOne more useful package is readr. Examples of using:\n\n# library(readr)\n# data <- read_csv(file = \"../../data/telecom_users.csv\")\n# data <- read_csv2(file = \"../../data/telecom_users.csv\")`"
  },
  {
    "objectID": "23-r-xml.html#ms-excel-files-xlsx",
    "href": "23-r-xml.html#ms-excel-files-xlsx",
    "title": "4  Data collection and saving",
    "section": "4.2 MS Excel files (xlsx)",
    "text": "4.2 MS Excel files (xlsx)\nThere are many packages to read/write MS Excel files. xlsx one of the most useful.\n\n# install.packages(\"xlsx\") #install before use it\n\n\nlibrary(xlsx)\n\n\nany(grepl(\"xlsx\", installed.packages())) # check if package installed\n\nTRUE\n\n\n?read.xlsx - review package functions and params\nLet’s read the data telecom_users.xlsx:\n\ndata <- read.xlsx(\"../../data/telecom_users.xlsx\", sheetIndex = 1)\n# sheetIndex = 1 - select sheet to read, or use sheetName = \"sheet1\" to read by Name\nhead(data)\n\n\n\nA data.frame: 6 × 21\n\n    customerIDgenderSeniorCitizenPartnerDependentstenurePhoneServiceMultipleLinesInternetServiceOnlineSecurity...DeviceProtectionTechSupportStreamingTVStreamingMoviesContractPaperlessBillingPaymentMethodMonthlyChargesTotalChargesChurn\n    <chr><chr><dbl><chr><chr><dbl><chr><chr><chr><chr>...<chr><chr><chr><chr><chr><chr><chr><dbl><dbl><chr>\n\n\n    17010-BRBUUMale  0YesYes72YesYes             No         No internet service...No internet serviceNo internet serviceNo internet serviceNo internet serviceTwo year      No Credit card (automatic)  24.101734.65No \n    29688-YGXVRFemale0No No 44YesNo              Fiber opticNo                 ...Yes                No                 Yes                No                 Month-to-monthYesCredit card (automatic)  88.153973.20No \n    39286-DOJGFFemale1YesNo 38YesYes             Fiber opticNo                 ...No                 No                 No                 No                 Month-to-monthYesBank transfer (automatic)74.952869.85Yes\n    46994-KERXLMale  0No No  4YesNo              DSL        No                 ...No                 No                 No                 Yes                Month-to-monthYesElectronic check         55.90 238.50No \n    52181-UAESMMale  0No No  2YesNo              DSL        Yes                ...Yes                No                 No                 No                 Month-to-monthNo Electronic check         53.45 119.50No \n    64312-GVYNHFemale0YesNo 70No No phone serviceDSL        Yes                ...Yes                Yes                No                 Yes                Two year      YesBank transfer (automatic)49.853370.20No \n\n\n\n\n\n# You can also use startRow, endRow and other params to define how much data read\ndata <- read.xlsx(\"../../data/telecom_users.xlsx\", sheetIndex = 1, endRow = 100)\nhead(data)\n\n\n\nA data.frame: 6 × 21\n\n    customerIDgenderSeniorCitizenPartnerDependentstenurePhoneServiceMultipleLinesInternetServiceOnlineSecurity...DeviceProtectionTechSupportStreamingTVStreamingMoviesContractPaperlessBillingPaymentMethodMonthlyChargesTotalChargesChurn\n    <chr><chr><dbl><chr><chr><dbl><chr><chr><chr><chr>...<chr><chr><chr><chr><chr><chr><chr><dbl><dbl><chr>\n\n\n    17010-BRBUUMale  0YesYes72YesYes             No         No internet service...No internet serviceNo internet serviceNo internet serviceNo internet serviceTwo year      No Credit card (automatic)  24.101734.65No \n    29688-YGXVRFemale0No No 44YesNo              Fiber opticNo                 ...Yes                No                 Yes                No                 Month-to-monthYesCredit card (automatic)  88.153973.20No \n    39286-DOJGFFemale1YesNo 38YesYes             Fiber opticNo                 ...No                 No                 No                 No                 Month-to-monthYesBank transfer (automatic)74.952869.85Yes\n    46994-KERXLMale  0No No  4YesNo              DSL        No                 ...No                 No                 No                 Yes                Month-to-monthYesElectronic check         55.90 238.50No \n    52181-UAESMMale  0No No  2YesNo              DSL        Yes                ...Yes                No                 No                 No                 Month-to-monthNo Electronic check         53.45 119.50No \n    64312-GVYNHFemale0YesNo 70No No phone serviceDSL        Yes                ...Yes                Yes                No                 Yes                Two year      YesBank transfer (automatic)49.853370.20No \n\n\n\n\nLet’s replace Churn values Yes/No by 1/0:\n\nhead(data$Churn)\n\n\n'No''No''Yes''No''No''No'\n\n\n\ndata$Churn <- ifelse(data$Churn == \"Yes\", 1, 0)\n\n\nhead(data$Churn)\n\n\n001000\n\n\nWrite final data to excel:\n\nwrite.xlsx(data, file = \"../../data/final_telecom_data.xlsx\")\n\n\n\n4.2.1 Task 1\nDownload from kaggle.com and read dataset Default_Fin.csv: https://www.kaggle.com/kmldas/loan-default-prediction\nDescription:\nThis is a synthetic dataset created using actual data from a financial institution. The data has been modified to remove identifiable features and the numbers transformed to ensure they do not link to original source (financial institution).\nThis is intended to be used for academic purposes for beginners who want to practice financial analytics from a simple financial dataset\n\nIndex - This is the serial number or unique identifier of the loan taker\nEmployed - This is a Boolean 1= employed 0= unemployed\nBank.Balance - Bank Balance of the loan taker\nAnnual.Salary - Annual salary of the loan taker\n\nDefaulted - This is a Boolean 1= defaulted 0= not defaulted\n\n\nCheck what columns has missing values\nCount default and non-default clients / and parts of total clients in %\nCount Employed clients\nCount Employed Default clients\nAverage salary by Employed clients\nRename columns to “id”, “empl”, “balance”, “salary”, “default”\n\n\nSolution for Task 1\n\ndata <- read.csv(\"../../data/Default_Fin.csv\")\nhead(data)\n\n\n\nA data.frame: 6 × 5\n\n    IndexEmployedBank.BalanceAnnual.SalaryDefaulted.\n    <int><int><dbl><dbl><int>\n\n\n    111 8754.36532339.560\n    220 9806.16145273.560\n    33112882.60381205.680\n    441 6351.00428453.880\n    551 9427.92461562.000\n    66011035.08 89898.720\n\n\n\n\n\n\nCheck what columns has missing values\n\n\n\nanyNA(data)\n\nFALSE\n\n\n\n\nCount default and non-default clients / and parts of total clients in %\n\n\n\ndef_count <- nrow(data[data$Defaulted. == 1, ])\nno_def_count <- nrow(data[data$Defaulted. == 0, ])\ndef_count\nno_def_count \n\n333\n\n\n9667\n\n\n\ndef_count / nrow(data) * 100 # part defaults\nno_def_count / nrow(data) * 100 # part non-defaults\n\n3.33\n\n\n96.67\n\n\n\n\nCount Employed clients\n\n\n\nempl <- data[data$Employed == 1, ]\nnrow(empl)\n\n7056\n\n\n\n\nCount Employed Default clients\n\n\n\nempl <- data[data$Employed == 1 & data$Defaulted. == 1, ]\nnrow(empl)\n\n206\n\n\n\n\nAverage salary by Employed clients\n\n\n\nempl <- data[data$Employed == 1, ]\nmean(empl$Annual.Salary)\n\n480143.43414966\n\n\n\n\nRename columns to “id”, “empl”, “balance”, “salary”, “default”:\n\n\n\ncolnames(data) <- c(\"id\", \"empl\", \"balance\", \"salary\", \"default\")\nhead(data)\n\n\n\nA data.frame: 6 × 5\n\n    idemplbalancesalarydefault\n    <int><int><dbl><dbl><int>\n\n\n    111 8754.36532339.560\n    220 9806.16145273.560\n    33112882.60381205.680\n    441 6351.00428453.880\n    551 9427.92461562.000\n    66011035.08 89898.720"
  },
  {
    "objectID": "23-r-xml.html#xml-extensible-markup-language",
    "href": "23-r-xml.html#xml-extensible-markup-language",
    "title": "4  Data collection and saving",
    "section": "4.3 XML (eXtensible Markup Language)",
    "text": "4.3 XML (eXtensible Markup Language)\nFor our example we will use data from data/employes.xml. File contains records with info:\n<RECORDS>\n   <EMPLOYEE>\n      <ID>1</ID>\n      <NAME>Rick</NAME>\n      <SALARY>623.3</SALARY>\n      <STARTDATE>1/1/2012</STARTDATE>\n      <DEPT>IT</DEPT>\n   </EMPLOYEE>\n   ...\n</RECORDS>\n\n#install.packages(\"XML\")\nlibrary(\"XML\")\n#install.packages(\"methods\")\nlibrary(\"methods\")\n\n\nresult <- xmlParse(file = \"../../data/employes.xml\")\nprint(result)\n\n<?xml version=\"1.0\"?>\n<RECORDS>\n  <EMPLOYEE>\n    <ID>1</ID>\n    <NAME>Rick</NAME>\n    <SALARY>623.3</SALARY>\n    <STARTDATE>1/1/2012</STARTDATE>\n    <DEPT>IT</DEPT>\n  </EMPLOYEE>\n  <EMPLOYEE>\n    <ID>2</ID>\n    <NAME>Dan</NAME>\n    <SALARY>515.2</SALARY>\n    <STARTDATE>9/23/2013</STARTDATE>\n    <DEPT>Operations</DEPT>\n  </EMPLOYEE>\n  <EMPLOYEE>\n    <ID>3</ID>\n    <NAME>Michelle</NAME>\n    <SALARY>611</SALARY>\n    <STARTDATE>11/15/2014</STARTDATE>\n    <DEPT>IT</DEPT>\n  </EMPLOYEE>\n  <EMPLOYEE>\n    <ID>4</ID>\n    <NAME>Ryan</NAME>\n    <SALARY>729</SALARY>\n    <STARTDATE>5/11/2014</STARTDATE>\n    <DEPT>HR</DEPT>\n  </EMPLOYEE>\n  <EMPLOYEE>\n    <ID>5</ID>\n    <NAME>Gary</NAME>\n    <SALARY>843.25</SALARY>\n    <STARTDATE>3/27/2015</STARTDATE>\n    <DEPT>Finance</DEPT>\n  </EMPLOYEE>\n  <EMPLOYEE>\n    <ID>6</ID>\n    <NAME>Nina</NAME>\n    <SALARY>578</SALARY>\n    <STARTDATE>5/21/2013</STARTDATE>\n    <DEPT>IT</DEPT>\n  </EMPLOYEE>\n  <EMPLOYEE>\n    <ID>7</ID>\n    <NAME>Simon</NAME>\n    <SALARY>632.8</SALARY>\n    <STARTDATE>7/30/2013</STARTDATE>\n    <DEPT>Operations</DEPT>\n  </EMPLOYEE>\n  <EMPLOYEE>\n    <ID>8</ID>\n    <NAME>Guru</NAME>\n    <SALARY>722.5</SALARY>\n    <STARTDATE>6/17/2014</STARTDATE>\n    <DEPT>Finance</DEPT>\n  </EMPLOYEE>\n</RECORDS>\n \n\n\n\nrootnode <- xmlRoot(result) # reading rootnode of xml document\nrootnode[[1]] # reading first record\n\n<EMPLOYEE>\n  <ID>1</ID>\n  <NAME>Rick</NAME>\n  <SALARY>623.3</SALARY>\n  <STARTDATE>1/1/2012</STARTDATE>\n  <DEPT>IT</DEPT>\n</EMPLOYEE> \n\n\n\nrootnode[[1]][[2]] # reading first record in root node and second tag, its <NAME>\n\n<NAME>Rick</NAME> \n\n\nFor us the best way is to get dataframe:\n\nxmldataframe <- xmlToDataFrame(\"../../data/employes.xml\")\nxmldataframe\n\n\n\nA data.frame: 8 × 5\n\n    IDNAMESALARYSTARTDATEDEPT\n    <chr><chr><chr><chr><chr>\n\n\n    1Rick    623.3 1/1/2012  IT        \n    2Dan     515.2 9/23/2013 Operations\n    3Michelle611   11/15/2014IT        \n    4Ryan    729   5/11/2014 HR        \n    5Gary    843.253/27/2015 Finance   \n    6Nina    578   5/21/2013 IT        \n    7Simon   632.8 7/30/2013 Operations\n    8Guru    722.5 6/17/2014 Finance"
  },
  {
    "objectID": "23-r-xml.html#api-and-json",
    "href": "23-r-xml.html#api-and-json",
    "title": "4  Data collection and saving",
    "section": "4.4 API and JSON",
    "text": "4.4 API and JSON\nJSON (JavaScript Object Notation) is a lightweight data-interchange format. It is easy for humans to read and write. It is easy for machines to parse and generate. It is based on a subset of the JavaScript Programming Language Standard.\nAPI is the acronym for Application Programming Interface, which is a software intermediary that allows two applications to talk to each other.\nOne of the most popular packages for json is jsonlite.\n\n#install.packages(\"jsonlite\")\nlibrary(jsonlite)\n\nLet’s use readinginformation about BTC and USDT crypro currencies from Binance\n\nmarket = 'BTCUSDT'\ninterval = '1h'\nlimit = 100\n\nurl <- paste0(url = \"https://api.binance.com/api/v3/klines?symbol=\", market ,\"&interval=\", interval,\"&limit=\", limit)\nprint(url) # complete request URL\n\n[1] \"https://api.binance.com/api/v3/klines?symbol=BTCUSDT&interval=1h&limit=100\"\n\n\nOn the next stage you need use fromJSON() function to get data.\nMore details about requests to Binanace at https://github.com/binance/binance-spot-api-docs/blob/master/rest-api.md#klinecandlestick-data\nIf you enter ‘url’ value at browser response is going to be like this:\n[\n  [\n    1499040000000,      // Open time\n    \"0.01634790\",       // Open\n    \"0.80000000\",       // High\n    \"0.01575800\",       // Low\n    \"0.01577100\",       // Close\n    \"148976.11427815\",  // Volume\n    1499644799999,      // Close time\n    \"2434.19055334\",    // Quote asset volume\n    308,                // Number of trades\n    \"1756.87402397\",    // Taker buy base asset volume\n    \"28.46694368\",      // Taker buy quote asset volume\n    \"17928899.62484339\" // Ignore.\n  ]\n]\n\ndata <- fromJSON(url) # get json and transform it to list()\ndata <- data[, 1:7] # let's left only 1:7 columns (from Open time to Close time)\nhead(data)\n\n\n\nA matrix: 6 × 7 of type chr\n\n    165051360000041693.5800000041750.0000000041525.0000000041610.010000001138.643370001650517199999\n    165051720000041610.0100000041699.0000000041434.4400000041462.760000001229.259360001650520799999\n    165052080000041462.7500000041600.0000000041419.2000000041522.380000001049.712440001650524399999\n    165052440000041522.3800000041940.0000000041451.0000000041855.690000001928.480910001650527999999\n    1.650528e+12 41855.6900000042050.3000000041741.1000000041922.970000002518.040900001650531599999\n    165053160000041922.9600000041971.9000000041743.9600000041803.700000001655.769930001650535199999\n\n\n\n\n\ntypeof(data) # check data type\ndata <- as.data.frame(data) # convert to dataframe\nhead(data)\n\n'character'\n\n\n\n\nA data.frame: 6 × 7\n\n    V1V2V3V4V5V6V7\n    <chr><chr><chr><chr><chr><chr><chr>\n\n\n    1165051360000041693.5800000041750.0000000041525.0000000041610.010000001138.643370001650517199999\n    2165051720000041610.0100000041699.0000000041434.4400000041462.760000001229.259360001650520799999\n    3165052080000041462.7500000041600.0000000041419.2000000041522.380000001049.712440001650524399999\n    4165052440000041522.3800000041940.0000000041451.0000000041855.690000001928.480910001650527999999\n    51.650528e+12 41855.6900000042050.3000000041741.1000000041922.970000002518.040900001650531599999\n    6165053160000041922.9600000041971.9000000041743.9600000041803.700000001655.769930001650535199999\n\n\n\n\n\n# fix columns names\ncolnames(data) <- c(\"Open_time\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\", \"Close_time\")\nhead(data) # looks better, but columns are characters still\n\n\n\nA data.frame: 6 × 7\n\n    Open_timeOpenHighLowCloseVolumeClose_time\n    <chr><chr><chr><chr><chr><chr><chr>\n\n\n    1165051360000041693.5800000041750.0000000041525.0000000041610.010000001138.643370001650517199999\n    2165051720000041610.0100000041699.0000000041434.4400000041462.760000001229.259360001650520799999\n    3165052080000041462.7500000041600.0000000041419.2000000041522.380000001049.712440001650524399999\n    4165052440000041522.3800000041940.0000000041451.0000000041855.690000001928.480910001650527999999\n    51.650528e+12 41855.6900000042050.3000000041741.1000000041922.970000002518.040900001650531599999\n    6165053160000041922.9600000041971.9000000041743.9600000041803.700000001655.769930001650535199999\n\n\n\n\n\nis.numeric(data[,1]) # check 1st column type is numeric\nis.numeric(data[,2]) # check 2nd column type is numeric\n\nFALSE\n\n\nFALSE\n\n\n\ndata <- as.data.frame(sapply(data, as.numeric)) # convert all columns to numeric\nhead(data) # good, its double now\n\n\n\nA data.frame: 6 × 7\n\n    Open_timeOpenHighLowCloseVolumeClose_time\n    <dbl><dbl><dbl><dbl><dbl><dbl><dbl>\n\n\n    11.650514e+1241693.5841750.041525.0041610.011138.6431.650517e+12\n    21.650517e+1241610.0141699.041434.4441462.761229.2591.650521e+12\n    31.650521e+1241462.7541600.041419.2041522.381049.7121.650524e+12\n    41.650524e+1241522.3841940.041451.0041855.691928.4811.650528e+12\n    51.650528e+1241855.6942050.341741.1041922.972518.0411.650532e+12\n    61.650532e+1241922.9641971.941743.9641803.701655.7701.650535e+12\n\n\n\n\nFinal stage is to convert Open_time and Close_time to dates.\n\ndata$Open_time <- as.POSIXct(data$Open_time/1e3, origin = '1970-01-01')\ndata$Close_time <- as.POSIXct(data$Close_time/1e3, origin = '1970-01-01')\n\nhead(data) \n\n\n\nA data.frame: 6 × 7\n\n    Open_timeOpenHighLowCloseVolumeClose_time\n    <dttm><dbl><dbl><dbl><dbl><dbl><dttm>\n\n\n    12022-04-21 07:00:0041693.5841750.041525.0041610.011138.6432022-04-21 07:59:59\n    22022-04-21 08:00:0041610.0141699.041434.4441462.761229.2592022-04-21 08:59:59\n    32022-04-21 09:00:0041462.7541600.041419.2041522.381049.7122022-04-21 09:59:59\n    42022-04-21 10:00:0041522.3841940.041451.0041855.691928.4812022-04-21 10:59:59\n    52022-04-21 11:00:0041855.6942050.341741.1041922.972518.0412022-04-21 11:59:59\n    62022-04-21 12:00:0041922.9641971.941743.9641803.701655.7702022-04-21 12:59:59\n\n\n\n\n\ntail(data) # check last records\n\n\n\nA data.frame: 6 × 7\n\n    Open_timeOpenHighLowCloseVolumeClose_time\n    <dttm><dbl><dbl><dbl><dbl><dbl><dttm>\n\n\n    952022-04-25 05:00:0039095.8139153.9438961.6439091.171205.51582022-04-25 05:59:59\n    962022-04-25 06:00:0039091.1739294.7639086.3739253.711443.33182022-04-25 06:59:59\n    972022-04-25 07:00:0039253.7039256.2839055.7139139.74 896.85542022-04-25 07:59:59\n    982022-04-25 08:00:0039139.7439230.5038947.4238975.221057.49002022-04-25 08:59:59\n    992022-04-25 09:00:0038975.2139057.9738590.0038636.352814.97162022-04-25 09:59:59\n    1002022-04-25 10:00:0038636.3538675.6838200.0038534.993528.23552022-04-25 10:59:59"
  },
  {
    "objectID": "23-r-xml.html#google-services",
    "href": "23-r-xml.html#google-services",
    "title": "4  Data collection and saving",
    "section": "4.5 Google Services",
    "text": "4.5 Google Services\n\n4.5.1 Google Spreadsheets\n\nTHIS CHAPTER IS UNDER CONSTRUCTION / Working with Google Spreadsheets need account authorization.\n\ngooglesheets4 is a package to work with Google Sheets from R.\n\n#install.packages(\"googlesheets4\")\nlibrary(googlesheets4)\n\nYou can read google documents after authentification on google service. There is sample code:\nread_sheet(\"https://docs.google.com/spreadsheets/d/1U6Cf_qEOhiR9AZqTqS3mbMF3zt2db48ZP5v3rkrAEJY/edit#gid=780868077\")\ngs4_deauth()\nLet’s read sample dataset gapminder. It detailed described in next paragraph.\n\n# gs4_example(\"gapminder\")\n\n\n\n\n4.5.2 Google Search Trends\nGoogle Trends is a service for analyzing search requests by many filters like region (continent, country, locality), period (year, month), information category (business, education, hobby, healthcare), information type (news, shopping, video, images) https://trends.google.com/trends/\n\n# install.packages('gtrendsR')\n# install.packages('ggplot2')\nlibrary(gtrendsR) # loading package for Google Trends queries\nlibrary(ggplot2)\n\nLet’s configure out google trends query params\n\nkeywords = c(\"Bitcoin\", \"FC Barcelona\") # search keywords\ncountry = c('AT') # search region from https://support.google.com/business/answer/6270107?hl=en\ntime = (\"2021-01-01 2021-06-01\") # period\nchannel = 'web' # search channel: google search ('news' - google news, 'images' - google images)\n\n\n# query\ntrends = gtrends(keywords, gprop = channel, geo = country, time = time, tz = \"UTC\")\n\n\ntime_trend = trends$interest_over_time\nhead(time_trend)\n\n\n\nA data.frame: 6 × 7\n\n    datehitskeywordgeotimegpropcategory\n    <dttm><chr><chr><chr><chr><chr><int>\n\n\n    12021-01-0136BitcoinAT2021-01-01 2021-06-01web0\n    22021-01-0267BitcoinAT2021-01-01 2021-06-01web0\n    32021-01-0374BitcoinAT2021-01-01 2021-06-01web0\n    42021-01-0457BitcoinAT2021-01-01 2021-06-01web0\n    52021-01-0553BitcoinAT2021-01-01 2021-06-01web0\n    62021-01-0666BitcoinAT2021-01-01 2021-06-01web0\n\n\n\n\n\nplot <- ggplot(data=time_trend, aes(x=date, y=hits, group=keyword, col=keyword)) +\n  geom_line() +\n  xlab('Time') + \n  ylab('Relative Interest') + \n  theme(legend.title = element_blank(), legend.position=\"bottom\", legend.text=element_text(size=15)) + \n  ggtitle(\"Google Search Volume\")  \n\nplot"
  },
  {
    "objectID": "23-r-xml.html#sql-with-sqlite-sample",
    "href": "23-r-xml.html#sql-with-sqlite-sample",
    "title": "4  Data collection and saving",
    "section": "4.6 SQL (with SQLite sample)",
    "text": "4.6 SQL (with SQLite sample)\nWe are going to review working with database on SQLite, becouse it allows us not to install DB-server and start working with simple file.\nFor now we will use RSQLite package.\n\n# install.packages(\"RSQLite\")\nlibrary(RSQLite)\n\n\n# let's use mtcars dataset\n\ndata(\"mtcars\") # loads the data\nhead(mtcars) # preview the data\n\n\n\nA data.frame: 6 × 11\n\n    mpgcyldisphpdratwtqsecvsamgearcarb\n    <dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl>\n\n\n    Mazda RX421.061601103.902.62016.460144\n    Mazda RX4 Wag21.061601103.902.87517.020144\n    Datsun 71022.84108 933.852.32018.611141\n    Hornet 4 Drive21.462581103.083.21519.441031\n    Hornet Sportabout18.783601753.153.44017.020032\n    Valiant18.162251052.763.46020.221031\n\n\n\n\n\nI need this code for book successful building (remove database file if exists):\n\n\n#Define the file name that will be deleted\nfn <- paste0(\"../../data/cars.sqlite\")\n#Check its existence\nif (file.exists(fn)) {\n  #Delete file if it exists\n  file.remove(fn)\n}\n\nTRUE\n\n\nNow, let’s create new:\n\n# create new db file\ndb_path = paste0(\"../../data/cars.sqlite\")\n# create connection\nconn <- dbConnect(RSQLite::SQLite(), \n                    db_path,\n                    overwrite = TRUE, append = FALSE) # for lecture content only\n\n\n# Write the mtcars dataset into a table names mtcars_data\ndbWriteTable(conn, \"cars_table\", mtcars)\n# List all the tables available in the database\ndbListTables(conn)\n\n\n'cars_table'\n\n\n\ntable_data <- dbGetQuery(conn, \"SELECT * FROM cars_table\")\nhead(table_data)\n\n\n\nA data.frame: 6 × 11\n\n    mpgcyldisphpdratwtqsecvsamgearcarb\n    <dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl>\n\n\n    121.061601103.902.62016.460144\n    221.061601103.902.87517.020144\n    322.84108 933.852.32018.611141\n    421.462581103.083.21519.441031\n    518.783601753.153.44017.020032\n    618.162251052.763.46020.221031\n\n\n\n\n\n# close connection\ndbDisconnect(conn)\n\nYou can write complex queries for many tables if you knowledge of SQL allows."
  },
  {
    "objectID": "23-r-xml.html#web-pages-html",
    "href": "23-r-xml.html#web-pages-html",
    "title": "4  Data collection and saving",
    "section": "4.7 Web-pages (HTML)",
    "text": "4.7 Web-pages (HTML)\nSometimes decision making needs scrap data from web sources and pages.\nLet’s try to parse data from Wikipedia as table.\n\n#install.packages(\"rvest\")\nlibrary(rvest) # Parsing of HTML/XML files\n\nGo to web page https://en.wikipedia.org/wiki/List_of_largest_banks and check it.\n\n# fix URL\nurl <- \"https://en.wikipedia.org/wiki/List_of_largest_banks\"\n#url <- \"data/List of largest banks - Wikipedia_.html\"\n\n\n# read html content of the page\npage <- read_html(url)\npage\n\n{html_document}\n<html class=\"client-nojs\" lang=\"en\" dir=\"ltr\">\n[1] <head>\\n<meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8 ...\n[2] <body class=\"mediawiki ltr sitedir-ltr mw-hide-empty-elt ns-0 ns-subject  ...\n\n\n\n# read all yables on page\ntables <- html_nodes(page, \"table\")\ntables\n\n{xml_nodeset (4)}\n[1] <table class=\"box-Missing_information plainlinks metadata ambox ambox-con ...\n[2] <table class=\"wikitable sortable mw-collapsible\"><tbody>\\n<tr>\\n<th data- ...\n[3] <table class=\"wikitable sortable mw-collapsible\">\\n<caption>Number of ban ...\n[4] <table class=\"wikitable sortable mw-collapsible\"><tbody>\\n<tr>\\n<th data- ...\n\n\nFor now, let’s read a table of Total Assets in US Billion\n\n# with pipe operator\n#tables[2] %>% \n #   html_table(fill = TRUE) %>% \n #   as.data.frame()\n#without pipe operator\nassets_table <- as.data.frame(html_table(tables[2], fill = TRUE))   \nhead(assets_table)\n\n\n\nA data.frame: 6 × 3\n\n    RankBank.nameTotal.assets.2020..US..billion.\n    <int><chr><chr>\n\n\n    11Industrial and Commercial Bank of China5,518.00\n    22China Construction Bank                4,400.00\n    33Agricultural Bank of China             4,300.00\n    44Bank of China                          4,200.00\n    55JPMorgan Chase                         3,831.65\n    66Mitsubishi UFJ Financial Group         3,175.21\n\n\n\n\nNext is reading data of market capitalization table (4th):\n\ncapital_table <- as.data.frame(html_table(tables[4], fill = TRUE))   \nhead(capital_table)\n\n\n\nA data.frame: 6 × 3\n\n    RankBank.nameMarket.cap.US..billion.\n    <int><chr><dbl>\n\n\n    11JPMorgan Chase                         368.78\n    22Industrial and Commercial Bank of China295.65\n    33Bank of America                        279.73\n    44Wells Fargo                            214.34\n    55China Construction Bank                207.98\n    66Agricultural Bank of China             181.49\n\n\n\n\nAnd now let’s merge() this two datasets:\n\nmerged_data <- merge(assets_table, capital_table, by = \"Bank.name\")\nhead(merged_data)\n\n\n\nA data.frame: 6 × 5\n\n    Bank.nameRank.xTotal.assets.2020..US..billion.Rank.yMarket.cap.US..billion.\n    <chr><int><chr><int><dbl>\n\n\n    1Agricultural Bank of China              34,300.00 6181.49\n    2Australia and New Zealand Banking Group48661.72  26 54.88\n    3Banco Bilbao Vizcaya Argentaria        42782.16  37 37.42\n    4Banco Bradesco                         79345.21  18 74.67\n    5Banco Santander                        161,702.6117 75.47\n    6Bank of America                         82,434.08 3279.73\n\n\n\n\n\n4.7.1 Task 3\nFrom a page https://en.wikipedia.org/wiki/List_of_largest_banks read and merge by country named tables:\n\nNumber of banks in the top 100 by total assets\nTotal market capital (US$ billion) across the top 70 banks by country\n\nSolution\n\nlibrary(rvest)\nurl <- \"https://en.wikipedia.org/wiki/List_of_largest_banks\" # got to url in other tab\n#url <- \"data/List of largest banks - Wikipedia_.html\"\npage_data <- read_html(url) # read html content\n\ntables <- html_nodes(page_data, \"table\")\nhtml_table(tables[1]) #its not needed table\n\n\n\n    \nA tibble: 1  2\n\n    X1X2\n    <lgl><chr>\n\n\n    NAThis article is missing information about Revenue and Employment. Please expand the article to include this information. Further details may exist on the talk page.  (September 2020)\n\n\n\n\n\n\n\nhtml_table(tables[3]) # thats solution for \"Number of banks in the top 100 by total assets\"\n#check the end of table. There are NA record\n# lets remove it\n\n\n\n    \nA tibble: 26  3\n\n    RankCountryNumber\n    <int><chr><int>\n\n\n    1China         19\n    2United States 11\n    3Japan          8\n    4United Kingdom 6\n    4France         6\n    4South Korea    6\n    5Canada         5\n    5Germany        5\n    6Australia      4\n    6Brazil         4\n    6Spain          4\n    7Netherlands    3\n    7Singapore      3\n    7Sweden         3\n    7Switzerland    3\n    8Italy          2\n    9India          1\n    9Austria        1\n    9Belgium        1\n    9Denmark        1\n    9Finland        1\n    9Norway         1\n    9Russia         1\n    9Qatar          1\n    9NA            NA\n    9NA            NA\n\n\n\n\n\n\n\ntable1 <- as.data.frame(html_table(tables[3]))\ntable1 <- table1[!is.na(table1$Country), ]\ntable1 # now it OK!\n\n\n\nA data.frame: 24 × 3\n\n    RankCountryNumber\n    <int><chr><int>\n\n\n    11China         19\n    22United States 11\n    33Japan          8\n    44United Kingdom 6\n    54France         6\n    64South Korea    6\n    75Canada         5\n    85Germany        5\n    96Australia      4\n    106Brazil         4\n    116Spain          4\n    127Netherlands    3\n    137Singapore      3\n    147Sweden         3\n    157Switzerland    3\n    168Italy          2\n    179India          1\n    189Austria        1\n    199Belgium        1\n    209Denmark        1\n    219Finland        1\n    229Norway         1\n    239Russia         1\n    249Qatar          1\n\n\n\n\n\n# SOlution for \"Total market capital (US$ billion) across the top 70 banks by country\"\n# compare this with table on a given page\ntable2 <- as.data.frame(html_table(tables[4]))\ntable2 # now it OK!\n\n\n\nA data.frame: 50 × 3\n\n    RankBank.nameMarket.cap.US..billion.\n    <int><chr><dbl>\n\n\n     1JPMorgan Chase                         368.78\n     2Industrial and Commercial Bank of China295.65\n     3Bank of America                        279.73\n     4Wells Fargo                            214.34\n     5China Construction Bank                207.98\n     6Agricultural Bank of China             181.49\n     7HSBC Holdings PLC                      169.47\n     8Citigroup Inc.                         163.58\n     9Bank of China                          151.15\n    10China Merchants Bank                   133.37\n    11Royal Bank of Canada                   113.80\n    12Toronto-Dominion Bank                  106.61\n    13Commonwealth Bank                       99.77\n    14HDFC Bank                              105.90\n    15U.S. Bancorp                            84.40\n    16Goldman Sachs                           78.70\n    17Banco Santander                         75.47\n    18Banco Bradesco                          74.67\n    19Morgan Stanley                          73.93\n    20Westpac                                 67.84\n    21Mitsubishi UFJ Financial Group          66.20\n    22Scotiabank                              65.48\n    23PNC Financial Services                  63.11\n    24Bank of Communications                  61.85\n    25BNP Paribas                             59.36\n    26Australia and New Zealand Banking Group 54.88\n    27National Australia Bank                 51.68\n    28Lloyds Banking Group                    51.19\n    29Sumitomo Mitsui Financial Group         49.85\n    30Bank of Montreal                        48.12\n    31UBS                                     45.92\n    32ING Group                               44.97\n    33Capital One                             43.22\n    34The Bank of New York Mellon             42.58\n    35China Minsheng Bank                     39.13\n    36China CITIC Bank                        38.55\n    37Banco Bilbao Vizcaya Argentaria         37.42\n    38Mizuho Financial Group                  36.95\n    39Intesa Sanpaolo                         36.90\n    40Credit Agricole                         34.89\n    41Canadian Imperial Bank of Commerce      34.87\n    42Royal Bank of Scotland                  33.95\n    43Barclays                                33.26\n    44Credit Suisse                           30.75\n    45Nordea                                  29.59\n    46Standard Chartered                      29.37\n    47KBC Bank                                27.40\n    48UniCredit                               26.88\n    49Societe Generale                        21.27\n    50Deutsche Bank                           15.77"
  },
  {
    "objectID": "23-r-xml.html#набори-даних",
    "href": "23-r-xml.html#набори-даних",
    "title": "4  Data collection and saving",
    "section": "4.8 Набори даних",
    "text": "4.8 Набори даних\n\nhttps://github.com/kleban/r-book-published/tree/main/datasets/telecom_users.csv\nhttps://github.com/kleban/r-book-published/tree/main/datasets/telecom_sers.xlsx\nhttps://github.com/kleban/r-book-published/tree/main/datasets/Default_Fin.csv\nhttps://github.com/kleban/r-book-published/tree/main/datasets/employes.xml"
  },
  {
    "objectID": "23-r-xml.html#references",
    "href": "23-r-xml.html#references",
    "title": "4  Data collection and saving",
    "section": "4.9 References",
    "text": "4.9 References\n\nSQLite in R. Datacamp\nTidyverse googlesheets4 0.2.0 \nBinanace spot Api Docs\nWeb Scraping in R: rvest Tutorial by Arvid Kingl"
  },
  {
    "objectID": "22-r-csv.html#what-is-csv-comma-separated-values",
    "href": "22-r-csv.html#what-is-csv-comma-separated-values",
    "title": "3  CSV",
    "section": "3.1 What is CSV (Comma Separated Values)?",
    "text": "3.1 What is CSV (Comma Separated Values)?\nCSV - comma separated values.\n\n# lets check current working directory to write correct files path\ngetwd()\n\n'E:/Repos/Season 2022/r-book/_book/docs/data-analysis-en'\n\n\nYou can use / or \\\\ for writing correct path in R. For example:\n\npath = \"d:/projects/file.csv\"\npath = \"d:\\\\projects\\\\file.csv\"\n\nTo combine path use paste() or paste0() functions\n\nwork_dir = getwd()\nwork_dir \n\n'E:/Repos/Season 2022/r-book/_book/docs/data-analysis-en'\n\n\n\nfile_name = \"temp_file.csv\"\nfile_path = paste0(work_dir, \"/\", file_name)\nfile_path\n\n'E:/Repos/Season 2022/r-book/_book/docs/data-analysis-en/temp_file.csv'\n\n\n\nfile_path = paste(work_dir, file_name, sep = \"/\")\nfile_path\n\n'E:/Repos/Season 2022/r-book/_book/docs/data-analysis-en/temp_file.csv'"
  },
  {
    "objectID": "22-r-csv.html#sample-dataset-description",
    "href": "22-r-csv.html#sample-dataset-description",
    "title": "3  CSV",
    "section": "3.2 Sample dataset description",
    "text": "3.2 Sample dataset description\nInformation about dataset from kaggle.com. Original file located at url: https://www.kaggle.com/radmirzosimov/telecom-users-dataset.\nAny business wants to maximize the number of customers. To achieve this goal, it is important not only to try to attract new ones, but also to retain existing ones. Retaining a client will cost the company less than attracting a new one. In addition, a new client may be weakly interested in business services and it will be difficult to work with him, while old clients already have the necessary data on interaction with the service.\nAccordingly, predicting the churn, we can react in time and try to keep the client who wants to leave. Based on the data about the services that the client uses, we can make him a special offer, trying to change his decision to leave the operator. This will make the task of retention easier to implement than the task of attracting new users, about which we do not know anything yet.\nYou are provided with a dataset from a telecommunications company. The data contains information about almost six thousand users, their demographic characteristics, the services they use, the duration of using the operator’s services, the method of payment, and the amount of payment.\nThe task is to analyze the data and predict the churn of users (to identify people who will and will not renew their contract). The work should include the following mandatory items:\n\nDescription of the data (with the calculation of basic statistics);\nResearch of dependencies and formulation of hypotheses;\nBuilding models for predicting the outflow (with justification for the choice of a particular model) 4. based on tested hypotheses and identified relationships;\nComparison of the quality of the obtained models.\n\nFields description:\n\ncustomerID - customer id\ngender - client gender (male / female)\nSeniorCitizen - is the client retired (1, 0)\nPartner - is the client married (Yes, No)\ntenure - how many months a person has been a client of the company\nPhoneService - is the telephone service connected (Yes, No)\nMultipleLines - are multiple phone lines connected (Yes, No, No phone service)\nInternetService - client’s Internet service provider (DSL, Fiber optic, No)\nOnlineSecurity - is the online security service connected (Yes, No, No internet service)\nOnlineBackup - is the online backup service activated (Yes, No, No internet service)\nDeviceProtection - does the client have equipment insurance (Yes, No, No internet service)\nTechSupport - is the technical support service connected (Yes, No, No internet service)\nStreamingTV - is the streaming TV service connected (Yes, No, No internet service)\nStreamingMovies - is the streaming cinema service activated (Yes, No, No internet service)\nContract - type of customer contract (Month-to-month, One year, Two year)\nPaperlessBilling - whether the client uses paperless billing (Yes, No)\nPaymentMethod - payment method (Electronic check, Mailed check, Bank transfer (automatic), Credit card (automatic))\nMonthlyCharges - current monthly payment\nTotalCharges - the total amount that the client paid for the services for the entire time\nChurn - whether there was a churn (Yes or No)"
  },
  {
    "objectID": "22-r-csv.html#reading",
    "href": "22-r-csv.html#reading",
    "title": "3  CSV",
    "section": "3.3 Reading",
    "text": "3.3 Reading\nThare are few methods for reading/writing csv in base package:\n\nread.csv(), write.csv - default data separator is ,, decimal is separator ..\nread.csv2(), write.csv2 - default data separator is ;, decimal is separator ,.\n\nBefore using any new function check it usage information with help(function_name) or ?function_name, example: ?read.csv.\nYou can read (current data set has NA values as example, there are no NA in original datase):\n\ndata <- read.csv(\"../../data/telecom_users.csv\") # default reading\nstr(data)\n\n'data.frame':   5986 obs. of  22 variables:\n $ X               : int  1869 4528 6344 6739 432 2215 5260 6001 1480 5137 ...\n $ customerID      : chr  \"7010-BRBUU\" \"9688-YGXVR\" \"9286-DOJGF\" \"6994-KERXL\" ...\n $ gender          : chr  \"Male\" \"Female\" \"Female\" \"Male\" ...\n $ SeniorCitizen   : int  0 0 1 0 0 0 0 0 0 1 ...\n $ Partner         : chr  \"Yes\" \"No\" \"Yes\" \"No\" ...\n $ Dependents      : chr  \"Yes\" \"No\" \"No\" \"No\" ...\n $ tenure          : int  72 44 38 4 2 70 33 1 39 55 ...\n $ PhoneService    : chr  \"Yes\" \"Yes\" \"Yes\" \"Yes\" ...\n $ MultipleLines   : chr  \"Yes\" \"No\" \"Yes\" \"No\" ...\n $ InternetService : chr  \"No\" \"Fiber optic\" \"Fiber optic\" \"DSL\" ...\n $ OnlineSecurity  : chr  \"No internet service\" \"No\" \"No\" \"No\" ...\n $ OnlineBackup    : chr  \"No internet service\" \"Yes\" \"No\" \"No\" ...\n $ DeviceProtection: chr  \"No internet service\" \"Yes\" \"No\" \"No\" ...\n $ TechSupport     : chr  \"No internet service\" \"No\" \"No\" \"No\" ...\n $ StreamingTV     : chr  \"No internet service\" \"Yes\" \"No\" \"No\" ...\n $ StreamingMovies : chr  \"No internet service\" \"No\" \"No\" \"Yes\" ...\n $ Contract        : chr  \"Two year\" \"Month-to-month\" \"Month-to-month\" \"Month-to-month\" ...\n $ PaperlessBilling: chr  \"No\" \"Yes\" \"Yes\" \"Yes\" ...\n $ PaymentMethod   : chr  \"Credit card (automatic)\" \"Credit card (automatic)\" \"Bank transfer (automatic)\" \"Electronic check\" ...\n $ MonthlyCharges  : chr  \"24.1\" \"88.15\" \"74.95\" \"55.9\" ...\n $ TotalCharges    : num  1735 3973 2870 238 120 ...\n $ Churn           : chr  \"No\" \"No\" \"Yes\" \"No\" ...\n\n\n\ndata <- read.csv(\"../../data/telecom_users.csv\",\n                  sep = \",\", # comma not only possibel separator\n                  dec = \".\", # decimal separator can be different\n                  na.strings = c(\"\", \"NA\", \"NULL\")) # you can define NA values\n\n\nstr(data) # chack data structure / types/ values\n\n'data.frame':   5986 obs. of  22 variables:\n $ X               : int  1869 4528 6344 6739 432 2215 5260 6001 1480 5137 ...\n $ customerID      : chr  \"7010-BRBUU\" \"9688-YGXVR\" \"9286-DOJGF\" \"6994-KERXL\" ...\n $ gender          : chr  \"Male\" \"Female\" \"Female\" \"Male\" ...\n $ SeniorCitizen   : int  0 0 1 0 0 0 0 0 0 1 ...\n $ Partner         : chr  \"Yes\" \"No\" \"Yes\" \"No\" ...\n $ Dependents      : chr  \"Yes\" \"No\" \"No\" \"No\" ...\n $ tenure          : int  72 44 38 4 2 70 33 1 39 55 ...\n $ PhoneService    : chr  \"Yes\" \"Yes\" \"Yes\" \"Yes\" ...\n $ MultipleLines   : chr  \"Yes\" \"No\" \"Yes\" \"No\" ...\n $ InternetService : chr  \"No\" \"Fiber optic\" \"Fiber optic\" \"DSL\" ...\n $ OnlineSecurity  : chr  \"No internet service\" \"No\" \"No\" \"No\" ...\n $ OnlineBackup    : chr  \"No internet service\" \"Yes\" \"No\" \"No\" ...\n $ DeviceProtection: chr  \"No internet service\" \"Yes\" \"No\" \"No\" ...\n $ TechSupport     : chr  \"No internet service\" \"No\" \"No\" \"No\" ...\n $ StreamingTV     : chr  \"No internet service\" \"Yes\" \"No\" \"No\" ...\n $ StreamingMovies : chr  \"No internet service\" \"No\" \"No\" \"Yes\" ...\n $ Contract        : chr  \"Two year\" \"Month-to-month\" \"Month-to-month\" \"Month-to-month\" ...\n $ PaperlessBilling: chr  \"No\" \"Yes\" \"Yes\" \"Yes\" ...\n $ PaymentMethod   : chr  \"Credit card (automatic)\" \"Credit card (automatic)\" \"Bank transfer (automatic)\" \"Electronic check\" ...\n $ MonthlyCharges  : num  24.1 88.2 75 55.9 53.5 ...\n $ TotalCharges    : num  1735 3973 2870 238 120 ...\n $ Churn           : chr  \"No\" \"No\" \"Yes\" \"No\" ...\n\n\n\nhead(data, 2) # top 6 rows, use n = X, for viewing top X lines\n\n\n\nA data.frame: 2 × 22\n\n    XcustomerIDgenderSeniorCitizenPartnerDependentstenurePhoneServiceMultipleLinesInternetService...DeviceProtectionTechSupportStreamingTVStreamingMoviesContractPaperlessBillingPaymentMethodMonthlyChargesTotalChargesChurn\n    <int><chr><chr><int><chr><chr><int><chr><chr><chr>...<chr><chr><chr><chr><chr><chr><chr><dbl><dbl><chr>\n\n\n    118697010-BRBUUMale  0YesYes72YesYesNo         ...No internet serviceNo internet serviceNo internet serviceNo internet serviceTwo year      No Credit card (automatic)24.101734.65No\n    245289688-YGXVRFemale0No No 44YesNo Fiber optic...Yes                No                 Yes                No                 Month-to-monthYesCredit card (automatic)88.153973.20No\n\n\n\n\n\nis.data.frame(data) # if data is data.frame\n\nTRUE\n\n\n\nanyNA(data) # if dataframe contains any NA values\n\nTRUE\n\n\n\nlapply(data, anyNA)\n#lapply(, any) #check NA by 2nd dimension - columns\n\n\n    $X\n        FALSE\n    $customerID\n        FALSE\n    $gender\n        FALSE\n    $SeniorCitizen\n        FALSE\n    $Partner\n        FALSE\n    $Dependents\n        FALSE\n    $tenure\n        FALSE\n    $PhoneService\n        FALSE\n    $MultipleLines\n        FALSE\n    $InternetService\n        FALSE\n    $OnlineSecurity\n        FALSE\n    $OnlineBackup\n        FALSE\n    $DeviceProtection\n        FALSE\n    $TechSupport\n        FALSE\n    $StreamingTV\n        FALSE\n    $StreamingMovies\n        FALSE\n    $Contract\n        FALSE\n    $PaperlessBilling\n        FALSE\n    $PaymentMethod\n        FALSE\n    $MonthlyCharges\n        TRUE\n    $TotalCharges\n        TRUE\n    $Churn\n        FALSE\n\n\n\nCheck MonthlyCharges: TRUE and TotalCharges: TRUE. These columns has NA-values.\nLet’s replace them with mean:\n\ndata[is.na(data$TotalCharges), \"TotalCharges\"] <- mean(data$TotalCharges, na.rm = T)\ndata[is.na(data$MonthlyCharges), \"MonthlyCharges\"] <- mean(data$MonthlyCharges, na.rm = T)\n\n\nany(is.na(data)) # check for NA\n\nFALSE\n\n\nYou can write data with write.csv(), write.csv2() from base package.\n\nwrite.csv(data, file = \"../../data/cleaned_data.csv\", row.names = F)\n# by default row.names = TRUE and file will contain first column with row numbers 1,2, ..., N\n\nERROR: Error in as.data.frame.default(x[[i]], optional = TRUE): cannot coerce class '\"function\"' to a data.frame"
  },
  {
    "objectID": "22-r-csv.html#readr-package",
    "href": "22-r-csv.html#readr-package",
    "title": "3  CSV",
    "section": "3.4 readr package",
    "text": "3.4 readr package\nOne more useful package is readr. Examples of using:\n\n# library(readr)\n# data <- read_csv(file = \"../../data/telecom_users.csv\")\n# data <- read_csv2(file = \"../../data/telecom_users.csv\")`"
  },
  {
    "objectID": "23-r-xlsx.html",
    "href": "23-r-xlsx.html",
    "title": "4  MS Excel (xlsx)",
    "section": "",
    "text": "You need this packages for code execution:"
  },
  {
    "objectID": "23-r-xlsx.html#xlsx-format",
    "href": "23-r-xlsx.html#xlsx-format",
    "title": "4  MS Excel (xlsx)",
    "section": "4.1 XLSX-format",
    "text": "4.1 XLSX-format\nThere are many packages to read/write MS Excel files. xlsx one of the most useful.\n\n# install.packages(\"xlsx\") #install before use it\n\n\nlibrary(xlsx)\n\n\nany(grepl(\"xlsx\", installed.packages())) # check if package installed\n\nTRUE\n\n\n?read.xlsx - review package functions and params\nLet’s read the data telecom_users.xlsx:\n\ndata <- read.xlsx(\"../../data/telecom_users.xlsx\", sheetIndex = 1)\n# sheetIndex = 1 - select sheet to read, or use sheetName = \"sheet1\" to read by Name\nhead(data)\n\n\n\nA data.frame: 6 × 21\n\n    customerIDgenderSeniorCitizenPartnerDependentstenurePhoneServiceMultipleLinesInternetServiceOnlineSecurity...DeviceProtectionTechSupportStreamingTVStreamingMoviesContractPaperlessBillingPaymentMethodMonthlyChargesTotalChargesChurn\n    <chr><chr><dbl><chr><chr><dbl><chr><chr><chr><chr>...<chr><chr><chr><chr><chr><chr><chr><dbl><dbl><chr>\n\n\n    17010-BRBUUMale  0YesYes72YesYes             No         No internet service...No internet serviceNo internet serviceNo internet serviceNo internet serviceTwo year      No Credit card (automatic)  24.101734.65No \n    29688-YGXVRFemale0No No 44YesNo              Fiber opticNo                 ...Yes                No                 Yes                No                 Month-to-monthYesCredit card (automatic)  88.153973.20No \n    39286-DOJGFFemale1YesNo 38YesYes             Fiber opticNo                 ...No                 No                 No                 No                 Month-to-monthYesBank transfer (automatic)74.952869.85Yes\n    46994-KERXLMale  0No No  4YesNo              DSL        No                 ...No                 No                 No                 Yes                Month-to-monthYesElectronic check         55.90 238.50No \n    52181-UAESMMale  0No No  2YesNo              DSL        Yes                ...Yes                No                 No                 No                 Month-to-monthNo Electronic check         53.45 119.50No \n    64312-GVYNHFemale0YesNo 70No No phone serviceDSL        Yes                ...Yes                Yes                No                 Yes                Two year      YesBank transfer (automatic)49.853370.20No \n\n\n\n\n\n# You can also use startRow, endRow and other params to define how much data read\ndata <- read.xlsx(\"../../data/telecom_users.xlsx\", sheetIndex = 1, endRow = 100)\nhead(data)\n\n\n\nA data.frame: 6 × 21\n\n    customerIDgenderSeniorCitizenPartnerDependentstenurePhoneServiceMultipleLinesInternetServiceOnlineSecurity...DeviceProtectionTechSupportStreamingTVStreamingMoviesContractPaperlessBillingPaymentMethodMonthlyChargesTotalChargesChurn\n    <chr><chr><dbl><chr><chr><dbl><chr><chr><chr><chr>...<chr><chr><chr><chr><chr><chr><chr><dbl><dbl><chr>\n\n\n    17010-BRBUUMale  0YesYes72YesYes             No         No internet service...No internet serviceNo internet serviceNo internet serviceNo internet serviceTwo year      No Credit card (automatic)  24.101734.65No \n    29688-YGXVRFemale0No No 44YesNo              Fiber opticNo                 ...Yes                No                 Yes                No                 Month-to-monthYesCredit card (automatic)  88.153973.20No \n    39286-DOJGFFemale1YesNo 38YesYes             Fiber opticNo                 ...No                 No                 No                 No                 Month-to-monthYesBank transfer (automatic)74.952869.85Yes\n    46994-KERXLMale  0No No  4YesNo              DSL        No                 ...No                 No                 No                 Yes                Month-to-monthYesElectronic check         55.90 238.50No \n    52181-UAESMMale  0No No  2YesNo              DSL        Yes                ...Yes                No                 No                 No                 Month-to-monthNo Electronic check         53.45 119.50No \n    64312-GVYNHFemale0YesNo 70No No phone serviceDSL        Yes                ...Yes                Yes                No                 Yes                Two year      YesBank transfer (automatic)49.853370.20No \n\n\n\n\nLet’s replace Churn values Yes/No by 1/0:\n\nhead(data$Churn)\n\n\n'No''No''Yes''No''No''No'\n\n\n\ndata$Churn <- ifelse(data$Churn == \"Yes\", 1, 0)\n\n\nhead(data$Churn)\n\n\n001000\n\n\nWrite final data to excel:\n\nwrite.xlsx(data, file = \"../../data/final_telecom_data.xlsx\")"
  },
  {
    "objectID": "23-r-xlsx.html#task-1",
    "href": "23-r-xlsx.html#task-1",
    "title": "4  MS Excel (xlsx)",
    "section": "4.2 Task 1",
    "text": "4.2 Task 1\nDownload from kaggle.com and read dataset Default_Fin.csv: https://www.kaggle.com/kmldas/loan-default-prediction\nDescription:\nThis is a synthetic dataset created using actual data from a financial institution. The data has been modified to remove identifiable features and the numbers transformed to ensure they do not link to original source (financial institution).\nThis is intended to be used for academic purposes for beginners who want to practice financial analytics from a simple financial dataset\n\nIndex - This is the serial number or unique identifier of the loan taker\nEmployed - This is a Boolean 1= employed 0= unemployed\nBank.Balance - Bank Balance of the loan taker\nAnnual.Salary - Annual salary of the loan taker\n\nDefaulted - This is a Boolean 1= defaulted 0= not defaulted\n\n\nCheck what columns has missing values\nCount default and non-default clients / and parts of total clients in %\nCount Employed clients\nCount Employed Default clients\nAverage salary by Employed clients\nRename columns to “id”, “empl”, “balance”, “salary”, “default”\n\n\nSolution for Task 1\n\ndata <- read.csv(\"../../data/Default_Fin.csv\")\nhead(data)\n\n\n\nA data.frame: 6 × 5\n\n    IndexEmployedBank.BalanceAnnual.SalaryDefaulted.\n    <int><int><dbl><dbl><int>\n\n\n    111 8754.36532339.560\n    220 9806.16145273.560\n    33112882.60381205.680\n    441 6351.00428453.880\n    551 9427.92461562.000\n    66011035.08 89898.720\n\n\n\n\n\n\nCheck what columns has missing values\n\n\n\nanyNA(data)\n\nFALSE\n\n\n\n\nCount default and non-default clients / and parts of total clients in %\n\n\n\ndef_count <- nrow(data[data$Defaulted. == 1, ])\nno_def_count <- nrow(data[data$Defaulted. == 0, ])\ndef_count\nno_def_count \n\n333\n\n\n9667\n\n\n\ndef_count / nrow(data) * 100 # part defaults\nno_def_count / nrow(data) * 100 # part non-defaults\n\n3.33\n\n\n96.67\n\n\n\n\nCount Employed clients\n\n\n\nempl <- data[data$Employed == 1, ]\nnrow(empl)\n\n7056\n\n\n\n\nCount Employed Default clients\n\n\n\nempl <- data[data$Employed == 1 & data$Defaulted. == 1, ]\nnrow(empl)\n\n206\n\n\n\n\nAverage salary by Employed clients\n\n\n\nempl <- data[data$Employed == 1, ]\nmean(empl$Annual.Salary)\n\n480143.43414966\n\n\n\n\nRename columns to “id”, “empl”, “balance”, “salary”, “default”:\n\n\n\ncolnames(data) <- c(\"id\", \"empl\", \"balance\", \"salary\", \"default\")\nhead(data)\n\n\n\nA data.frame: 6 × 5\n\n    idemplbalancesalarydefault\n    <int><int><dbl><dbl><int>\n\n\n    111 8754.36532339.560\n    220 9806.16145273.560\n    33112882.60381205.680\n    441 6351.00428453.880\n    551 9427.92461562.000\n    66011035.08 89898.720"
  },
  {
    "objectID": "23-r-xlsx.html#набори-даних",
    "href": "23-r-xlsx.html#набори-даних",
    "title": "4  MS Excel (xlsx)",
    "section": "4.3 Набори даних",
    "text": "4.3 Набори даних\n\nhttps://github.com/kleban/r-book-published/tree/main/datasets/telecom_users.csv\nhttps://github.com/kleban/r-book-published/tree/main/datasets/telecom_sers.xlsx\nhttps://github.com/kleban/r-book-published/tree/main/datasets/Default_Fin.csv\nhttps://github.com/kleban/r-book-published/tree/main/datasets/employes.xml"
  },
  {
    "objectID": "23-r-xlsx.html#references",
    "href": "23-r-xlsx.html#references",
    "title": "4  MS Excel (xlsx)",
    "section": "4.4 References",
    "text": "4.4 References\n\nSQLite in R. Datacamp\nTidyverse googlesheets4 0.2.0 \nBinanace spot Api Docs\nWeb Scraping in R: rvest Tutorial by Arvid Kingl"
  },
  {
    "objectID": "24-r-xml.html",
    "href": "24-r-xml.html",
    "title": "5  XML",
    "section": "",
    "text": "You need this packages for code execution:"
  },
  {
    "objectID": "24-r-xml.html#xml-extensible-markup-language",
    "href": "24-r-xml.html#xml-extensible-markup-language",
    "title": "5  XML",
    "section": "5.1 XML (eXtensible Markup Language)",
    "text": "5.1 XML (eXtensible Markup Language)\nFor our example we will use data from data/employes.xml. File contains records with info:\n<RECORDS>\n   <EMPLOYEE>\n      <ID>1</ID>\n      <NAME>Rick</NAME>\n      <SALARY>623.3</SALARY>\n      <STARTDATE>1/1/2012</STARTDATE>\n      <DEPT>IT</DEPT>\n   </EMPLOYEE>\n   ...\n</RECORDS>\n\n#install.packages(\"XML\")\nlibrary(\"XML\")\n#install.packages(\"methods\")\nlibrary(\"methods\")\n\n\nresult <- xmlParse(file = \"../../data/employes.xml\")\nprint(result)\n\n<?xml version=\"1.0\"?>\n<RECORDS>\n  <EMPLOYEE>\n    <ID>1</ID>\n    <NAME>Rick</NAME>\n    <SALARY>623.3</SALARY>\n    <STARTDATE>1/1/2012</STARTDATE>\n    <DEPT>IT</DEPT>\n  </EMPLOYEE>\n  <EMPLOYEE>\n    <ID>2</ID>\n    <NAME>Dan</NAME>\n    <SALARY>515.2</SALARY>\n    <STARTDATE>9/23/2013</STARTDATE>\n    <DEPT>Operations</DEPT>\n  </EMPLOYEE>\n  <EMPLOYEE>\n    <ID>3</ID>\n    <NAME>Michelle</NAME>\n    <SALARY>611</SALARY>\n    <STARTDATE>11/15/2014</STARTDATE>\n    <DEPT>IT</DEPT>\n  </EMPLOYEE>\n  <EMPLOYEE>\n    <ID>4</ID>\n    <NAME>Ryan</NAME>\n    <SALARY>729</SALARY>\n    <STARTDATE>5/11/2014</STARTDATE>\n    <DEPT>HR</DEPT>\n  </EMPLOYEE>\n  <EMPLOYEE>\n    <ID>5</ID>\n    <NAME>Gary</NAME>\n    <SALARY>843.25</SALARY>\n    <STARTDATE>3/27/2015</STARTDATE>\n    <DEPT>Finance</DEPT>\n  </EMPLOYEE>\n  <EMPLOYEE>\n    <ID>6</ID>\n    <NAME>Nina</NAME>\n    <SALARY>578</SALARY>\n    <STARTDATE>5/21/2013</STARTDATE>\n    <DEPT>IT</DEPT>\n  </EMPLOYEE>\n  <EMPLOYEE>\n    <ID>7</ID>\n    <NAME>Simon</NAME>\n    <SALARY>632.8</SALARY>\n    <STARTDATE>7/30/2013</STARTDATE>\n    <DEPT>Operations</DEPT>\n  </EMPLOYEE>\n  <EMPLOYEE>\n    <ID>8</ID>\n    <NAME>Guru</NAME>\n    <SALARY>722.5</SALARY>\n    <STARTDATE>6/17/2014</STARTDATE>\n    <DEPT>Finance</DEPT>\n  </EMPLOYEE>\n</RECORDS>\n \n\n\n\nrootnode <- xmlRoot(result) # reading rootnode of xml document\nrootnode[[1]] # reading first record\n\n<EMPLOYEE>\n  <ID>1</ID>\n  <NAME>Rick</NAME>\n  <SALARY>623.3</SALARY>\n  <STARTDATE>1/1/2012</STARTDATE>\n  <DEPT>IT</DEPT>\n</EMPLOYEE> \n\n\n\nrootnode[[1]][[2]] # reading first record in root node and second tag, its <NAME>\n\n<NAME>Rick</NAME> \n\n\nFor us the best way is to get dataframe:\n\nxmldataframe <- xmlToDataFrame(\"../../data/employes.xml\")\nxmldataframe\n\n\n\nA data.frame: 8 × 5\n\n    IDNAMESALARYSTARTDATEDEPT\n    <chr><chr><chr><chr><chr>\n\n\n    1Rick    623.3 1/1/2012  IT        \n    2Dan     515.2 9/23/2013 Operations\n    3Michelle611   11/15/2014IT        \n    4Ryan    729   5/11/2014 HR        \n    5Gary    843.253/27/2015 Finance   \n    6Nina    578   5/21/2013 IT        \n    7Simon   632.8 7/30/2013 Operations\n    8Guru    722.5 6/17/2014 Finance"
  },
  {
    "objectID": "24-r-xml.html#набори-даних",
    "href": "24-r-xml.html#набори-даних",
    "title": "5  XML",
    "section": "5.2 Набори даних",
    "text": "5.2 Набори даних\n\nhttps://github.com/kleban/r-book-published/tree/main/datasets/telecom_users.csv\nhttps://github.com/kleban/r-book-published/tree/main/datasets/telecom_sers.xlsx\nhttps://github.com/kleban/r-book-published/tree/main/datasets/Default_Fin.csv\nhttps://github.com/kleban/r-book-published/tree/main/datasets/employes.xml"
  },
  {
    "objectID": "24-r-xml.html#references",
    "href": "24-r-xml.html#references",
    "title": "5  XML",
    "section": "5.3 References",
    "text": "5.3 References\n\nSQLite in R. Datacamp\nTidyverse googlesheets4 0.2.0 \nBinanace spot Api Docs\nWeb Scraping in R: rvest Tutorial by Arvid Kingl"
  },
  {
    "objectID": "10-r-data-read-intro.html",
    "href": "10-r-data-read-intro.html",
    "title": "\n1  Загальна інформація + презентація\n",
    "section": "",
    "text": "Розглянути осноновні типи джерел даних, їх структуру, сервіси, бібліотеки та способи завантаження/вивантаження у R."
  },
  {
    "objectID": "10-r-data-read-intro.html#короткий-опис",
    "href": "10-r-data-read-intro.html#короткий-опис",
    "title": "\n1  Загальна інформація + презентація\n",
    "section": "\n1.2 Короткий опис",
    "text": "1.2 Короткий опис\nМатеріали розділу містять інформацію про структуру файлів у форматах CSV, XML, XLSX, JSON, а також способи читання інформації з API, chatGPT 3.5. Окрім того розглянуто також можливості читання запису SQL (на прикладі SQLite) та веб-сторінок (HTML).\n\n\nЦе вбудований документ <a target=\"_blank\" href=\"https://office.com\">Microsoft Office</a> на платформі <a target=\"_blank\" href=\"https://office.com/webapps\">Office</a>."
  },
  {
    "objectID": "20-r-data-read-intro.html",
    "href": "20-r-data-read-intro.html",
    "title": "\n2  Загальна інформація + презентація\n",
    "section": "",
    "text": "Розглянути осноновні типи джерел даних, їх структуру, сервіси, бібліотеки та способи завантаження/вивантаження у R."
  },
  {
    "objectID": "20-r-data-read-intro.html#короткий-опис",
    "href": "20-r-data-read-intro.html#короткий-опис",
    "title": "\n2  Загальна інформація + презентація\n",
    "section": "\n2.2 Короткий опис",
    "text": "2.2 Короткий опис\nМатеріали розділу містять інформацію про структуру файлів у форматах CSV, XML, XLSX, JSON, а також способи читання інформації з API, chatGPT 3.5. Окрім того розглянуто також можливості читання запису SQL (на прикладі SQLite) та веб-сторінок (HTML)."
  },
  {
    "objectID": "20-r-data-read-intro.html#презентація",
    "href": "20-r-data-read-intro.html#презентація",
    "title": "\n2  Загальна інформація + презентація\n",
    "section": "\n2.3 Презентація",
    "text": "2.3 Презентація\n\nЦе вбудований документ <a target=\"_blank\" href=\"https://office.com\">Microsoft Office</a> на платформі <a target=\"_blank\" href=\"https://office.com/webapps\">Office</a>."
  },
  {
    "objectID": "25-r-api-json.html",
    "href": "25-r-api-json.html",
    "title": "6  JSON and API",
    "section": "",
    "text": "JSON (JavaScript Object Notation) is a lightweight data-interchange format. It is easy for humans to read and write. It is easy for machines to parse and generate. It is based on a subset of the JavaScript Programming Language Standard.\nAPI is the acronym for Application Programming Interface, which is a software intermediary that allows two applications to talk to each other.\nOne of the most popular packages for json is jsonlite.\n\n#install.packages(\"jsonlite\")\nlibrary(jsonlite)\n\nLet’s use readinginformation about BTC and USDT crypro currencies from Binance\n\nmarket = 'BTCUSDT'\ninterval = '1h'\nlimit = 100\n\nurl <- paste0(url = \"https://api.binance.com/api/v3/klines?symbol=\", market ,\"&interval=\", interval,\"&limit=\", limit)\nprint(url) # complete request URL\n\n[1] \"https://api.binance.com/api/v3/klines?symbol=BTCUSDT&interval=1h&limit=100\"\n\n\nOn the next stage you need use fromJSON() function to get data.\nMore details about requests to Binanace at https://github.com/binance/binance-spot-api-docs/blob/master/rest-api.md#klinecandlestick-data\nIf you enter ‘url’ value at browser response is going to be like this:\n[\n  [\n    1499040000000,      // Open time\n    \"0.01634790\",       // Open\n    \"0.80000000\",       // High\n    \"0.01575800\",       // Low\n    \"0.01577100\",       // Close\n    \"148976.11427815\",  // Volume\n    1499644799999,      // Close time\n    \"2434.19055334\",    // Quote asset volume\n    308,                // Number of trades\n    \"1756.87402397\",    // Taker buy base asset volume\n    \"28.46694368\",      // Taker buy quote asset volume\n    \"17928899.62484339\" // Ignore.\n  ]\n]\n\ndata <- fromJSON(url) # get json and transform it to list()\ndata <- data[, 1:7] # let's left only 1:7 columns (from Open time to Close time)\nhead(data)\n\n\n\nA matrix: 6 × 7 of type chr\n\n    165051360000041693.5800000041750.0000000041525.0000000041610.010000001138.643370001650517199999\n    165051720000041610.0100000041699.0000000041434.4400000041462.760000001229.259360001650520799999\n    165052080000041462.7500000041600.0000000041419.2000000041522.380000001049.712440001650524399999\n    165052440000041522.3800000041940.0000000041451.0000000041855.690000001928.480910001650527999999\n    1.650528e+12 41855.6900000042050.3000000041741.1000000041922.970000002518.040900001650531599999\n    165053160000041922.9600000041971.9000000041743.9600000041803.700000001655.769930001650535199999\n\n\n\n\n\ntypeof(data) # check data type\ndata <- as.data.frame(data) # convert to dataframe\nhead(data)\n\n'character'\n\n\n\n\nA data.frame: 6 × 7\n\n    V1V2V3V4V5V6V7\n    <chr><chr><chr><chr><chr><chr><chr>\n\n\n    1165051360000041693.5800000041750.0000000041525.0000000041610.010000001138.643370001650517199999\n    2165051720000041610.0100000041699.0000000041434.4400000041462.760000001229.259360001650520799999\n    3165052080000041462.7500000041600.0000000041419.2000000041522.380000001049.712440001650524399999\n    4165052440000041522.3800000041940.0000000041451.0000000041855.690000001928.480910001650527999999\n    51.650528e+12 41855.6900000042050.3000000041741.1000000041922.970000002518.040900001650531599999\n    6165053160000041922.9600000041971.9000000041743.9600000041803.700000001655.769930001650535199999\n\n\n\n\n\n# fix columns names\ncolnames(data) <- c(\"Open_time\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\", \"Close_time\")\nhead(data) # looks better, but columns are characters still\n\n\n\nA data.frame: 6 × 7\n\n    Open_timeOpenHighLowCloseVolumeClose_time\n    <chr><chr><chr><chr><chr><chr><chr>\n\n\n    1165051360000041693.5800000041750.0000000041525.0000000041610.010000001138.643370001650517199999\n    2165051720000041610.0100000041699.0000000041434.4400000041462.760000001229.259360001650520799999\n    3165052080000041462.7500000041600.0000000041419.2000000041522.380000001049.712440001650524399999\n    4165052440000041522.3800000041940.0000000041451.0000000041855.690000001928.480910001650527999999\n    51.650528e+12 41855.6900000042050.3000000041741.1000000041922.970000002518.040900001650531599999\n    6165053160000041922.9600000041971.9000000041743.9600000041803.700000001655.769930001650535199999\n\n\n\n\n\nis.numeric(data[,1]) # check 1st column type is numeric\nis.numeric(data[,2]) # check 2nd column type is numeric\n\nFALSE\n\n\nFALSE\n\n\n\ndata <- as.data.frame(sapply(data, as.numeric)) # convert all columns to numeric\nhead(data) # good, its double now\n\n\n\nA data.frame: 6 × 7\n\n    Open_timeOpenHighLowCloseVolumeClose_time\n    <dbl><dbl><dbl><dbl><dbl><dbl><dbl>\n\n\n    11.650514e+1241693.5841750.041525.0041610.011138.6431.650517e+12\n    21.650517e+1241610.0141699.041434.4441462.761229.2591.650521e+12\n    31.650521e+1241462.7541600.041419.2041522.381049.7121.650524e+12\n    41.650524e+1241522.3841940.041451.0041855.691928.4811.650528e+12\n    51.650528e+1241855.6942050.341741.1041922.972518.0411.650532e+12\n    61.650532e+1241922.9641971.941743.9641803.701655.7701.650535e+12\n\n\n\n\nFinal stage is to convert Open_time and Close_time to dates.\n\ndata$Open_time <- as.POSIXct(data$Open_time/1e3, origin = '1970-01-01')\ndata$Close_time <- as.POSIXct(data$Close_time/1e3, origin = '1970-01-01')\n\nhead(data) \n\n\n\nA data.frame: 6 × 7\n\n    Open_timeOpenHighLowCloseVolumeClose_time\n    <dttm><dbl><dbl><dbl><dbl><dbl><dttm>\n\n\n    12022-04-21 07:00:0041693.5841750.041525.0041610.011138.6432022-04-21 07:59:59\n    22022-04-21 08:00:0041610.0141699.041434.4441462.761229.2592022-04-21 08:59:59\n    32022-04-21 09:00:0041462.7541600.041419.2041522.381049.7122022-04-21 09:59:59\n    42022-04-21 10:00:0041522.3841940.041451.0041855.691928.4812022-04-21 10:59:59\n    52022-04-21 11:00:0041855.6942050.341741.1041922.972518.0412022-04-21 11:59:59\n    62022-04-21 12:00:0041922.9641971.941743.9641803.701655.7702022-04-21 12:59:59\n\n\n\n\n\ntail(data) # check last records\n\n\n\nA data.frame: 6 × 7\n\n    Open_timeOpenHighLowCloseVolumeClose_time\n    <dttm><dbl><dbl><dbl><dbl><dbl><dttm>\n\n\n    952022-04-25 05:00:0039095.8139153.9438961.6439091.171205.51582022-04-25 05:59:59\n    962022-04-25 06:00:0039091.1739294.7639086.3739253.711443.33182022-04-25 06:59:59\n    972022-04-25 07:00:0039253.7039256.2839055.7139139.74 896.85542022-04-25 07:59:59\n    982022-04-25 08:00:0039139.7439230.5038947.4238975.221057.49002022-04-25 08:59:59\n    992022-04-25 09:00:0038975.2139057.9738590.0038636.352814.97162022-04-25 09:59:59\n    1002022-04-25 10:00:0038636.3538675.6838200.0038534.993528.23552022-04-25 10:59:59"
  },
  {
    "objectID": "25-r-api-json.html#набори-даних",
    "href": "25-r-api-json.html#набори-даних",
    "title": "6  JSON and API",
    "section": "6.2 Набори даних",
    "text": "6.2 Набори даних\n\nhttps://github.com/kleban/r-book-published/tree/main/datasets/telecom_users.csv\nhttps://github.com/kleban/r-book-published/tree/main/datasets/telecom_sers.xlsx\nhttps://github.com/kleban/r-book-published/tree/main/datasets/Default_Fin.csv\nhttps://github.com/kleban/r-book-published/tree/main/datasets/employes.xml"
  },
  {
    "objectID": "25-r-api-json.html#references",
    "href": "25-r-api-json.html#references",
    "title": "6  JSON and API",
    "section": "6.3 References",
    "text": "6.3 References\n\nSQLite in R. Datacamp\nTidyverse googlesheets4 0.2.0 \nBinanace spot Api Docs\nWeb Scraping in R: rvest Tutorial by Arvid Kingl"
  },
  {
    "objectID": "26-r-google.html",
    "href": "26-r-google.html",
    "title": "7  Google Services",
    "section": "",
    "text": "THIS CHAPTER IS UNDER CONSTRUCTION / Working with Google Spreadsheets need account authorization.\n\ngooglesheets4 is a package to work with Google Sheets from R.\n\n#install.packages(\"googlesheets4\")\nlibrary(googlesheets4)\n\nYou can read google documents after authentification on google service. There is sample code:\nread_sheet(\"https://docs.google.com/spreadsheets/d/1U6Cf_qEOhiR9AZqTqS3mbMF3zt2db48ZP5v3rkrAEJY/edit#gid=780868077\")\ngs4_deauth()\nLet’s read sample dataset gapminder. It detailed described in next paragraph.\n\n# gs4_example(\"gapminder\")"
  },
  {
    "objectID": "26-r-google.html#google-search-trends",
    "href": "26-r-google.html#google-search-trends",
    "title": "7  Google Services",
    "section": "7.2 Google Search Trends",
    "text": "7.2 Google Search Trends\nGoogle Trends is a service for analyzing search requests by many filters like region (continent, country, locality), period (year, month), information category (business, education, hobby, healthcare), information type (news, shopping, video, images) https://trends.google.com/trends/\n\n# install.packages('gtrendsR')\n# install.packages('ggplot2')\nlibrary(gtrendsR) # loading package for Google Trends queries\nlibrary(ggplot2)\n\nLet’s configure out google trends query params\n\nkeywords = c(\"Bitcoin\", \"FC Barcelona\") # search keywords\ncountry = c('AT') # search region from https://support.google.com/business/answer/6270107?hl=en\ntime = (\"2021-01-01 2021-06-01\") # period\nchannel = 'web' # search channel: google search ('news' - google news, 'images' - google images)\n\n\n# query\ntrends = gtrends(keywords, gprop = channel, geo = country, time = time, tz = \"UTC\")\n\n\ntime_trend = trends$interest_over_time\nhead(time_trend)\n\n\n\nA data.frame: 6 × 7\n\n    datehitskeywordgeotimegpropcategory\n    <dttm><chr><chr><chr><chr><chr><int>\n\n\n    12021-01-0136BitcoinAT2021-01-01 2021-06-01web0\n    22021-01-0267BitcoinAT2021-01-01 2021-06-01web0\n    32021-01-0374BitcoinAT2021-01-01 2021-06-01web0\n    42021-01-0457BitcoinAT2021-01-01 2021-06-01web0\n    52021-01-0553BitcoinAT2021-01-01 2021-06-01web0\n    62021-01-0666BitcoinAT2021-01-01 2021-06-01web0\n\n\n\n\n\nplot <- ggplot(data=time_trend, aes(x=date, y=hits, group=keyword, col=keyword)) +\n  geom_line() +\n  xlab('Time') + \n  ylab('Relative Interest') + \n  theme(legend.title = element_blank(), legend.position=\"bottom\", legend.text=element_text(size=15)) + \n  ggtitle(\"Google Search Volume\")  \n\nplot"
  },
  {
    "objectID": "26-r-google.html#набори-даних",
    "href": "26-r-google.html#набори-даних",
    "title": "7  Google Services",
    "section": "7.3 Набори даних",
    "text": "7.3 Набори даних\n\nhttps://github.com/kleban/r-book-published/tree/main/datasets/telecom_users.csv\nhttps://github.com/kleban/r-book-published/tree/main/datasets/telecom_sers.xlsx\nhttps://github.com/kleban/r-book-published/tree/main/datasets/Default_Fin.csv\nhttps://github.com/kleban/r-book-published/tree/main/datasets/employes.xml"
  },
  {
    "objectID": "26-r-google.html#references",
    "href": "26-r-google.html#references",
    "title": "7  Google Services",
    "section": "7.4 References",
    "text": "7.4 References\n\nSQLite in R. Datacamp\nTidyverse googlesheets4 0.2.0 \nBinanace spot Api Docs\nWeb Scraping in R: rvest Tutorial by Arvid Kingl"
  },
  {
    "objectID": "27-r-sql.html",
    "href": "27-r-sql.html",
    "title": "8  SQL (with SQLite sample)",
    "section": "",
    "text": "We are going to review working with database on SQLite, becouse it allows us not to install DB-server and start working with simple file.\nFor now we will use RSQLite package.\nNow, let’s create new:\nYou can write complex queries for many tables if you knowledge of SQL allows."
  },
  {
    "objectID": "27-r-sql.html#набори-даних",
    "href": "27-r-sql.html#набори-даних",
    "title": "8  SQL (with SQLite sample)",
    "section": "8.1 Набори даних",
    "text": "8.1 Набори даних\n\nhttps://github.com/kleban/r-book-published/tree/main/datasets/telecom_users.csv\nhttps://github.com/kleban/r-book-published/tree/main/datasets/telecom_sers.xlsx\nhttps://github.com/kleban/r-book-published/tree/main/datasets/Default_Fin.csv\nhttps://github.com/kleban/r-book-published/tree/main/datasets/employes.xml"
  },
  {
    "objectID": "27-r-sql.html#references",
    "href": "27-r-sql.html#references",
    "title": "8  SQL (with SQLite sample)",
    "section": "8.2 References",
    "text": "8.2 References\n\nSQLite in R. Datacamp\nTidyverse googlesheets4 0.2.0 \nBinanace spot Api Docs\nWeb Scraping in R: rvest Tutorial by Arvid Kingl"
  },
  {
    "objectID": "28-r-html.html",
    "href": "28-r-html.html",
    "title": "9  Web-pages (HTML)",
    "section": "",
    "text": "Sometimes decision making needs scrap data from web sources and pages.\nLet’s try to parse data from Wikipedia as table.\nGo to web page https://en.wikipedia.org/wiki/List_of_largest_banks and check it.\nFor now, let’s read a table of Total Assets in US Billion\nNext is reading data of market capitalization table (4th):\nAnd now let’s merge() this two datasets:"
  },
  {
    "objectID": "28-r-html.html#task-3",
    "href": "28-r-html.html#task-3",
    "title": "9  Web-pages (HTML)",
    "section": "9.1 Task 3",
    "text": "9.1 Task 3\nFrom a page https://en.wikipedia.org/wiki/List_of_largest_banks read and merge by country named tables:\n\nNumber of banks in the top 100 by total assets\nTotal market capital (US$ billion) across the top 70 banks by country\n\nSolution\n\nlibrary(rvest)\nurl <- \"https://en.wikipedia.org/wiki/List_of_largest_banks\" # got to url in other tab\n#url <- \"data/List of largest banks - Wikipedia_.html\"\npage_data <- read_html(url) # read html content\n\ntables <- html_nodes(page_data, \"table\")\nhtml_table(tables[1]) #its not needed table\n\n\n\n    \nA tibble: 1  2\n\n    X1X2\n    <lgl><chr>\n\n\n    NAThis article is missing information about Revenue and Employment. Please expand the article to include this information. Further details may exist on the talk page.  (September 2020)\n\n\n\n\n\n\n\nhtml_table(tables[3]) # thats solution for \"Number of banks in the top 100 by total assets\"\n#check the end of table. There are NA record\n# lets remove it\n\n\n\n    \nA tibble: 26  3\n\n    RankCountryNumber\n    <int><chr><int>\n\n\n    1China         19\n    2United States 11\n    3Japan          8\n    4United Kingdom 6\n    4France         6\n    4South Korea    6\n    5Canada         5\n    5Germany        5\n    6Australia      4\n    6Brazil         4\n    6Spain          4\n    7Netherlands    3\n    7Singapore      3\n    7Sweden         3\n    7Switzerland    3\n    8Italy          2\n    9India          1\n    9Austria        1\n    9Belgium        1\n    9Denmark        1\n    9Finland        1\n    9Norway         1\n    9Russia         1\n    9Qatar          1\n    9NA            NA\n    9NA            NA\n\n\n\n\n\n\n\ntable1 <- as.data.frame(html_table(tables[3]))\ntable1 <- table1[!is.na(table1$Country), ]\ntable1 # now it OK!\n\n\n\nA data.frame: 24 × 3\n\n    RankCountryNumber\n    <int><chr><int>\n\n\n    11China         19\n    22United States 11\n    33Japan          8\n    44United Kingdom 6\n    54France         6\n    64South Korea    6\n    75Canada         5\n    85Germany        5\n    96Australia      4\n    106Brazil         4\n    116Spain          4\n    127Netherlands    3\n    137Singapore      3\n    147Sweden         3\n    157Switzerland    3\n    168Italy          2\n    179India          1\n    189Austria        1\n    199Belgium        1\n    209Denmark        1\n    219Finland        1\n    229Norway         1\n    239Russia         1\n    249Qatar          1\n\n\n\n\n\n# SOlution for \"Total market capital (US$ billion) across the top 70 banks by country\"\n# compare this with table on a given page\ntable2 <- as.data.frame(html_table(tables[4]))\ntable2 # now it OK!\n\n\n\nA data.frame: 50 × 3\n\n    RankBank.nameMarket.cap.US..billion.\n    <int><chr><dbl>\n\n\n     1JPMorgan Chase                         368.78\n     2Industrial and Commercial Bank of China295.65\n     3Bank of America                        279.73\n     4Wells Fargo                            214.34\n     5China Construction Bank                207.98\n     6Agricultural Bank of China             181.49\n     7HSBC Holdings PLC                      169.47\n     8Citigroup Inc.                         163.58\n     9Bank of China                          151.15\n    10China Merchants Bank                   133.37\n    11Royal Bank of Canada                   113.80\n    12Toronto-Dominion Bank                  106.61\n    13Commonwealth Bank                       99.77\n    14HDFC Bank                              105.90\n    15U.S. Bancorp                            84.40\n    16Goldman Sachs                           78.70\n    17Banco Santander                         75.47\n    18Banco Bradesco                          74.67\n    19Morgan Stanley                          73.93\n    20Westpac                                 67.84\n    21Mitsubishi UFJ Financial Group          66.20\n    22Scotiabank                              65.48\n    23PNC Financial Services                  63.11\n    24Bank of Communications                  61.85\n    25BNP Paribas                             59.36\n    26Australia and New Zealand Banking Group 54.88\n    27National Australia Bank                 51.68\n    28Lloyds Banking Group                    51.19\n    29Sumitomo Mitsui Financial Group         49.85\n    30Bank of Montreal                        48.12\n    31UBS                                     45.92\n    32ING Group                               44.97\n    33Capital One                             43.22\n    34The Bank of New York Mellon             42.58\n    35China Minsheng Bank                     39.13\n    36China CITIC Bank                        38.55\n    37Banco Bilbao Vizcaya Argentaria         37.42\n    38Mizuho Financial Group                  36.95\n    39Intesa Sanpaolo                         36.90\n    40Credit Agricole                         34.89\n    41Canadian Imperial Bank of Commerce      34.87\n    42Royal Bank of Scotland                  33.95\n    43Barclays                                33.26\n    44Credit Suisse                           30.75\n    45Nordea                                  29.59\n    46Standard Chartered                      29.37\n    47KBC Bank                                27.40\n    48UniCredit                               26.88\n    49Societe Generale                        21.27\n    50Deutsche Bank                           15.77"
  },
  {
    "objectID": "28-r-html.html#набори-даних",
    "href": "28-r-html.html#набори-даних",
    "title": "9  Web-pages (HTML)",
    "section": "9.2 Набори даних",
    "text": "9.2 Набори даних\n\nhttps://github.com/kleban/r-book-published/tree/main/datasets/telecom_users.csv\nhttps://github.com/kleban/r-book-published/tree/main/datasets/telecom_sers.xlsx\nhttps://github.com/kleban/r-book-published/tree/main/datasets/Default_Fin.csv\nhttps://github.com/kleban/r-book-published/tree/main/datasets/employes.xml"
  },
  {
    "objectID": "28-r-html.html#references",
    "href": "28-r-html.html#references",
    "title": "9  Web-pages (HTML)",
    "section": "9.3 References",
    "text": "9.3 References\n\nSQLite in R. Datacamp\nTidyverse googlesheets4 0.2.0 \nBinanace spot Api Docs\nWeb Scraping in R: rvest Tutorial by Arvid Kingl"
  },
  {
    "objectID": "etl-dplyr.html",
    "href": "etl-dplyr.html",
    "title": "10  Manipulate data with dplyr",
    "section": "",
    "text": "You need this packages for code execution:"
  },
  {
    "objectID": "etl-dplyr.html#whats-dplyr-package",
    "href": "etl-dplyr.html#whats-dplyr-package",
    "title": "10  Manipulate data with dplyr",
    "section": "10.1 What’s dplyr package",
    "text": "10.1 What’s dplyr package\nThe dplyr package is one of the most powerful and popular package in R for data manipulation.\nWorking with data:\n\nFigure out what you want to do.\nDescribe those tasks in the form of a computer program.\nExecute the program.\n\nThe dplyr package makes these steps fast and easy:\n\nBy constraining your options, it helps you think about your data manipulation challenges.\nIt provides simple verbs, functions that correspond to the most common data manipulation tasks, to help you translate your thoughts into code.\nIt uses efficient backends, so you spend less time waiting for the computer.\n\nBefore use you should install package:\n\n# install.packages(\"dplyr\")\n\nNext step is loading package:\n\nlibrary(dplyr)\n\ndplyr functions work with pipes and expect tidy data. In tidy data:\n\nAlternative way is to load tidyverse package with other attached:\n\n# install.packages(\"tidyverse\")\nlibrary(tidyverse)"
  },
  {
    "objectID": "etl-dplyr.html#exploring-data-with-dplyr",
    "href": "etl-dplyr.html#exploring-data-with-dplyr",
    "title": "10  Manipulate data with dplyr",
    "section": "10.2 Exploring data with dplyr",
    "text": "10.2 Exploring data with dplyr\n\n10.2.1 Basic funtions and dataset explore\nThere are most popular functions in dplyr is listed in table.\n\n\n\ndplyr Function\nDescription\nEquivalent SQL\n\n\n\n\nselect()\nSelecting columns (variables)\nSELECT\n\n\nfilter()\nFilter (subset) rows.\nWHERE\n\n\ngroup_by()\nGroup the data\nGROUP BY\n\n\nsummarise()\nSummarise (or aggregate) data\n-\n\n\narrange()\nSort the data\nORDER BY\n\n\njoin()\nJoining data frames (tables)\nJOIN\n\n\nmutate()\nCreating New Variables\nCOLUMN ALIAS\n\n\n\nFor the next sample we are going to use gapminder dataset. Go to gapminder dataset description\nThe gapminder data frame include six variables:\n\n\n\nvariable\nmeaning\n\n\n\n\ncountry\n-\n\n\ncontinent\n-\n\n\nyear\n-\n\n\nlifeExp\nlife expectancy at birth\n\n\npop\ntotal population\n\n\ngdpPercap\nper-capita GDP\n\n\n\nPer-capita GDP (Gross domestic product) is given in units of international dollars, a hypothetical unit of currency that has the same purchasing power parity that the U.S. dollar had in the United States at a given point in time – 2005, in this case.\nThe gapminder data frame is a special kind of data frame: a tibble.\n\n# install.packages(\"gapminder\")\nlibrary(gapminder)  # load package and dataset\nclass(gapminder)\n\n\n'tbl_df''tbl''data.frame'\n\n\nLet’s preview it with functions str(), glimpse(), head(), tail(), summary().\n\nstr(gapminder)\n\ntibble [1,704 x 6] (S3: tbl_df/tbl/data.frame)\n $ country  : Factor w/ 142 levels \"Afghanistan\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ continent: Factor w/ 5 levels \"Africa\",\"Americas\",..: 3 3 3 3 3 3 3 3 3 3 ...\n $ year     : int [1:1704] 1952 1957 1962 1967 1972 1977 1982 1987 1992 1997 ...\n $ lifeExp  : num [1:1704] 28.8 30.3 32 34 36.1 ...\n $ pop      : int [1:1704] 8425333 9240934 10267083 11537966 13079460 14880372 12881816 13867957 16317921 22227415 ...\n $ gdpPercap: num [1:1704] 779 821 853 836 740 ...\n\n\n\nglimpse(gapminder)\n\nRows: 1,704\nColumns: 6\n$ country   <fct> \"Afghanistan\", \"Afghanistan\", \"Afghanistan\", \"Afghanistan\", ~\n$ continent <fct> Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asia, ~\n$ year      <int> 1952, 1957, 1962, 1967, 1972, 1977, 1982, 1987, 1992, 1997, ~\n$ lifeExp   <dbl> 28.801, 30.332, 31.997, 34.020, 36.088, 38.438, 39.854, 40.8~\n$ pop       <int> 8425333, 9240934, 10267083, 11537966, 13079460, 14880372, 12~\n$ gdpPercap <dbl> 779.4453, 820.8530, 853.1007, 836.1971, 739.9811, 786.1134, ~\n\n\n\nhead(gapminder) #shows first n-rows, 6 by default\n\n\n\nA tibble: 6 × 6\n\n    countrycontinentyearlifeExppopgdpPercap\n    <fct><fct><int><dbl><int><dbl>\n\n\n    AfghanistanAsia195228.801 8425333779.4453\n    AfghanistanAsia195730.332 9240934820.8530\n    AfghanistanAsia196231.99710267083853.1007\n    AfghanistanAsia196734.02011537966836.1971\n    AfghanistanAsia197236.08813079460739.9811\n    AfghanistanAsia197738.43814880372786.1134\n\n\n\n\n\ntail(gapminder) #shows last n-rows, 6 by default\n\n\n\nA tibble: 6 × 6\n\n    countrycontinentyearlifeExppopgdpPercap\n    <fct><fct><int><dbl><int><dbl>\n\n\n    ZimbabweAfrica198260.363 7636524788.8550\n    ZimbabweAfrica198762.351 9216418706.1573\n    ZimbabweAfrica199260.37710704340693.4208\n    ZimbabweAfrica199746.80911404948792.4500\n    ZimbabweAfrica200239.98911926563672.0386\n    ZimbabweAfrica200743.48712311143469.7093\n\n\n\n\n\nsummary(gapminder)\n\n        country        continent        year         lifeExp     \n Afghanistan:  12   Africa  :624   Min.   :1952   Min.   :23.60  \n Albania    :  12   Americas:300   1st Qu.:1966   1st Qu.:48.20  \n Algeria    :  12   Asia    :396   Median :1980   Median :60.71  \n Angola     :  12   Europe  :360   Mean   :1980   Mean   :59.47  \n Argentina  :  12   Oceania : 24   3rd Qu.:1993   3rd Qu.:70.85  \n Australia  :  12                  Max.   :2007   Max.   :82.60  \n (Other)    :1632                                                \n      pop              gdpPercap       \n Min.   :6.001e+04   Min.   :   241.2  \n 1st Qu.:2.794e+06   1st Qu.:  1202.1  \n Median :7.024e+06   Median :  3531.8  \n Mean   :2.960e+07   Mean   :  7215.3  \n 3rd Qu.:1.959e+07   3rd Qu.:  9325.5  \n Max.   :1.319e+09   Max.   :113523.1  \n                                       \n\n\n\n\n10.2.2 filter() function\n\naustria <- filter(gapminder, country == \"Austria\")\naustria\n\n\n\nA tibble: 12 × 6\n\n    countrycontinentyearlifeExppopgdpPercap\n    <fct><fct><int><dbl><int><dbl>\n\n\n    AustriaEurope195266.8006927772 6137.076\n    AustriaEurope195767.4806965860 8842.598\n    AustriaEurope196269.540712986410750.721\n    AustriaEurope196770.140737699812834.602\n    AustriaEurope197270.630754420116661.626\n    AustriaEurope197772.170756843019749.422\n    AustriaEurope198273.180757461321597.084\n    AustriaEurope198774.940757890323687.826\n    AustriaEurope199276.040791496927042.019\n    AustriaEurope199777.510806987629095.921\n    AustriaEurope200278.980814831232417.608\n    AustriaEurope200779.829819978336126.493\n\n\n\n\nfilter() takes logical expressions and returns the rows for which all are TRUE.\n\n# task: select rows with lifeExp less than 31\nfilter(gapminder, lifeExp < 31)\n\n\n\nA tibble: 6 × 6\n\n    countrycontinentyearlifeExppopgdpPercap\n    <fct><fct><int><dbl><int><dbl>\n\n\n    Afghanistan Asia  195228.8018425333 779.4453\n    Afghanistan Asia  195730.3329240934 820.8530\n    Angola      Africa195230.01542320953520.6103\n    Gambia      Africa195230.000 284320 485.2307\n    Rwanda      Africa199223.5997290203 737.0686\n    Sierra LeoneAfrica195230.3312143249 879.7877\n\n\n\n\n\n# task: select Austria only and year after 1980\nfilter(gapminder, country == \"Austria\", year > 1980)\n\n\n\nA tibble: 6 × 6\n\n    countrycontinentyearlifeExppopgdpPercap\n    <fct><fct><int><dbl><int><dbl>\n\n\n    AustriaEurope198273.180757461321597.08\n    AustriaEurope198774.940757890323687.83\n    AustriaEurope199276.040791496927042.02\n    AustriaEurope199777.510806987629095.92\n    AustriaEurope200278.980814831232417.61\n    AustriaEurope200779.829819978336126.49\n\n\n\n\n\n# task: select Austria and Belgium\nfilter(gapminder, country %in% c(\"Austria\", \"Belgium\"))\n\n\n\nA tibble: 24 × 6\n\n    countrycontinentyearlifeExppopgdpPercap\n    <fct><fct><int><dbl><int><dbl>\n\n\n    AustriaEurope195266.800 6927772 6137.076\n    AustriaEurope195767.480 6965860 8842.598\n    AustriaEurope196269.540 712986410750.721\n    AustriaEurope196770.140 737699812834.602\n    AustriaEurope197270.630 754420116661.626\n    AustriaEurope197772.170 756843019749.422\n    AustriaEurope198273.180 757461321597.084\n    AustriaEurope198774.940 757890323687.826\n    AustriaEurope199276.040 791496927042.019\n    AustriaEurope199777.510 806987629095.921\n    AustriaEurope200278.980 814831232417.608\n    AustriaEurope200779.829 819978336126.493\n    BelgiumEurope195268.000 8730405 8343.105\n    BelgiumEurope195769.240 8989111 9714.961\n    BelgiumEurope196270.250 921840010991.207\n    BelgiumEurope196770.940 955650013149.041\n    BelgiumEurope197271.440 970910016672.144\n    BelgiumEurope197772.800 982180019117.974\n    BelgiumEurope198273.930 985630320979.846\n    BelgiumEurope198775.350 987020022525.563\n    BelgiumEurope199276.4601004562225575.571\n    BelgiumEurope199777.5301019978727561.197\n    BelgiumEurope200278.3201031197030485.884\n    BelgiumEurope200779.4411039222633692.605\n\n\n\n\nLets rewrite initial code and record it to the variable/data.frame:\n\n\n10.2.3 Pipe (%>%) operator\n%>% is pipe operator. The pipe operator takes the thing on the left-hand-side and pipes it into the function call on the right-hand-side – literally, drops it in as the first argument.\nhead() function without pipe and top 4 items:\n\nIn R version before 4.1.0 pipe %>% operator is not a language build-in and you should install magrittr package:\n\n\nPipe opertor in R 4.1+ |>, using this is preferable\n\n\n#install.packages(\"magrittr\") # for pipe %>% operator\nlibrary(magrittr)\n\n\nhead(gapminder, n = 4)\n\n\n\nA tibble: 4 × 6\n\n    countrycontinentyearlifeExppopgdpPercap\n    <fct><fct><int><dbl><int><dbl>\n\n\n    AfghanistanAsia195228.801 8425333779.4453\n    AfghanistanAsia195730.332 9240934820.8530\n    AfghanistanAsia196231.99710267083853.1007\n    AfghanistanAsia196734.02011537966836.1971\n\n\n\n\nhead() function with pipe and top 4 items:\n\ngapminder %>% head(4)\n\n\n\nA tibble: 4 × 6\n\n    countrycontinentyearlifeExppopgdpPercap\n    <fct><fct><int><dbl><int><dbl>\n\n\n    AfghanistanAsia195228.801 8425333779.4453\n    AfghanistanAsia195730.332 9240934820.8530\n    AfghanistanAsia196231.99710267083853.1007\n    AfghanistanAsia196734.02011537966836.1971\n\n\n\n\nOutput is the same. So, let’s rewrire filtering for Austria with pipe:\n\naustria <- gapminder %>% filter(country == \"Austria\")\naustria\n\n\n\nA tibble: 12 × 6\n\n    countrycontinentyearlifeExppopgdpPercap\n    <fct><fct><int><dbl><int><dbl>\n\n\n    AustriaEurope195266.8006927772 6137.076\n    AustriaEurope195767.4806965860 8842.598\n    AustriaEurope196269.540712986410750.721\n    AustriaEurope196770.140737699812834.602\n    AustriaEurope197270.630754420116661.626\n    AustriaEurope197772.170756843019749.422\n    AustriaEurope198273.180757461321597.084\n    AustriaEurope198774.940757890323687.826\n    AustriaEurope199276.040791496927042.019\n    AustriaEurope199777.510806987629095.921\n    AustriaEurope200278.980814831232417.608\n    AustriaEurope200779.829819978336126.493\n\n\n\n\n\n# add more conditions in filter\naustria <- gapminder %>% filter(country == \"Austria\", year > 2000)\naustria\n\n\n\nA tibble: 2 × 6\n\n    countrycontinentyearlifeExppopgdpPercap\n    <fct><fct><int><dbl><int><dbl>\n\n\n    AustriaEurope200278.980814831232417.61\n    AustriaEurope200779.829819978336126.49\n\n\n\n\n\n\n\n10.2.4 select() function\nUse select() to subset the data on variables/columns by names or index. You also can define order of columns with select().\n\ngapminder %>% \nselect(year, country, pop) %>%\nslice(1: 10)\n\n\n\nA tibble: 10 × 3\n\n    yearcountrypop\n    <int><fct><int>\n\n\n    1952Afghanistan 8425333\n    1957Afghanistan 9240934\n    1962Afghanistan10267083\n    1967Afghanistan11537966\n    1972Afghanistan13079460\n    1977Afghanistan14880372\n    1982Afghanistan12881816\n    1987Afghanistan13867957\n    1992Afghanistan16317921\n    1997Afghanistan22227415\n\n\n\n\nLets combine few functions with pipe (%>%):\nFinally, lest extend our filtering:\n\n# compare dplyr syntax with base R call\ngapminder[gapminder$country == \"Austria\", c(\"year\", \"pop\", \"lifeExp\")]\n\ngapminder %>% \nfilter(country == \"Austria\") %>%\nselect(year, pop, lifeExp)\n\n\n\nA tibble: 12 × 3\n\n    yearpoplifeExp\n    <int><int><dbl>\n\n\n    1952692777266.800\n    1957696586067.480\n    1962712986469.540\n    1967737699870.140\n    1972754420170.630\n    1977756843072.170\n    1982757461373.180\n    1987757890374.940\n    1992791496976.040\n    1997806987677.510\n    2002814831278.980\n    2007819978379.829\n\n\n\n\n\n\nA tibble: 12 × 3\n\n    yearpoplifeExp\n    <int><int><dbl>\n\n\n    1952692777266.800\n    1957696586067.480\n    1962712986469.540\n    1967737699870.140\n    1972754420170.630\n    1977756843072.170\n    1982757461373.180\n    1987757890374.940\n    1992791496976.040\n    1997806987677.510\n    2002814831278.980\n    2007819978379.829\n\n\n\n\nYou can remove some columns using minus(operator) and add few filter conditions:\n\naustria <- gapminder %>% \n                filter(country == \"Austria\", year > 2000) %>%\n                select(-continent, -gdpPercap) %>%\n                head()\naustria\n\n\n\nA tibble: 2 × 4\n\n    countryyearlifeExppop\n    <fct><int><dbl><int>\n\n\n    Austria200278.9808148312\n    Austria200779.8298199783\n\n\n\n\nYou can insert different conditions about columns you need to select.\n\ngapminder %>%\n    select(!where(is.numeric)) %>%  # its 1704 records, because of repeating some records\n    slice(1:5)\n\n\n\nA tibble: 5 × 2\n\n    countrycontinent\n    <fct><fct>\n\n\n    AfghanistanAsia\n    AfghanistanAsia\n    AfghanistanAsia\n    AfghanistanAsia\n    AfghanistanAsia\n\n\n\n\nLet’s output all unique pairs continent -> country with distinct() function:\n\ngapminder %>%\n    select(country) %>%\n    distinct() # its 142 records now\n\n\n\nA tibble: 142 × 1\n\n    country\n    <fct>\n\n\n    Afghanistan             \n    Albania                 \n    Algeria                 \n    Angola                  \n    Argentina               \n    Australia               \n    Austria                 \n    Bahrain                 \n    Bangladesh              \n    Belgium                 \n    Benin                   \n    Bolivia                 \n    Bosnia and Herzegovina  \n    Botswana                \n    Brazil                  \n    Bulgaria                \n    Burkina Faso            \n    Burundi                 \n    Cambodia                \n    Cameroon                \n    Canada                  \n    Central African Republic\n    Chad                    \n    Chile                   \n    China                   \n    Colombia                \n    Comoros                 \n    Congo, Dem. Rep.        \n    Congo, Rep.             \n    Costa Rica              \n    ...\n    Sierra Leone       \n    Singapore          \n    Slovak Republic    \n    Slovenia           \n    Somalia            \n    South Africa       \n    Spain              \n    Sri Lanka          \n    Sudan              \n    Swaziland          \n    Sweden             \n    Switzerland        \n    Syria              \n    Taiwan             \n    Tanzania           \n    Thailand           \n    Togo               \n    Trinidad and Tobago\n    Tunisia            \n    Turkey             \n    Uganda             \n    United Kingdom     \n    United States      \n    Uruguay            \n    Venezuela          \n    Vietnam            \n    West Bank and Gaza \n    Yemen, Rep.        \n    Zambia             \n    Zimbabwe           \n\n\n\n\n\n\n\n10.2.5 Selecting random \\(N\\) rows\nThe sample_n() function selects random rows from a data frame\n\ngapminder %>% sample_n(5)\n\n\n\nA tibble: 5 × 6\n\n    countrycontinentyearlifeExppopgdpPercap\n    <fct><fct><int><dbl><int><dbl>\n\n\n    Norway          Europe  197274.340393300418965.0555\n    Liberia         Africa  197743.7641703617  640.3224\n    Jamaica         Americas199772.2622531311 7121.9247\n    Jamaica         Americas195762.6101535090 4756.5258\n    Hong Kong, ChinaAsia    200281.495676247630209.0152\n\n\n\n\nIf you want make pseudo-random generation reprodusable use set.seed(). Seed is start point of random generation. Different seeds give different output.\n\nset.seed(2021) # example, seed = 2021\n\nThe sample_frac() function selects random fraction rows from a data frame. Let’s select \\(1\\%\\) of data\n\nset.seed(2021) # output not changing, uncomment it \ngapminder %>% sample_frac(0.1)\n\n\n\nA tibble: 170 × 6\n\n    countrycontinentyearlifeExppopgdpPercap\n    <fct><fct><int><dbl><int><dbl>\n\n\n    Libya              Africa  196247.808 1441863 6757.0308\n    Botswana           Africa  199752.556 1536536 8647.1423\n    Swaziland          Africa  195743.424  326741 1244.7084\n    Dominican Republic Americas199769.957 7992357 3614.1013\n    Iraq               Asia    200257.04624001816 4390.7173\n    Libya              Africa  198766.234 379984511770.5898\n    Montenegro         Europe  196767.178  501035 5907.8509\n    New Zealand        Oceania 195770.260 222940712247.3953\n    Bulgaria           Europe  200773.005 732285810680.7928\n    Malawi             Africa  199747.49510419991  692.2758\n    Venezuela          Americas197767.4561350356313143.9510\n    Guinea             Africa  199751.455 8048834  869.4498\n    Congo, Dem. Rep.   Africa  195239.14314100005  780.5423\n    Eritrea            Africa  196240.158 1666618  380.9958\n    Bangladesh         Asia    198250.00993074406  676.9819\n    Cote d'Ivoire      Africa  195240.477 2977019 1388.5947\n    Trinidad and TobagoAmericas200268.976 110183211460.6002\n    Sierra Leone       Africa  200742.568 6144562  862.5408\n    Malaysia           Asia    200273.0442266236510206.9779\n    Mali               Africa  198746.364 7634008  684.1716\n    Pakistan           Asia    197754.04378152686 1175.9212\n    Norway             Europe  198275.970 411478726298.6353\n    Peru               Americas200771.42128674757 7408.9056\n    Haiti              Americas195237.579 3201488 1840.3669\n    Cuba               Americas196265.246 7254373 5180.7559\n    Costa Rica         Americas200778.782 4133884 9645.0614\n    France             Europe  199778.6405862342825889.7849\n    Botswana           Africa  198763.622 1151184 6205.8839\n    Bangladesh         Asia    197245.25270759295  630.2336\n    Congo, Rep.        Africa  197755.625 1536769 3259.1790\n    ..................\n    Mozambique Africa  197240.328  9809596  724.9178\n    Nicaragua  Americas197255.151  2182908 4688.5933\n    Turkey     Europe  197257.005 37492953 3450.6964\n    Gabon      Africa  200256.761  129930412521.7139\n    Ecuador    Americas195751.356  4058385 3780.5467\n    Honduras   Americas197253.884  2965146 2529.8423\n    Paraguay   Americas195262.649  1555876 1952.3087\n    Guinea     Africa  200756.007  9947814  942.6542\n    SwitzerlandEurope  197775.390  631642426982.2905\n    Honduras   Americas196248.041  2090162 2291.1568\n    Thailand   Asia    195250.848 21289402  757.7974\n    Portugal   Europe  195761.510  8817650 3774.5717\n    Cuba       Americas198774.174 10239839 7532.9248\n    Brazil     Americas199769.388168546719 7957.9808\n    Madagascar Africa  196240.848  5703324 1643.3871\n    Mauritius  Africa  198266.711   992040 3688.0377\n    Ghana      Africa  198253.744 11400338  876.0326\n    Congo, Rep.Africa  198757.470  2064095 4201.1949\n    Haiti      Americas197749.923  4908554 1874.2989\n    Portugal   Europe  195259.820  8526050 3068.3199\n    Angola     Africa  198239.942  7016384 2756.9537\n    Swaziland  Africa  199754.289  1054486 3876.7685\n    Norway     Europe  199277.320  428635733965.6611\n    Austria    Europe  197270.630  754420116661.6256\n    Croatia    Europe  195764.770  3991242 4338.2316\n    New ZealandOceania 195269.390  199479410556.5757\n    Angola     Africa  200742.731 12420476 4797.2313\n    Sudan      Africa  200758.556 42292929 2602.3950\n    Poland     Europe  196267.640 30329617 5338.7521\n    Japan      Asia    197273.42010718827314778.7864\n\n\n\n\n\n\n\n10.2.6 Subset rows using their positions with slice()\nDescription\n\nslice() lets you index rows by their (integer) locations. It allows you to select, remove, and duplicate rows. It is accompanied by a number of helpers for common use cases:\nslice_head() and slice_tail() select the first or last rows.\nslice_sample() randomly selects rows.\nslice_min() and slice_max() select rows with highest or lowest values of a variable.\n\nIf .data is a grouped_df, the operation will be performed on each group, so that (e.g.) slice_head(df, n = 5) will select the first five rows in each group.\nSamples\n\ngapminder %>% slice(1) # top 1 row\n\n\n\nA tibble: 1 × 6\n\n    countrycontinentyearlifeExppopgdpPercap\n    <fct><fct><int><dbl><int><dbl>\n\n\n    AfghanistanAsia195228.8018425333779.4453\n\n\n\n\n\ngapminder %>% slice(1:6) # top n = 6\n\n\n\nA tibble: 6 × 6\n\n    countrycontinentyearlifeExppopgdpPercap\n    <fct><fct><int><dbl><int><dbl>\n\n\n    AfghanistanAsia195228.801 8425333779.4453\n    AfghanistanAsia195730.332 9240934820.8530\n    AfghanistanAsia196231.99710267083853.1007\n    AfghanistanAsia196734.02011537966836.1971\n    AfghanistanAsia197236.08813079460739.9811\n    AfghanistanAsia197738.43814880372786.1134\n\n\n\n\n\ngapminder %>% slice_head(n = 6) # works like head()\n\n\n\nA tibble: 6 × 6\n\n    countrycontinentyearlifeExppopgdpPercap\n    <fct><fct><int><dbl><int><dbl>\n\n\n    AfghanistanAsia195228.801 8425333779.4453\n    AfghanistanAsia195730.332 9240934820.8530\n    AfghanistanAsia196231.99710267083853.1007\n    AfghanistanAsia196734.02011537966836.1971\n    AfghanistanAsia197236.08813079460739.9811\n    AfghanistanAsia197738.43814880372786.1134\n\n\n\n\n\ngapminder %>% slice_tail(n = 5) # works like tail()\n\n\n\nA tibble: 5 × 6\n\n    countrycontinentyearlifeExppopgdpPercap\n    <fct><fct><int><dbl><int><dbl>\n\n\n    ZimbabweAfrica198762.351 9216418706.1573\n    ZimbabweAfrica199260.37710704340693.4208\n    ZimbabweAfrica199746.80911404948792.4500\n    ZimbabweAfrica200239.98911926563672.0386\n    ZimbabweAfrica200743.48712311143469.7093\n\n\n\n\nYou can drop some recods with negative indexes:\n\ngapminder %>% slice(-c(1:3,5)) %>% # remove Afganistan years 1952, 1957, 1962 and 1972 \n    head(6)\n\n\n\nA tibble: 6 × 6\n\n    countrycontinentyearlifeExppopgdpPercap\n    <fct><fct><int><dbl><int><dbl>\n\n\n    AfghanistanAsia196734.02011537966836.1971\n    AfghanistanAsia197738.43814880372786.1134\n    AfghanistanAsia198239.85412881816978.0114\n    AfghanistanAsia198740.82213867957852.3959\n    AfghanistanAsia199241.67416317921649.3414\n    AfghanistanAsia199741.76322227415635.3414\n\n\n\n\n\n# Random rows selection with slice_sample()\ngapminder %>% slice_sample(n = 5) #use set.seed() to fix random\n\n\n\nA tibble: 5 × 6\n\n    countrycontinentyearlifeExppopgdpPercap\n    <fct><fct><int><dbl><int><dbl>\n\n\n    Cambodia        Asia  200256.75212926707  896.2260\n    Poland          Europe200274.6703862597612002.2391\n    Bulgaria        Europe197270.900 8576200 6597.4944\n    Congo, Dem. Rep.Africa195239.14314100005  780.5423\n    Chad            Africa200250.525 8835739 1156.1819\n\n\n\n\n\n# Rows with minimum and maximum values of a variable\n# Lets find top 5 records with minimum and maximum lifeExp in all dataset\ngapminder %>% slice_min(lifeExp, n = 5)\ngapminder %>% slice_max(lifeExp, n = 5)\n\n\n\nA tibble: 5 × 6\n\n    countrycontinentyearlifeExppopgdpPercap\n    <fct><fct><int><dbl><int><dbl>\n\n\n    Rwanda      Africa199223.5997290203 737.0686\n    Afghanistan Asia  195228.8018425333 779.4453\n    Gambia      Africa195230.000 284320 485.2307\n    Angola      Africa195230.01542320953520.6103\n    Sierra LeoneAfrica195230.3312143249 879.7877\n\n\n\n\n\n\nA tibble: 5 × 6\n\n    countrycontinentyearlifeExppopgdpPercap\n    <fct><fct><int><dbl><int><dbl>\n\n\n    Japan           Asia  200782.60312746797231656.07\n    Hong Kong, ChinaAsia  200782.208  698041239724.98\n    Japan           Asia  200282.00012706584128604.59\n    Iceland         Europe200781.757   30193136180.79\n    Switzerland     Europe200781.701  755466137506.42\n\n\n\n\n\n\n\n10.2.7 Sorting with arrange()\narrange(.data, …) function order rows by values of a column or columns (low to high)You can use with desc() to order from high to low.\nFor example, we need to select top 10 countries in 2002 by lifeExp variable.\n\ndata2002 <- gapminder %>% \n                filter(year == 2002) %>%\n                top_n(10, lifeExp) # select top 10 by lifeExp value\ndata2002\n\n\n\nA tibble: 10 × 6\n\n    countrycontinentyearlifeExppopgdpPercap\n    <fct><fct><int><dbl><int><dbl>\n\n\n    Australia       Oceania 200280.370 1954679230687.75\n    Canada          Americas200279.770 3190226833328.97\n    Hong Kong, ChinaAsia    200281.495  676247630209.02\n    Iceland         Europe  200280.500   28803031163.20\n    Israel          Asia    200279.696  602952921905.60\n    Italy           Europe  200280.240 5792699927968.10\n    Japan           Asia    200282.00012706584128604.59\n    Spain           Europe  200279.780 4015251724835.47\n    Sweden          Europe  200280.040  895417529341.63\n    Switzerland     Europe  200280.620  736175734480.96\n\n\n\n\n\n# sort by pop\nt <- gapminder %>% arrange(continent)\nt <- gapminder %>% arrange(continent,  country)\nt <- gapminder %>% arrange(continent, desc( country))\nhead(t)\n\n\n\nA tibble: 6 × 6\n\n    countrycontinentyearlifeExppopgdpPercap\n    <fct><fct><int><dbl><int><dbl>\n\n\n    ZimbabweAfrica195248.4513080907406.8841\n    ZimbabweAfrica195750.4693646340518.7643\n    ZimbabweAfrica196252.3584277736527.2722\n    ZimbabweAfrica196753.9954995432569.7951\n    ZimbabweAfrica197255.6355861135799.3622\n    ZimbabweAfrica197757.6746642107685.5877\n\n\n\n\n\n\n\n10.2.8 Create new variables with mutate()\nmutate(.data, …) compute new column(s). Lets compute new column for data2002 \\(gdpTotal = gdpPercap * pop / 1000000\\).\n\ngapminder %>% \n    mutate(gdpTotal = gdpPercap * pop) %>%\n    head(10)\n\n\n\nA tibble: 10 × 7\n\n    countrycontinentyearlifeExppopgdpPercapgdpTotal\n    <fct><fct><int><dbl><int><dbl><dbl>\n\n\n    AfghanistanAsia195228.801 8425333779.4453 6567086330\n    AfghanistanAsia195730.332 9240934820.8530 7585448670\n    AfghanistanAsia196231.99710267083853.1007 8758855797\n    AfghanistanAsia196734.02011537966836.1971 9648014150\n    AfghanistanAsia197236.08813079460739.9811 9678553274\n    AfghanistanAsia197738.43814880372786.113411697659231\n    AfghanistanAsia198239.85412881816978.011412598563401\n    AfghanistanAsia198740.82213867957852.395911820990309\n    AfghanistanAsia199241.67416317921649.341410595901589\n    AfghanistanAsia199741.76322227415635.341414121995875\n\n\n\n\ntransmute(.data, …) compute new column(s), drop others.\n\ngapminder %>% \n    transmute(gdpTotal = gdpPercap * pop) %>%\n    head(10)\n\n\n\nA tibble: 10 × 1\n\n    gdpTotal\n    <dbl>\n\n\n     6567086330\n     7585448670\n     8758855797\n     9648014150\n     9678553274\n    11697659231\n    12598563401\n    11820990309\n    10595901589\n    14121995875\n\n\n\n\nYou can mutate many columns at once:\n\ngapminder %>% \n    mutate(gdpTotal = gdpPercap * pop,\n           countryUpper = toupper(country), # uppercase country\n           lifeExpRounded = round(lifeExp)) %>%\n    head(10)\n\n\n\nA tibble: 10 × 9\n\n    countrycontinentyearlifeExppopgdpPercapgdpTotalcountryUpperlifeExpRounded\n    <fct><fct><int><dbl><int><dbl><dbl><chr><dbl>\n\n\n    AfghanistanAsia195228.801 8425333779.4453 6567086330AFGHANISTAN29\n    AfghanistanAsia195730.332 9240934820.8530 7585448670AFGHANISTAN30\n    AfghanistanAsia196231.99710267083853.1007 8758855797AFGHANISTAN32\n    AfghanistanAsia196734.02011537966836.1971 9648014150AFGHANISTAN34\n    AfghanistanAsia197236.08813079460739.9811 9678553274AFGHANISTAN36\n    AfghanistanAsia197738.43814880372786.113411697659231AFGHANISTAN38\n    AfghanistanAsia198239.85412881816978.011412598563401AFGHANISTAN40\n    AfghanistanAsia198740.82213867957852.395911820990309AFGHANISTAN41\n    AfghanistanAsia199241.67416317921649.341410595901589AFGHANISTAN42\n    AfghanistanAsia199741.76322227415635.341414121995875AFGHANISTAN42\n\n\n\n\nYou also can edit existing column (let’s change continent Europe to EU in dataframe):\n\ndata2002 %>%\n    mutate(continent = as.character(continent), # convert factor -> character \n           continent = ifelse(continent == \"Europe\", \"EU\", continent))\n\n\n\nA tibble: 10 × 6\n\n    countrycontinentyearlifeExppopgdpPercap\n    <fct><chr><int><dbl><int><dbl>\n\n\n    Australia       Oceania 200280.370 1954679230687.75\n    Canada          Americas200279.770 3190226833328.97\n    Hong Kong, ChinaAsia    200281.495  676247630209.02\n    Iceland         EU      200280.500   28803031163.20\n    Israel          Asia    200279.696  602952921905.60\n    Italy           EU      200280.240 5792699927968.10\n    Japan           Asia    200282.00012706584128604.59\n    Spain           EU      200279.780 4015251724835.47\n    Sweden          EU      200280.040  895417529341.63\n    Switzerland     EU      200280.620  736175734480.96\n\n\n\n\n\n\n\n10.2.9 Renaming columns with rename()\nrename(.data, …) rename columns. Let’s rename column pop to poulation:\n\ngapminder %>% \n    rename(population = pop) %>%\n    head(10)\n\n\n\nA tibble: 10 × 6\n\n    countrycontinentyearlifeExppopulationgdpPercap\n    <fct><fct><int><dbl><int><dbl>\n\n\n    AfghanistanAsia195228.801 8425333779.4453\n    AfghanistanAsia195730.332 9240934820.8530\n    AfghanistanAsia196231.99710267083853.1007\n    AfghanistanAsia196734.02011537966836.1971\n    AfghanistanAsia197236.08813079460739.9811\n    AfghanistanAsia197738.43814880372786.1134\n    AfghanistanAsia198239.85412881816978.0114\n    AfghanistanAsia198740.82213867957852.3959\n    AfghanistanAsia199241.67416317921649.3414\n    AfghanistanAsia199741.76322227415635.3414\n\n\n\n\n\n\n\n10.2.10 Calculations with group_by() + summarise()\ngroup_by(.data, ..., add = FALSE) returns copy of table grouped by defined columns.\nLet’s find average by lifeExp for each continent in 2002 (ouput is continent, lifeExpAvg2002, countriesCount, year = 2002):\n\ngapminder %>%\n    filter(year == 2002) %>% # year\n    group_by(continent, year) %>% # grouping condition\n    summarise(\n        lifeExpAvg2002 = mean(lifeExp),\n        countriesCount = n() # n() count of rows in group  \n        ) \n\n`summarise()` has grouped output by 'continent'. You can override using the\n`.groups` argument.\n\n\n\n\nA grouped_df: 5 × 4\n\n    continentyearlifeExpAvg2002countriesCount\n    <fct><int><dbl><int>\n\n\n    Africa  200253.3252352\n    Americas200272.4220425\n    Asia    200269.2338833\n    Europe  200276.7006030\n    Oceania 200279.74000 2\n\n\n\n\nLet’s find total population for each continent in 2002 (ouput is continent, totalPop, year):\n\ngapminder %>%\n    filter(year == 2002) %>% # year\n    group_by(continent, year) %>% # grouping condition\n    summarise(totalPop = sum(pop), .groups = \"keep\") \n\n\n\nA grouped_df: 5 × 3\n\n    continentyeartotalPop\n    <fct><int><dbl>\n\n\n    Africa  2002 833723916\n    Americas2002 849772762\n    Asia    20023601802203\n    Europe  2002 578223869\n    Oceania 2002  23454829\n\n\n\n\nThere are additional variations of summarise():\n\nsummarise_all() - Apply funs to every column.\nsummarise_at() - Apply funs to specific columns.\n\nsummarise_if() - Apply funs to all cols of one type.\n\n\n\n\n10.2.11 Task on Credits\n\nlibrary(ISLR)\n\ngroup_inc <- aggregate(Income ~ Age + Gender, data = Credit, mean)\n\nm_data <- group_inc[group_inc$Gender == \" Male\", ]\nnrow(m_data)\n\nf_data <- group_inc[group_inc$Gender == \"Female\", ]\nnrow(f_data)\nwith(m_data, plot(Age, Income, type = \"l\", col=\"red\"))\nwith(f_data, lines(Age, Income, type = \"l\", col =\"blue\"))\n\n63\n\n\n62\n\n\n\n\n\n\ncd <- Credit %>%\nselect(Income, Age, Gender) %>%\ngroup_by(Age, Gender) %>%\nsummarize(Income = mean(Income))\n\nm_data <- cd %>% filter(Gender == \" Male\")\nnrow(m_data)\n\nf_data <- cd %>% filter(Gender == \"Female\")\nnrow(f_data)\n\nwith(m_data, plot(Age, Income, type = \"l\", col=\"red\"))\nwith(f_data, lines(Age, Income, type = \"l\", col =\"blue\"))\n\n`summarise()` has grouped output by 'Age'. You can override using the `.groups`\nargument.\n\n\n63\n\n\n62\n\n\n\n\n\n\n\n\n10.2.12 Binding rows and columns\nbind_rows(.data, …) helps to unite two dataframes with the same columns order and names.\nSo, if we need add one data frame to an other vertically (bind rows) we shoul use bind_rows:\n\nd2002 <- gapminder %>%\n            filter(year == 2002) %>% # year\n            group_by(continent, year) %>% # grouping condition\n            summarise(\n                lifeExpAvg = mean(lifeExp),\n                countriesCount = n() # n() count of rows in group                \n            )\nhead(d2002)\n\n`summarise()` has grouped output by 'continent'. You can override using the\n`.groups` argument.\n\n\n\n\nA grouped_df: 5 × 4\n\n    continentyearlifeExpAvgcountriesCount\n    <fct><int><dbl><int>\n\n\n    Africa  200253.3252352\n    Americas200272.4220425\n    Asia    200269.2338833\n    Europe  200276.7006030\n    Oceania 200279.74000 2\n\n\n\n\n\nd2007 <- gapminder %>%\n            filter(year == 2007) %>% # year\n            group_by(continent, year) %>% # grouping condition\n            summarise(\n                lifeExpAvg = mean(lifeExp),\n                countriesCount = n() # n() count of rows in group                \n            )\nhead(d2007)\n\n`summarise()` has grouped output by 'continent'. You can override using the\n`.groups` argument.\n\n\n\n\nA grouped_df: 5 × 4\n\n    continentyearlifeExpAvgcountriesCount\n    <fct><int><dbl><int>\n\n\n    Africa  200754.8060452\n    Americas200773.6081225\n    Asia    200770.7284833\n    Europe  200777.6486030\n    Oceania 200780.71950 2\n\n\n\n\nUnite them:\n\nd2002 %>% bind_rows(d2007) ## bind rows\n\n\n\nA grouped_df: 10 × 4\n\n    continentyearlifeExpAvgcountriesCount\n    <fct><int><dbl><int>\n\n\n    Africa  200253.3252352\n    Americas200272.4220425\n    Asia    200269.2338833\n    Europe  200276.7006030\n    Oceania 200279.74000 2\n    Africa  200754.8060452\n    Americas200773.6081225\n    Asia    200770.7284833\n    Europe  200777.6486030\n    Oceania 200780.71950 2\n\n\n\n\nbind_cols(.data, …) helps to unite two dataframes with the same rows count.\n\ngrouped_data2002pop <- gapminder %>%\n    filter(year == 2002) %>% # year\n    group_by(continent) %>% # grouping condition\n    summarise(totalPop = sum(pop)) %>%\n    mutate(year = 2002)\ngrouped_data2002pop\n\n\n\nA tibble: 5 × 3\n\n    continenttotalPopyear\n    <fct><dbl><dbl>\n\n\n    Africa   8337239162002\n    Americas 8497727622002\n    Asia    36018022032002\n    Europe   5782238692002\n    Oceania   234548292002\n\n\n\n\nLet’s combine d2002 and grouped_data2002pop:\n\ngrouped_data <- d2002 %>% \n    bind_cols(grouped_data2002pop)\ngrouped_data\n\n# columns with the same name were renamed!\n\nNew names:\n* `continent` -> `continent...1`\n* `year` -> `year...2`\n* `continent` -> `continent...5`\n* `year` -> `year...7`\n\n\n\n\nA tibble: 5 × 7\n\n    continent...1year...2lifeExpAvgcountriesCountcontinent...5totalPopyear...7\n    <fct><int><dbl><int><fct><dbl><dbl>\n\n\n    Africa  200253.3252352Africa   8337239162002\n    Americas200272.4220425Americas 8497727622002\n    Asia    200269.2338833Asia    36018022032002\n    Europe  200276.7006030Europe   5782238692002\n    Oceania 200279.74000 2Oceania   234548292002\n\n\n\n\nYou can remove same named variables before binding:\n\ngrouped_data <- d2002 %>% \n    bind_cols(grouped_data2002pop %>%\n              select(-continent, -year))\ngrouped_data\n\n# better, but continents order is not the same in both frames \n# your data is going to be damaged\n\n\n\nA grouped_df: 5 × 5\n\n    continentyearlifeExpAvgcountriesCounttotalPop\n    <fct><int><dbl><int><dbl>\n\n\n    Africa  200253.3252352 833723916\n    Americas200272.4220425 849772762\n    Asia    200269.23388333601802203\n    Europe  200276.7006030 578223869\n    Oceania 200279.74000 2  23454829\n\n\n\n\n\ngrouped_data2002pop <- grouped_data2002pop %>% \n    arrange(totalPop)\n\ngrouped_data <- d2002 %>% \n    bind_cols(grouped_data2002pop)\ngrouped_data\n\n# you can see that continent fields different in the same row\n\nNew names:\n* `continent` -> `continent...1`\n* `year` -> `year...2`\n* `continent` -> `continent...5`\n* `year` -> `year...7`\n\n\n\n\nA tibble: 5 × 7\n\n    continent...1year...2lifeExpAvgcountriesCountcontinent...5totalPopyear...7\n    <fct><int><dbl><int><fct><dbl><dbl>\n\n\n    Africa  200253.3252352Oceania   234548292002\n    Americas200272.4220425Europe   5782238692002\n    Asia    200269.2338833Africa   8337239162002\n    Europe  200276.7006030Americas 8497727622002\n    Oceania 200279.74000 2Asia    36018022032002\n\n\n\n\n\n\n\n10.2.13 Join()ing data\nTo solve previous problem you can use set of join()-functions. left_join() can solve our previous example:\n\ngrouped_data2002pop <- grouped_data2002pop %>% \n    arrange(totalPop)\n\ngrouped_data <- d2002 %>% \n    left_join(grouped_data2002pop, by = \"continent\")\ngrouped_data\n\n# but we have duplicated year\n\n\n\nA grouped_df: 5 × 6\n\n    continentyear.xlifeExpAvgcountriesCounttotalPopyear.y\n    <fct><int><dbl><int><dbl><dbl>\n\n\n    Africa  200253.3252352 8337239162002\n    Americas200272.4220425 8497727622002\n    Asia    200269.233883336018022032002\n    Europe  200276.7006030 5782238692002\n    Oceania 200279.74000 2  234548292002\n\n\n\n\n\ngrouped_data2002pop <- grouped_data2002pop %>% \n    arrange(totalPop)\n\ngrouped_data <- d2002 %>% \n    left_join(grouped_data2002pop, by = c(\"continent\", \"year\"))\ngrouped_data\n\n#ok\n\n\n\nA grouped_df: 5 × 5\n\n    continentyearlifeExpAvgcountriesCounttotalPop\n    <fct><dbl><dbl><int><dbl>\n\n\n    Africa  200253.3252352 833723916\n    Americas200272.4220425 849772762\n    Asia    200269.23388333601802203\n    Europe  200276.7006030 578223869\n    Oceania 200279.74000 2  23454829\n\n\n\n\nLet’s make a different data sets for testing join() fucntions:\n\nfirst_df <- data.frame(Letter = c(\"A\", \"B\", \"C\", \"D\", \"E\"),\n                      Value = c(1:5))\n\nsecond_df <- data.frame(Letter = c(\"A\", \"B\", \"C\", \"D\", \"F\"),\n                      Value = c(12, 7, 4, 1, 5))\nfirst_df\nsecond_df \n\n\n\nA data.frame: 5 × 2\n\n    LetterValue\n    <chr><int>\n\n\n    A1\n    B2\n    C3\n    D4\n    E5\n\n\n\n\n\n\nA data.frame: 5 × 2\n\n    LetterValue\n    <chr><dbl>\n\n\n    A12\n    B 7\n    C 4\n    D 1\n    F 5\n\n\n\n\nYou can see that the last row Letter is different in dataframes. left_join() test is next.\n\nfirst_df %>% \n    left_join(second_df, by = \"Letter\")\n# there is no F letter, becouse first_db joined only known first_df Letters.\n\n\n\nA data.frame: 5 × 3\n\n    LetterValue.xValue.y\n    <chr><int><dbl>\n\n\n    A112\n    B2 7\n    C3 4\n    D4 1\n    E5NA\n\n\n\n\n\nfirst_df %>% \n    right_join(second_df, by = \"Letter\")\n# right_join! there is no E letter, becouse first_db joined only known second_df Letters.\n\n\n\nA data.frame: 5 × 3\n\n    LetterValue.xValue.y\n    <chr><int><dbl>\n\n\n    A 112\n    B 2 7\n    C 3 4\n    D 4 1\n    FNA 5\n\n\n\n\n\nfirst_df %>% \n    inner_join(second_df, by = \"Letter\")\n# inner_join! there is no E and F Letters, \n# only known both first_df and second_df are left here.\n\n\n\nA data.frame: 4 × 3\n\n    LetterValue.xValue.y\n    <chr><int><dbl>\n\n\n    A112\n    B2 7\n    C3 4\n    D4 1\n\n\n\n\n\nfirst_df %>% \n    full_join(second_df, by = \"Letter\")\n# all are here, but unknown values replaced by NA, it's ok.\n\n\n\nA data.frame: 6 × 3\n\n    LetterValue.xValue.y\n    <chr><int><dbl>\n\n\n    A 112\n    B 2 7\n    C 3 4\n    D 4 1\n    E 5NA\n    FNA 5\n\n\n\n\nShort description of reviewed functions:\n\n\n\n\n\n\n\n\n\nFunction\nObjectives\nArguments\nMultiple keys\n\n\n\n\nleft_join()\nMerge two datasets. Keep all observations from the origin table\ndata, origin, destination, by = “ID”\norigin, destination, by = c(“ID”, “ID2”)\n\n\nright_join()\nMerge two datasets. Keep all observations from the destination table\ndata, origin, destination, by = “ID”\norigin, destination, by = c(“ID”, “ID2”)\n\n\ninner_join()\nMerge two datasets. Excludes all unmatched rows\ndata, origin, destination, by = “ID”\norigin, destination, by = c(“ID”, “ID2”)\n\n\nfull_join()\nMerge two datasets. Keeps all observations\ndata, origin, destination, by = “ID”\norigin, destination, by = c(“ID”, “ID2”)\n\n\n\n\n\n\n10.2.14 Data cleaning with gather()\nSome times your data is not in tidy format. Peole can collect data year by year in each column. It’s problem to use such data for feature engeniering and building prediction models. Let’s generate such data sample (quaterly salary of some people).\n\nnot_good_data <- data.frame(Name = c(\"Nick\", \"Jake\", \"Anna\", \"Jane\", \"Dina\"),\n                           q1_2021 = c(12442, 22131, 21343, 22111, 14123),\n                           q2_2021 = c(13442, 22871, 20343, 22222, 14456),\n                           q3_2021 = c(15482, 22031, 22456, 22444, 14533),\n                           q4_2021 = c(14511, 20031, 21741, 22333, 14511))\nnot_good_data\n\n\n\nA data.frame: 5 × 5\n\n    Nameq1_2021q2_2021q3_2021q4_2021\n    <chr><dbl><dbl><dbl><dbl>\n\n\n    Nick12442134421548214511\n    Jake22131228712203120031\n    Anna21343203432245621741\n    Jane22111222222244422333\n    Dina14123144561453314511\n\n\n\n\n\nbetter_data <- not_good_data %>%\n                gather(quater, salary, 2:5)\n                # gather(quater, salary, q1_2021:q4_2021) possible code too\nbetter_data\n\n\n\nA data.frame: 20 × 3\n\n    Namequatersalary\n    <chr><chr><dbl>\n\n\n    Nickq1_202112442\n    Jakeq1_202122131\n    Annaq1_202121343\n    Janeq1_202122111\n    Dinaq1_202114123\n    Nickq2_202113442\n    Jakeq2_202122871\n    Annaq2_202120343\n    Janeq2_202122222\n    Dinaq2_202114456\n    Nickq3_202115482\n    Jakeq3_202122031\n    Annaq3_202122456\n    Janeq3_202122444\n    Dinaq3_202114533\n    Nickq4_202114511\n    Jakeq4_202120031\n    Annaq4_202121741\n    Janeq4_202122333\n    Dinaq4_202114511\n\n\n\n\nTo make our data tidier separate() can split quater column into 2 (quater and year):\n\nbest_data <- better_data %>%\n    separate(quater, c(\"quater\", \"year\"), sep = \"_\") %>% # separate\n    mutate(year = as.integer(year), # convert year to integer\n           quater = substr(better_data$quater, 2,2), # trim `q` from start\n           quater = as.integer(quater), # convert quater to integer\n          ) %>%\n    head(10)\nbest_data\n\n\n\nA data.frame: 10 × 4\n\n    Namequateryearsalary\n    <chr><int><int><dbl>\n\n\n    1Nick1202112442\n    2Jake1202122131\n    3Anna1202121343\n    4Jane1202122111\n    5Dina1202114123\n    6Nick2202113442\n    7Jake2202122871\n    8Anna2202120343\n    9Jane2202122222\n    10Dina2202114456\n\n\n\n\nThe unite() function concanates two columns into one:\n\nunited_data <- best_data %>%\n                unite(Qt, quater, year, sep = \"#\")\nunited_data\n\n\n\nA data.frame: 10 × 3\n\n    NameQtsalary\n    <chr><chr><dbl>\n\n\n    1Nick1#202112442\n    2Jake1#202122131\n    3Anna1#202121343\n    4Jane1#202122111\n    5Dina1#202114123\n    6Nick2#202113442\n    7Jake2#202122871\n    8Anna2#202120343\n    9Jane2#202122222\n    10Dina2#202114456\n\n\n\n\n\n# if dont want remove old columns use remove param\nunited_data <- best_data %>%\n                unite(Qt, quater, year, sep = \"#\", remove = F)\nunited_data\n\n\n\nA data.frame: 10 × 5\n\n    NameQtquateryearsalary\n    <chr><chr><int><int><dbl>\n\n\n    1Nick1#20211202112442\n    2Jake1#20211202122131\n    3Anna1#20211202121343\n    4Jane1#20211202122111\n    5Dina1#20211202114123\n    6Nick2#20212202113442\n    7Jake2#20212202122871\n    8Anna2#20212202120343\n    9Jane2#20212202122222\n    10Dina2#20212202114456\n\n\n\n\nIf you need to make table like initial use spread() function:\n\nnot_good_data2 <- better_data %>%\n                    spread(quater, salary)\nnot_good_data2\n\n\n\nA data.frame: 5 × 5\n\n    Nameq1_2021q2_2021q3_2021q4_2021\n    <chr><dbl><dbl><dbl><dbl>\n\n\n    Anna21343203432245621741\n    Dina14123144561453314511\n    Jake22131228712203120031\n    Jane22111222222244422333\n    Nick12442134421548214511\n\n\n\n\nLet’s try to spread() feild pop of gapminder by year:\n\ngapminder %>% select(country, pop, year) %>%\n                spread(year, pop) %>%\n                head() # for shorter code\n\n# now you can easy send data to your director in excel :)\n\n\n\nA tibble: 6 × 13\n\n    country195219571962196719721977198219871992199720022007\n    <fct><int><int><int><int><int><int><int><int><int><int><int><int>\n\n\n    Afghanistan 8425333 924093410267083115379661307946014880372128818161386795716317921222274152526840531889923\n    Albania     1282697 1476505 1728137 1984060 2263554 2509048 2780097 3075321 3326498 3428038 3508512 3600523\n    Algeria     92795251027085611000948127604991476078717152804200337532325495626298373290720153128714233333216\n    Angola      4232095 4561361 4826015 5247469 5894858 6162675 7016384 7874230 8735988 98750241086610612420476\n    Argentina  178769561961053821283783229342252477979926983828293413743162091833958947362034633833112140301927\n    Australia   8691212 971256910794968118722641317700014074100151842001625724917481977185652431954679220434176\n\n\n\n\nFunctions table:\n\n\n\n\n\n\n\n\nFunction\nObjectives\nArguments\n\n\n\n\ngather()\nTransform the data from wide to long\n(data, key, value, na.rm = FALSE)\n\n\nspread()\nTransform the data from long to wide\n(data, key, value)\n\n\nseparate()\nSplit one variables into two\n(data, col, into, sep= ““, remove = TRUE)\n\n\nunite()\nUnite two variables into one\n(data, col, conc ,sep= ““, remove = TRUE)"
  },
  {
    "objectID": "etl-dplyr.html#refences",
    "href": "etl-dplyr.html#refences",
    "title": "10  Manipulate data with dplyr",
    "section": "10.3 Refences",
    "text": "10.3 Refences\n\ndplyr: A Grammar of Data Manipulation on https://cran.r-project.org/.\nData Transformation with splyr::cheat sheet.\nDPLYR TUTORIAL : DATA MANIPULATION (50 EXAMPLES) by Deepanshu Bhalla.\nDplyr Intro by Stat 545. 6.R Dplyr Tutorial: Data Manipulation(Join) & Cleaning(Spread). Introduction to Data Analysis\nLoan Default Prediction. Beginners data set for financial analytics Kaggle"
  },
  {
    "objectID": "data-cleaning.html",
    "href": "data-cleaning.html",
    "title": "20  Підготовка та очистка даних у R",
    "section": "",
    "text": "Матеріали розділу описують інформацію про виміри оцінки якості даних, підходи до визначення та обробки пропущених значень, а також розглядаються способи боротьби зі статистичними викидами.\nДо початку роботи варто інстралювати наступні пакети:"
  },
  {
    "objectID": "data-cleaning.html#поняття-та-виміри-оцінки-якості-даних",
    "href": "data-cleaning.html#поняття-та-виміри-оцінки-якості-даних",
    "title": "20  Підготовка та очистка даних у R",
    "section": "20.1 Поняття та виміри оцінки якості даних",
    "text": "20.1 Поняття та виміри оцінки якості даних\nЯкість даних залежить від очищення та коригування даних, які відсутні, некоректні, недійсні або нечитабельні. Для забезпечення достовірності даних важливо зрозуміти ключові аспекти якості даних, щоб оцінити, наскільки дані погані/хороші.\n\n20.1.1 Що таке валідація даних?\nВалідація даних відноситься до процесу забезпечення точності та якості даних. Він реалізується шляхом вбудовування кількох перевірок у систему або звітування для забезпечення логічної узгодженості введених і збережених даних.\nНа перший погляд, очевидно, що перетворення даних до якісних полягає в очищенні поганих даних – даних, які відсутні, неправильні або якимось чином недійсні. Але щоб переконатися, що дані заслуговують довіри, важливо розуміти ключові виміри якості даних, щоб оцінити, наскільки дані є «поганими».\nОкремі компанії мають внутрішні документи, що визначають виміри оцінки якості даних та порядок його проведення - Data Validation Framework або Data Quality Framework.\nКоли говорять про якість даних, то мається на увазі їх оцінка у кількох вимірах. Розглянемо коротко ці виміри:\n\nПравильність / Accuracy\nПовнота / Completeness\nУзгодженість / Consistency\nВідповідність / Conformity\nЦілісність / Integrity\nСвоєчасність / Timeliness\nУнікальність / Uniqueness\n\n\n\n\n20.1.2 Правильність / (Accuracy)\nПравильність — це ступінь, до якого дані правильно відображають реальний об’єкт АБО описувану подію.\nПриклади: - [x] Реальною вартістю є ціна продажу одиниці товару. - [x] Адреса співробітника в базі даних співробітників є справжньою адресою.\nЗапитання, які ви можете задати собі:\n\nЧи об’єкти даних точно представляють значення «реального світу», які вони повинні моделювати? Наприклад, чи правильно вказувати вік у сотнях тисяч років?\nЧи присутнє неправильне написання назв товарів чи осіб, адрес і навіть несвоєчасних чи неактуальних даних?\n\nЦі проблеми можуть вплинути на результатати аналітичних звітів, наприклад, неправильні середні значення певних показників.\n\n\n\n20.1.3 Повнота / (Completeness)\nПовнота визначається як очікувана всебічність. Дані можуть бути повними, навіть якщо додаткові дані відсутні. Поки дані відповідають очікуванням, вони вважаються повними.\nНаприклад, ім’я та прізвище замовника є обов’язковими, але прізвище необов’язково; тому запис можна вважати повним, навіть якщо прізвища не існує.\nПитання, які ви можете задати собі:\n\nЧи доступна вся необхідна інформація?\nЧи мають якісь дані відсутні елементи?\nАбо вони перебувають у непридатному для роботи вигляді?\n\n\n\n\n20.1.4 Узгодженість / Consistency\nУзгодженість означає, що дані в усіх системах/таблицях відображають однакову інформацію та синхронізовані між собою.\nПриклади: - [x] Статус бізнес-підрозділу “закритий”, але є продажі для цього підрозділу. - [x] Статус працівника “звільнено”, але статус випалати заробіної плати містить суму відмінну від 0 за той самий період. - [x] Зафіксовано, що клієнт має у банку депозити, але у даних про депозити записи по клієнту відсутні.\nЗапитання, які ви можете поставити собі:\n\nЧи однакові значення даних у наборах даних?\nЧи існують якісь різні випадки, коли однакові екземпляри даних надають суперечливу інформацію?\n\n\n\n\n20.1.5 Відповідність / Conformity\nВідповідність означає, що дані відповідають набору стандартних визначень даних, як-от тип даних, розмір і формат. Наприклад, дата народження клієнта у форматі dd/mm/yyyy або відстань у км числом 100, а не записом 100км.\nЗапитання, які ви можете задати собі: - [x] Чи відповідають значення даних зазначеним форматам? - [x] Якщо так, то чи всі значення даних відповідають цим форматам?\nВажливо підтримувати відповідність конкретним форматам.\n\n\n\n20.1.6 Цілісність / Integrity\nЦілісність означає достовірність даних у взаємозв’язках і гарантує, що всі дані в базі даних можна відстежити та з’єднати з іншими даними.\nНаприклад, у базі даних клієнтів має бути дійсний клієнт, адреси та відношення/зв’язки між ними. Якщо є дані про зв’язок адреси без клієнта, то ці дані недійсні й вважаються загубленим записом.\nЗапитайте себе: - [x] Чи є якісь дані без важливих зв’язків?\nНеможливість пов’язати записи разом може призвести до дублювання у ваших системах.\n\n\n\n20.1.7 Своєчасність / Timeliness\nСвоєчасність показує, чи є інформація доступною, коли вона очікується та потрібна. Своєчасність даних дуже важлива.\nЦе відображається в: - [x] Компанії, які зобов’язані публікувати свої квартальні результати протягом певного періоду часу - [x] Обслуговування клієнтів надає клієнтам актуальну інформацію - [x] Кредитна система перевіряє активність рахунку кредитної картки в режимі реального часу\nСвоєчасність залежить від очікувань користувача. Доступність даних в Інтернеті може знадобитися для системи розподілу номерів у сфері готельного бізнесу.\nЯк бачите, якість даних є важливим питанням, яке слід враховувати, починаючи від етапу визначення цілей проекту, аж до впровадження, обслуговування та використання готово рішення у виробничі процесі підприємства."
  },
  {
    "objectID": "data-cleaning.html#робота-з-неіменованими-та-поганоіменованими-даними",
    "href": "data-cleaning.html#робота-з-неіменованими-та-поганоіменованими-даними",
    "title": "20  Підготовка та очистка даних у R",
    "section": "20.2 Робота з неіменованими та “поганоіменованими” даними",
    "text": "20.2 Робота з неіменованими та “поганоіменованими” даними\n\n20.2.1 Іменування даних\nПершим прикладом проблем у даних можна розгянути читання неіменованих даних, тобто стопці таблиці не мають заголовків у файлі.\nСтворимо такий файл у блокноті і зчитаємо його:\n\ndata <- read.csv(\"../../data/untitled.csv\")\ndata\n\n\n\nA data.frame: 5 × 4\n\n    X23X185X85.7Male\n    <int><chr><dbl><chr>\n\n\n    41175 68.3M               \n    11142*55.4Female          \n    12NA  48.2Man             \n    54171   NALooks like a man\n    32168 78.0F               \n\n\n\n\nЗверніть увагу, що у якості стовпців взято перший рядок даних у додано X на початку. Зчитаємо дані із параметром, що вказує на відсутність заголовків:\n\ndata <- read.csv(\"../../data/untitled.csv\", header = FALSE)\ndata\n\n\n\nA data.frame: 6 × 4\n\n    V1V2V3V4\n    <int><chr><dbl><chr>\n\n\n    23185 85.7Male            \n    41175 68.3M               \n    11142*55.4Female          \n    12NA  48.2Man             \n    54171   NALooks like a man\n    32168 78.0F               \n\n\n\n\nПроблема іменування не вирішена, дані ми уже не втратили. Передамо одночасно з читанням інформацію про назви стовпців:\n\ndata <- read.csv(\"../../data/untitled.csv\", \n            header = FALSE,\n            col.names = c(\"Age\",\"Height\", \"Weight\", \"Gender\"))\ndata\n\n\n\nA data.frame: 6 × 4\n\n    AgeHeightWeightGender\n    <int><chr><dbl><chr>\n\n\n    23185 85.7Male            \n    41175 68.3M               \n    11142*55.4Female          \n    12NA  48.2Man             \n    54171   NALooks like a man\n    32168 78.0F               \n\n\n\n\nЩе одним варіантом задання назв стовпців є використання функції colnames() як для усіх різом, так і для окремого:\n\ncolnames(data) <- c(\"age\", \"height\", \"width\", \"gender\")\ndata\ncolnames(data)[2] <- \"HEIGHT\"\ndata\n\n\n\nA data.frame: 6 × 4\n\n    ageheightwidthgender\n    <int><chr><dbl><chr>\n\n\n    23185 85.7Male            \n    41175 68.3M               \n    11142*55.4Female          \n    12NA  48.2Man             \n    54171   NALooks like a man\n    32168 78.0F               \n\n\n\n\n\n\nA data.frame: 6 × 4\n\n    ageHEIGHTwidthgender\n    <int><chr><dbl><chr>\n\n\n    23185 85.7Male            \n    41175 68.3M               \n    11142*55.4Female          \n    12NA  48.2Man             \n    54171   NALooks like a man\n    32168 78.0F               \n\n\n\n\nТакож змінювати назви стовпців можна за допомогою функції rename() з пакету dplyr:\n\nlibrary(dplyr)\n\ndata <- data |> rename(AGE = age) # %>%\ndata\n\n\n\nA data.frame: 6 × 4\n\n    AGEHEIGHTwidthgender\n    <int><chr><dbl><chr>\n\n\n    23185 85.7Male            \n    41175 68.3M               \n    11142*55.4Female          \n    12NA  48.2Man             \n    54171   NALooks like a man\n    32168 78.0F               \n\n\n\n\n\n\n\n20.2.2 Заміна назв стовпців data.frame \nЗчитаємо файл, що містить інформацію про осіб, але уже має іменовані стовтці:\n\ndata <- read.csv(\"../../data/badtitled.csv\")\ndata\n\n\n\nA data.frame: 13 × 5\n\n    Person.AgePerson__Heightperson.WeightPerson.Genderempty\n    <int><chr><dbl><chr><lgl>\n\n\n    23185   NAMale  NA\n    41175 68.3   M  NA\n    11142*55.4FemaleNA\n    12NA  48.2Man   NA\n    54191   NAfemaleNA\n    32168 78.0F     NA\n    22NA  54.0male. NA\n    21165   NAm     NA\n    14NA  90.2Man   NA\n    51250   NAfemaleNA\n    4120  81.0F     NA\n    66NA  59.0male. NA\n    71171   NAm     NA\n\n\n\n\nШвидко змінити назви стовпців та привести їх до однакового стилю можна за домогою бібліотеки janitor:\n\nlibrary(janitor)\nclean <- clean_names(data)\ncolnames(clean)\n\n\n'person_age''person_height''person_weight''person_gender''empty'\n\n\n\n\n\n20.2.3 Підготовка та очистка текстової інформації\nЗчитаємо інформацію про стать з попереднього прикладу:\n\ndata <- read.csv(\"../../data/badtitled.csv\")\ndata <- clean_names(data)\ndata <- as.data.frame(data$person_gender)\ncolnames(data) <- c(\"gender\")\nunlist(data)\n\ngender1'Male'gender2'   M'gender3'Female'gender4'Man'gender5'female'gender6'F    'gender7'male.'gender8'm'gender9'Man'gender10'female'gender11'F    'gender12'male.'gender13'm'\n\n\nСхоже, що ці дані насправді мають всього 2 записи, проте у базу даних їх вносили різні люди або вони були зібрані з різних джерел інформації. Це досить поширена проблема у роботі з даними. Особливо коли відбуваєть заміна людей на рочих місцях або перехід на інше програмне забезпечення.\nЯкщо це буде розглядатися як факторна змінна без будь-якої попередньої обробки, очевидно, що 8, а не 2 класи будуть збережені. Тому завдання полягає в тому, щоб автоматично розпізнавати наведені вище дані про те, чи відноситься кожен елемент до чоловічої чи жіночої статі. У статистичних контекстах класифікацію таких “безладні” текстові рядки в ряд фіксованих категорій часто називають кодуванням.\nОпишемо два взаємодоповнюючих підходи до кодування рядків: нормалізація (string normalization) рядків і аналіз схожості тексту (approximate text matching).\nРозглянемо наступні підходи до очистки текстових даних:\n– [x] Видалення пробілів на початку або в кінці\n– [x] Обрізання/збільшення рядків до певної ширини\n– [x] Перетворення у верхній/нижній регістр.\n– [x] Пошук рядків, що містять прості шаблони (підрядки).\n– [x] Апроксимація рядків на основі \"відстаней\".\nРобота з текстом у R здійснюється за допомогою пакету stringr.\nВидалення пробілів на початку або в кінці здійснюється за допомогою функції str_trim().\n\nlibrary(stringr)\nstr_trim(\" ostroh academy  \")\nstr_trim(\" ostroh academy \", side = \"left\")\nstr_trim(\" ostroh academy \", side = \"right\")\n\n'ostroh academy'\n\n\n'ostroh academy '\n\n\n' ostroh academy'\n\n\nОбрізання/збільшення рядків до певної ширини здійснюється за допомогою функції str_pad().\n\nstr_pad(57, width = 6, side = \"left\", pad = 0)\n\n'000057'\n\n\n\nstr_pad(\"ostroh\", width = 10, side = \"right\", pad = \"_\")\n\n'ostroh____'\n\n\nПеретворення у верхній/нижній регістр\n\ntext <- \"Ostroh Academy!\"\ntoupper(text)\ntolower(text)\n\n'OSTROH ACADEMY!'\n\n\n'ostroh academy!'\n\n\nПошук рядків, що містять прості шаблони (підрядки)\nСкористаємося функцієя grep() та grepl() для пошуку підрядків у інформації про стать:\n\ngrepl(\"m\", data$gender) # Повертає TRUE/FALSE, якщо знахоить входження рядка\ngrep(\"m\", data$gender) # Повертає номери рядків, по яких є входження\n\n\nFALSEFALSETRUEFALSETRUEFALSETRUETRUEFALSETRUEFALSETRUETRUE\n\n\n\n3578101213\n\n\n\ngrepl(\"m\", data$gender, ignore.case = TRUE) # не враховує регістр букв\ngrepl(\"m\", tolower(data$gender))\n\n\nTRUETRUETRUETRUETRUEFALSETRUETRUETRUETRUEFALSETRUETRUE\n\n\n\nTRUETRUETRUETRUETRUEFALSETRUETRUETRUETRUEFALSETRUETRUE\n\n\n\ndata$gender\ngrepl(\"^m\", data$gender, ignore.case = TRUE) # Показує усі збіги, що починаються з вказаної літери\n\n\n'Male''   M''Female''Man''female''F    ''male.''m''Man''female''F    ''male.''m'\n\n\n\nTRUEFALSEFALSETRUEFALSEFALSETRUETRUETRUEFALSEFALSETRUETRUE\n\n\nПошук “відстані” між ряжками - це аналіз рядків на схожіть з визначенням рівня співпадінь.\n\nadist(\"ao\", \"ao\")\nadist(\"ao\", \"oa\")\nadist(\"ao\", \"45fb\")\n\n\n\nA matrix: 1 × 1 of type dbl\n\n    0\n\n\n\n\n\n\nA matrix: 1 × 1 of type dbl\n\n    2\n\n\n\n\n\n\nA matrix: 1 × 1 of type dbl\n\n    4\n\n\n\n\nДавайте проаналізуємо інформацію про стать з точки зору схожості текстів:\n\nm <- c(\"male\", \"female\")\nadj_m <- adist(data$gender, m)\n#adj_m <- adist(tolower(data$gender), m)\n#adj_m <- adist(str_trim(tolower(data$gender), side=\"both\"), m)\ncolnames(adj_m) <- m \nrownames(adj_m) <- data$gender\nadj_m\n\n\n\nA matrix: 13 × 2 of type dbl\n\n    malefemale\n\n\n    Male13\n       M46\n    Female21\n    Man35\n    female20\n    F    56\n    male.13\n    m35\n    Man35\n    female20\n    F    56\n    male.13\n    m35\n\n\n\n\n\n# Видалимо повтори\nadj_m |> as.data.frame() |> dplyr::distinct()\n\n\n\nA data.frame: 6 × 2\n\n    malefemale\n    <dbl><dbl>\n\n\n    Male13\n    X...M46\n    Female21\n    Man35\n    female20\n    F....56\n\n\n\n\nПримінимо інформацію про відстані до “нечистих” даних про стать:\n\nnums <- apply(adj_m, 1, which.min) # Знайдемо найближчі значення\nnums\n\nMale1   M1Female2Man1female2F    1male.1m1Man1female2F    1male.1m1\n\n\n\ndata.frame(initial = data$gender, coded = m[nums]) # FFFFFFFFFFFFFF - проблема!\n\n\n\nA data.frame: 13 × 2\n\n    initialcoded\n    <chr><chr>\n\n\n    Male  male  \n       M  male  \n    Femalefemale\n    Man   male  \n    femalefemale\n    F     male  \n    male. male  \n    m     male  \n    Man   male  \n    femalefemale\n    F     male  \n    male. male  \n    m     male  \n\n\n\n\nЯк альтернативу для знаходження відстаней між рядками можна використовувати функції з бібліотеки stringdist.\n\nlibrary(stringdist)\nadist(\"ao\", \"oa\")\nstringdist(\"oa\", \"ao\") # 1, а було 2\n\n\n\nA matrix: 1 × 1 of type dbl\n\n    2\n\n\n\n\n1\n\n\nСпробуємо “очистити” дані, які ми отримали з допомогою функції amatch():\n\nnums <- amatch(data$gender,  c(\"male\", \"female\"), maxDist = 4) # Знайдемо найближчі значення\nnums\n\n\n11212<NA>1112<NA>11\n\n\n\ndata.frame(initial = data$gender, coded = m[nums]) # FFFFFFFFFFFFFF - проблема!\n\n\n\nA data.frame: 13 × 2\n\n    initialcoded\n    <chr><chr>\n\n\n    Male  male  \n       M  male  \n    Femalefemale\n    Man   male  \n    femalefemale\n    F     NA    \n    male. male  \n    m     male  \n    Man   male  \n    femalefemale\n    F     NA    \n    male. male  \n    m     male  \n\n\n\n\n\ndata <- data |> mutate(gender = ifelse(gender == \"F\", \"female\", gender)) # ????? # Space\ndata\ndata <- data |> mutate(gender = ifelse(str_trim(gender) == \"F\", \"female\", gender))\ndata\nnums <- amatch(data$gender,  c(\"male\", \"female\"), maxDist = 4)\ndata.frame(initial = data$gender, coded = m[nums]) \n\n\n\nA data.frame: 13 × 1\n\n    gender\n    <chr>\n\n\n    Male  \n       M  \n    Female\n    Man   \n    female\n    F     \n    male. \n    m     \n    Man   \n    female\n    F     \n    male. \n    m     \n\n\n\n\n\n\nA data.frame: 13 × 1\n\n    gender\n    <chr>\n\n\n    Male  \n       M  \n    Female\n    Man   \n    female\n    female\n    male. \n    m     \n    Man   \n    female\n    female\n    male. \n    m     \n\n\n\n\n\n\nA data.frame: 13 × 2\n\n    initialcoded\n    <chr><chr>\n\n\n    Male  male  \n       M  male  \n    Femalefemale\n    Man   male  \n    femalefemale\n    femalefemale\n    male. male  \n    m     male  \n    Man   male  \n    femalefemale\n    femalefemale\n    male. male  \n    m     male  \n\n\n\n\nМісія виконана! Замінимо та збережемо інформацію у файл для майбутніх експериментів по цій темі:\n\ndata <- read.csv(\"../../data/badtitled.csv\")\ndata <- clean_names(data)\nhead(data, 2)\n\n\n\nA data.frame: 2 × 5\n\n    person_ageperson_heightperson_weightperson_genderempty\n    <int><chr><dbl><chr><lgl>\n\n\n    123185  NAMaleNA\n    24117568.3   MNA\n\n\n\n\n\ndata <- data |> mutate(person_gender = ifelse(str_trim(person_gender) == \"F\", \"female\", person_gender))\nm <- c(\"male\", \"female\")\nnums <- amatch(data$person_gender, m, maxDist = 4)\ndata <- data |> mutate(person_gender = m[nums])\ndata\n\n\n\nA data.frame: 13 × 5\n\n    person_ageperson_heightperson_weightperson_genderempty\n    <int><chr><dbl><chr><lgl>\n\n\n    23185   NAmale  NA\n    41175 68.3male  NA\n    11142*55.4femaleNA\n    12NA  48.2male  NA\n    54191   NAfemaleNA\n    32168 78.0femaleNA\n    22NA  54.0male  NA\n    21165   NAmale  NA\n    14NA  90.2male  NA\n    51250   NAfemaleNA\n    4120  81.0femaleNA\n    66NA  59.0male  NA\n    71171   NAmale  NA\n\n\n\n\nЗамінимо також висоту на числове значення, а не текст:\n\ndata <- data |> \n    mutate(person_height = str_remove(data$person_height, pattern = \"[*]\"))\ndata\n\nERROR: Error in mutate(data, person_height = str_remove(data$person_height, pattern = \"[*]\")): could not find function \"mutate\"\n\n\n\ndata <- data |> mutate(person_height = as.numeric(person_height))\ndata\n\n\n\nA data.frame: 13 × 5\n\n    person_ageperson_heightperson_weightperson_genderempty\n    <int><dbl><dbl><chr><lgl>\n\n\n    23185  NAmale  NA\n    4117568.3male  NA\n    1114255.4femaleNA\n    12 NA48.2male  NA\n    54191  NAfemaleNA\n    3216878.0femaleNA\n    22 NA54.0male  NA\n    21165  NAmale  NA\n    14 NA90.2male  NA\n    51250  NAfemaleNA\n    41 2081.0femaleNA\n    66 NA59.0male  NA\n    71171  NAmale  NA\n\n\n\n\n\nwrite.csv(data, file = \"../../data/cleaned_titled.csv\", row.names = F)"
  },
  {
    "objectID": "data-cleaning.html#заміна-пропусків-у-даних-missing-value-imputation",
    "href": "data-cleaning.html#заміна-пропусків-у-даних-missing-value-imputation",
    "title": "20  Підготовка та очистка даних у R",
    "section": "20.3 Заміна пропусків у даних (Missing Value Imputation)",
    "text": "20.3 Заміна пропусків у даних (Missing Value Imputation)\nДані реального світу часто мають відсутні значення. Дані можуть мати відсутні значення з ряду причин, таких як спостереження, які не були записані, пошкодження даних тощо.\nПроблема - [x] Обробка відсутніх даних важлива, оскільки багато алгоритмів машинного навчання або програм для візуалізації та аналізу данихне підтримують дані з відсутніми значеннями.\nРішення\n\nВидалити рядки з відсутніми даними з набору даних.\nЗамінити відсутні значення середніми/медіанними значеннями.\n\nПримітка\n\nВикористовуйте бізнес-логіку/знання для окремого підходу до кожної змінної\nУ разі малого розміру вибірки або великої частки спостережень із відсутніми значеннями бажано замінювати, а видаляти\n\nНекоректна інформація в даних може бути записана різними способами, наприклад у датасеті ці дані можуть бутьу визначені як NA <NA> NULL undefinded Undefined. Перед обробкою таких даних усі невизначені записи варто конвертувати у NA.\nЩоб переглянути список усіх стовпців, що мають пропуски даних можна скористатися наступним кодом:\n\ndata <- data <- read.csv(\"../../data/cleaned_titled.csv\", na.strings = c(\"<NA>\", \"NA\", \"null\", \"undefined\", \"NULL\", \"\"))\nglimpse(data)\n\nRows: 13\nColumns: 5\n$ person_age    <int> 23, 41, 11, 12, 54, 32, 22, 21, 14, 51, 41, 66, 71\n$ person_height <int> 185, 175, 142, NA, 191, 168, NA, 165, NA, 250, 20, NA, 1~\n$ person_weight <dbl> NA, 68.3, 55.4, 48.2, NA, 78.0, 54.0, NA, 90.2, NA, 81.0~\n$ person_gender <chr> \"male\", \"male\", \"female\", \"male\", \"female\", \"female\", \"m~\n$ empty         <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA\n\n\n\n20.3.1 Перевірка наявності пропусків у даних\nПакет MICE (Multivariate Imputation via Chained Equations)\n\nlibrary(mice)\nmd.pattern(data)\n\n\n\nA matrix: 4 × 6 of type dbl\n\n    person_ageperson_genderperson_heightperson_weightempty\n\n\n    41111 0 1\n    51110 0 2\n    41101 0 2\n    00451322\n\n\n\n\n\n\n\n\nlibrary(VIM)\nmice_plot <- aggr(data, \n                  col=c('navyblue','yellow'),\n                  numbers=TRUE, \n                  sortVars=TRUE,\n                  labels=names(data), \n                  cex.axis=.7,\n                  gap=3, \n                  ylab=c(\"Missing data\",\"Pattern\"))\nmice_plot\n\n\n Variables sorted by number of missings: \n      Variable     Count\n         empty 1.0000000\n person_weight 0.3846154\n person_height 0.3076923\n    person_age 0.0000000\n person_gender 0.0000000\n\n\n\n Missings in variables:\n      Variable Count\n person_height     4\n person_weight     5\n         empty    13\n\n\n\n\n\n\nlibrary(Amelia)\nAmelia::missmap(data)\n\nWarning message in is.na(obj):\n\"is.na() applied to non-(list or vector) of type 'closure'\"\n\n\nERROR: Error in colMeans(is.na(obj)): 'x' must be an array of at least two dimensions\n\n\nТакож можна скористатися альтернативними макетами: missForest, mi.\n\n\n\n20.3.2 Видалення пустих рядків та сповпців у data.frame\nПереглянемо стовпці, що містять пропуски:\n\n# Переглянемо список стовпців з пропусками\ncolnames(data)[apply(data, 2, anyNA)]\n\n\n'person_height''person_weight''empty'\n\n\nФункція complete.cases повертає логічні значення\n\ncomplete.cases(data) # бо є стовпець Empty\n\n\nFALSEFALSEFALSEFALSEFALSEFALSEFALSEFALSEFALSEFALSEFALSEFALSEFALSE\n\n\nТакож видаляти стовпці та рядки з data.frame можна за допомогою пакету janitor.\n\nlibrary(janitor)\ndata_cleaned <- remove_empty(data, which = c(\"rows\",\"cols\"), quiet = FALSE)\ndata_cleaned\n\nNo empty rows to remove.\n\nRemoving 1 empty columns of 5 columns total (Removed: empty).\n\n\n\n\n\nA data.frame: 13 × 4\n\n    person_ageperson_heightperson_weightperson_gender\n    <int><int><dbl><chr>\n\n\n    123185  NAmale  \n    24117568.3male  \n    31114255.4female\n    412 NA48.2male  \n    554191  NAfemale\n    63216878.0female\n    722 NA54.0male  \n    821165  NAmale  \n    914 NA90.2male  \n    1051250  NAfemale\n    1141 2081.0female\n    1266 NA59.0male  \n    1371171  NAmale  \n\n\n\n\n\nwrite.csv(data_cleaned, file = \"../../data/cleaned_titled2.csv\", row.names = F)\n\nЯк бачимо, колонка empty була видалена.\nЩоб переглянути усі записи, що не мають пропусків скористаємося функцією na.omit():\n\nna.omit(data_cleaned)\n\n\n\nA data.frame: 4 × 4\n\n    person_ageperson_heightperson_weightperson_gender\n    <int><int><dbl><chr>\n\n\n    24117568.3male  \n    31114255.4female\n    63216878.0female\n    1141 2081.0female\n\n\n\n\nТаким чином пропущені значення будуть видалені з датасети, якщо інформацію переприсвоїти data <- na.omit(data)\n\n\n\n20.3.3 Заміна пропусків у data.frame\nІснує ряд підходів, що використовуються для заміни пропущених значень у датасеті:\nЗаміна на 0 * Вставте пропущені значення нулем\nЗаміна на медіану/середнє значення * Для числових змінних - середнє або медіана, мінімум, максимум * Для категоріальних змінних - мода (бувають випадки, коли моду доцільно використовувати і для цислових)\nСегментна заміна * Визначення сегментів * Обчислення середнього/медіани/моди для сегментів * Замінити значення по сегментах * Наприклад, ми можемо сказати, що кількість опадів майже не змінюється для міст у певній області України, у такому випадку ми можемо для усіх міст з пропусками записати значення середнє по регіону.\nІнтелектуальна заміна (Частковий випадок сегментної заміни) * Заміна значень з використанням методів машинного навчання\n\n20.3.3.1 3.3.1. Заміна пропусків на нуль (0)\n\ndata <- read.csv(\"../../data/cleaned_titled2.csv\")\ndata\n\n\n\nA data.frame: 13 × 4\n\n    person_ageperson_heightperson_weightperson_gender\n    <int><int><dbl><chr>\n\n\n    23185  NAmale  \n    4117568.3male  \n    1114255.4female\n    12 NA48.2male  \n    54191  NAfemale\n    3216878.0female\n    22 NA54.0male  \n    21165  NAmale  \n    14 NA90.2male  \n    51250  NAfemale\n    41 2081.0female\n    66 NA59.0male  \n    71171  NAmale  \n\n\n\n\nЗамінимо інформацію про вагу з пропусками на 0:\n\ndata_w0 <- data |> mutate(person_weight = ifelse(is.na(person_weight), 0, person_weight))\ndata_w0\n\n\n\nA data.frame: 13 × 4\n\n    person_ageperson_heightperson_weightperson_gender\n    <int><int><dbl><chr>\n\n\n    23185 0.0male  \n    4117568.3male  \n    1114255.4female\n    12 NA48.2male  \n    54191 0.0female\n    3216878.0female\n    22 NA54.0male  \n    21165 0.0male  \n    14 NA90.2male  \n    51250 0.0female\n    41 2081.0female\n    66 NA59.0male  \n    71171 0.0male  \n\n\n\n\n\n# Без dplyr\ndata_w0 <- data\ndata_w0[is.na(data_w0$person_weight), \"person_weight\"] <- 0\ndata_w0\n\n\n\nA data.frame: 13 × 4\n\n    person_ageperson_heightperson_weightperson_gender\n    <int><int><dbl><chr>\n\n\n    23185 0.0male  \n    4117568.3male  \n    1114255.4female\n    12 NA48.2male  \n    54191 0.0female\n    3216878.0female\n    22 NA54.0male  \n    21165 0.0male  \n    14 NA90.2male  \n    51250 0.0female\n    41 2081.0female\n    66 NA59.0male  \n    71171 0.0male  \n\n\n\n\nЗробити заміну для усіх числових стовпців:\n\nlibrary(tidyr) # for replace_na()\ndata_all <- data |> mutate_if(is.numeric , replace_na, replace = 0)\ndata_all\n\n\nAttaching package: 'tidyr'\n\n\nThe following object is masked from 'package:stringdist':\n\n    extract\n\n\n\n\n\n\nA data.frame: 13 × 4\n\n    person_ageperson_heightperson_weightperson_gender\n    <int><int><dbl><chr>\n\n\n    23185 0.0male  \n    4117568.3male  \n    1114255.4female\n    12  048.2male  \n    54191 0.0female\n    3216878.0female\n    22  054.0male  \n    21165 0.0male  \n    14  090.2male  \n    51250 0.0female\n    41 2081.0female\n    66  059.0male  \n    71171 0.0male  \n\n\n\n\n\n\n\n20.3.3.2 Базова числова заміна пропусків\nЗаміна на константи або обчислені значення є стандарним підходом. Так, наприклад, заміна певного значення на середнє матиме вигляд:\n\ndata_m <- data |> \n    mutate(person_weight = ifelse(is.na(person_weight), mean(data$person_weight, na.rm = T), person_weight))\ndata_m\n\n\n\nA data.frame: 13 × 4\n\n    person_ageperson_heightperson_weightperson_gender\n    <int><int><dbl><chr>\n\n\n    2318566.7625male  \n    4117568.3000male  \n    1114255.4000female\n    12 NA48.2000male  \n    5419166.7625female\n    3216878.0000female\n    22 NA54.0000male  \n    2116566.7625male  \n    14 NA90.2000male  \n    5125066.7625female\n    41 2081.0000female\n    66 NA59.0000male  \n    7117166.7625male  \n\n\n\n\nЗаміна на min, max, median не відрізняється.\nЯкщо виникає потреба замінити, наприклад, усі значення на медіану у всіх стовпцях за один прохід можна скористатися функцією mutate_if():\n\ndata_all <- data |> \n    mutate_if(is.numeric, function(x) ifelse(is.na(x), median(x, na.rm = T), x))\ndata_all\n\n\n\nA data.frame: 13 × 4\n\n    person_ageperson_heightperson_weightperson_gender\n    <int><int><dbl><chr>\n\n\n    2318563.65male  \n    4117568.30male  \n    1114255.40female\n    1217148.20male  \n    5419163.65female\n    3216878.00female\n    2217154.00male  \n    2116563.65male  \n    1417190.20male  \n    5125063.65female\n    41 2081.00female\n    6617159.00male  \n    7117163.65male  \n\n\n\n\nРозгялнемо кілька бібліотек для перевірки даних на наявність про\nЩе одним із варіантів заміни значень може бути використання бібліотеки Hmisc:\n\nlibrary(Hmisc)\ndata_wm <- data |> mutate(person_weight = impute(data$person_weight, fun = mean)) # mean imputation\n# Аналогічно можна замінити на min,max, median чи інші функції\ndata_wm \n# * Значення із * - замінені\n\n\n\nA data.frame: 13 × 4\n\n    person_ageperson_heightperson_weightperson_gender\n    <int><int><impute><chr>\n\n\n    2318566.7625male  \n    4117568.3000male  \n    1114255.4000female\n    12 NA48.2000male  \n    5419166.7625female\n    3216878.0000female\n    22 NA54.0000male  \n    2116566.7625male  \n    14 NA90.2000male  \n    5125066.7625female\n    41 2081.0000female\n    66 NA59.0000male  \n    7117166.7625male  \n\n\n\n\n\n\n\n20.3.3.3 Hot deck imputation (як перекласти???)\nМетод Hot deck imputation передбачає, що пропущені значення обчислюються шляхом копіювання значень із подібних записів у тому ж наборі даних.\nОсновне питання при Hot deck imputation полягає в тому, як вибрати значення заміни. Одним із поширених підходів є випадковий відбір:\n\n# set.seed(1)\ndata_hot <- data |> mutate(person_weight = impute(data$person_weight, \"random\")) \ndata_hot \n\n\n\nA data.frame: 13 × 4\n\n    person_ageperson_heightperson_weightperson_gender\n    <int><int><impute><chr>\n\n\n    2318559.0male  \n    4117568.3male  \n    1114255.4female\n    12 NA48.2male  \n    5419178.0female\n    3216878.0female\n    22 NA54.0male  \n    2116568.3male  \n    14 NA90.2male  \n    5125048.2female\n    41 2081.0female\n    66 NA59.0male  \n    7117190.2male  \n\n\n\n\nВихідне значення залежить від значення seed.\n\n\n\n20.3.3.4 Сегментна заміна пропусків\nЗаміна по сегментах часто дозволяє будувати точніші математичні моделі, адже групові середні краще описують явища і процеси, ніж загальні для всієї вибірки.\nЗнайдемо середні значення ваги за статтю та використаємо ці значення для заміни пропусків у даних.\n\ndata_sgm <- data |> \n                group_by(person_gender) |>\n                mutate(person_weight = replace_na(person_weight, mean(person_weight, na.rm = TRUE)))\ndata_sgm\n\n\n\nA grouped_df: 13 × 4\n\n    person_ageperson_heightperson_weightperson_gender\n    <int><int><dbl><chr>\n\n\n    2318563.94000male  \n    4117568.30000male  \n    1114255.40000female\n    12 NA48.20000male  \n    5419171.46667female\n    3216878.00000female\n    22 NA54.00000male  \n    2116563.94000male  \n    14 NA90.20000male  \n    5125071.46667female\n    41 2081.00000female\n    66 NA59.00000male  \n    7117163.94000male  \n\n\n\n\nТакож можна здійснити заміну значень по усіх стовпцях датасету за один раз. Проте не варто такий підхід використовувати постійно, а враховувати бізнес-логіку процесів, що вивчаються.\n\ndata_sgm2 <- data %>% \n  group_by(person_gender) %>% \n    mutate(\n      across(everything(), ~replace_na(.x, min(.x, na.rm = TRUE)))\n    )\ndata_sgm2\n\n\n\nA grouped_df: 13 × 4\n\n    person_ageperson_heightperson_weightperson_gender\n    <int><int><dbl><chr>\n\n\n    2318548.2male  \n    4117568.3male  \n    1114255.4female\n    1216548.2male  \n    5419155.4female\n    3216878.0female\n    2216554.0male  \n    2116548.2male  \n    1416590.2male  \n    5125055.4female\n    41 2081.0female\n    6616559.0male  \n    7117148.2male  \n\n\n\n\nЯкщо ж є потреба замінювати по окремих стовпцях, то їх можна вказати замість everything(): across(c(\"person_height\", \"person_weight\"), ~replace_na(.x, min(.x, na.rm = TRUE))).\nІншим варіантом може бути вказання номерів колонок: across(c(1,3), ~replace_na(.x, min(.x, na.rm = TRUE)))\n\n\n\n20.3.3.5 Інтелектуальні методи заміни\nТеоретично інтелектуальні методи заміни пропусків є найкращими, адже враховують математичні залежності у даних.\n\nlibrary(VIM)\ndata_knn <- kNN(data)\ndata_knn\ndata\n\n\n\nA data.frame: 13 × 8\n\n    person_ageperson_heightperson_weightperson_genderperson_age_impperson_height_impperson_weight_impperson_gender_imp\n    <int><int><dbl><chr><lgl><lgl><lgl><lgl>\n\n\n    2318559.0male  FALSEFALSE TRUEFALSE\n    4117568.3male  FALSEFALSEFALSEFALSE\n    1114255.4femaleFALSEFALSEFALSEFALSE\n    1216848.2male  FALSE TRUEFALSEFALSE\n    5419168.3femaleFALSEFALSE TRUEFALSE\n    3216878.0femaleFALSEFALSEFALSEFALSE\n    2216854.0male  FALSE TRUEFALSEFALSE\n    2116559.0male  FALSEFALSE TRUEFALSE\n    1416890.2male  FALSE TRUEFALSEFALSE\n    5125068.3femaleFALSEFALSE TRUEFALSE\n    41 2081.0femaleFALSEFALSEFALSEFALSE\n    6616859.0male  FALSE TRUEFALSEFALSE\n    7117159.0male  FALSEFALSE TRUEFALSE\n\n\n\n\n\n\nA data.frame: 13 × 4\n\n    person_ageperson_heightperson_weightperson_gender\n    <int><int><dbl><chr>\n\n\n    23185  NAmale  \n    4117568.3male  \n    1114255.4female\n    12 NA48.2male  \n    54191  NAfemale\n    3216878.0female\n    22 NA54.0male  \n    21165  NAmale  \n    14 NA90.2male  \n    51250  NAfemale\n    41 2081.0female\n    66 NA59.0male  \n    71171  NAmale  \n\n\n\n\nЩе одним схожим методом заміни пропусків може бути здійснення прогнозів на основі регресії чи складніших математичних методів пропусків."
  },
  {
    "objectID": "data-cleaning.html#аналіз-та-обробка-статистичних-викидів-у-даних",
    "href": "data-cleaning.html#аналіз-та-обробка-статистичних-викидів-у-даних",
    "title": "20  Підготовка та очистка даних у R",
    "section": "20.4 Аналіз та обробка статистичних викидів у даних",
    "text": "20.4 Аналіз та обробка статистичних викидів у даних\nВиявлення аномалій — це сукупність методів, призначених для виявлення незвичайних точок даних, які мають вирішальне значення для виявлення шахрайства та захисту комп’ютерних мереж від зловмисної діяльності.\nАномалія - точка даних або набір точок даних, які не мають таку саму структуру та поведінку, що й інші дані.\nАномалії у даних можуть мати різну природу та по різному себе проявляти:\n\nТочкова аномалія\nЄдина точка даних\nНезвично в порівнянні з іншими даними\n\n\nПриклад: одна добова висока температура 41°С серед ряду звичайних весняних днів\n\ntemp <- c(15, 17, 19, 12, 30, 41, 17, 20)\nboxplot(temp, ylab = \"Celcium\")\n\n\n\n\n\nКолективна аномалія\nАномальна колекція екземплярів даних\nНезвично, якщо розглядати разом\n\n\nОпишемо набір даних, до використовуватиметься надалі для прикладів.\nriver_eco - це data.frame, що містить такі три стовпці: - [x] index - цілі числа, що описують порядок спостережень нітратів; - [x] nitrate - місячні концентрації розчинених нітратів у річці; - [x] month - змінна, що містить місяць для кожного спостереження нітратів\nНам потрібно дослідити стовпець nitrate, щоб оцінити наявність точкових аномалій у даних.\n\nriver_data <- read.csv(\"../../data/river_eco.csv\")\nhead(river_data)\n\n\n\nA data.frame: 6 × 3\n\n    indexnitratemonths\n    <int><dbl><chr>\n\n\n    111.581January \n    221.323February\n    331.140March   \n    441.245April   \n    551.072May     \n    661.483June    \n\n\n\n\nПереглянемо описову статистику показника нітрати:\n\nsummary(river_data$nitrate)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.5920  0.9485  1.0680  1.0649  1.1700  1.8970 \n\n\nЯк видно, медіана та середнє відрізняються не дуже.\nДалі перевіримо наявність викидів у даних за допомогою boxplot:\n\nboxplot(river_data$nitrate)\n# Додамо лінії 1 та 3 квантилів\nabline(h=quantile(river_data$nitrate,0.25),col=\"red\",lty=2)\nabline(h=quantile(river_data$nitrate,0.75),col=\"red\",lty=2)\n\n\n\n\nТакож виведемо номери рядків спостереженнь, що є викидами:\n\nboxplot.stats(river_data$nitrate)$out\n\n\n1.5811.6431.5331.5171.8970.592\n\n\n\nhist(river_data$nitrate, xlab = \"Nitrate concentration\", breaks = 40)\n\n\n\n\n\nplot(nitrate ~ index, data = river_data, type = \"o\")\n\n\n\n\n\n# Середньомісячний вміст нітратів у річці\nriver_grouped <- river_data |> group_by(months) |> summarise(mean = mean(nitrate))\nriver_grouped \n\n\n\nA tibble: 12 × 2\n\n    monthsmean\n    <chr><dbl>\n\n\n    April    1.0166250\n    August   0.9380833\n    December 1.2264167\n    February 1.1838400\n    January  1.2163600\n    July     0.9810417\n    June     0.9792083\n    March    1.1050400\n    May      0.9978333\n    November 1.0962500\n    October  1.0360000\n    September0.9885833\n\n\n\n\n\nplot(river_grouped$mean, type = \"o\", xlab = \"Month\", ylab = \"Monthly mean\")\n\n\n\n\n\nboxplot(nitrate ~ months, data = river_data)\n\n\n\n\nМіж Q1 та Q2 зосереджено 50% усіх спостережень. Персентиль відображає кількість спостережень, що зосереджені з ним включно. Нижче розміщено більше інформації для ознайомлення з інформацією про квантилі.\nQuantile. Wikipedia\n\nДжерело: https://en.wikipedia.org/wiki/Interquartile_range\n\nДжерело: https://makemeanalyst.com/explore-your-data-range-interquartile-range-and-box-plot/\nВизначивши викиди у даних з ними можна здійснити кілька операцій:\n\nЗаміна на деякі значення (impute)\nЗаміна на границі квантилей\n\n\nlower_bound <- quantile(river_data$nitrate, 0.025)\nlower_bound\n\nupper_bound <- quantile(river_data$nitrate, 0.975)\nupper_bound\n\n2.5%: 0.75475\n\n\n97.5%: 1.4095\n\n\n\noutlier_index <- which(river_data$nitrate < lower_bound | river_data$nitrate > upper_bound)\noutlier_index\n\n\n163653104119121156159167199200269270281282\n\n\n\nriver_data[outlier_index, ]\n\n\n\nA data.frame: 16 × 3\n\n    indexnitratemonths\n    <int><dbl><chr>\n\n\n    1  11.581January \n    6  61.483June    \n    36 361.643December\n    53 531.533May     \n    1041040.671August  \n    1191191.517November\n    1211211.414January \n    1561561.897December\n    1591591.414March   \n    1671670.671November\n    1991990.748July    \n    2002000.592August  \n    2692690.700May     \n    2702700.673June    \n    2812810.730May     \n    2822820.693June    \n\n\n\n\nТаким чином, усі значення вище та нище деякого показника можемо замінити на потрібні нам значення, наприклад, середні за поточний місяць.\nЗдійснимо заміну значень у наборі даних на основі квантилей:\n\nriver_data$nitrate_upd <- river_data$nitrate\nqnt <- quantile(river_data$nitrate_upd, probs=c(.05, .95), na.rm = T)\nH <- 1.5 * IQR(qnt[1], na.rm = T)\nriver_data$nitrate_upd[river_data$nitrate_upd < (qnt[1] - H)] <- qnt[1]\nriver_data$nitrate_upd[river_data$nitrate_upd > (qnt[2] + H)] <- qnt[2]\n\nqnt\n\n5%0.80595%1.3325\n\n\n\nboxplot(river_data$nitrate_upd)\n\n\n\n\n\nboxplot(nitrate_upd ~ months, data = river_data)\n\n\n\n\n\nplot(nitrate_upd ~ index, data = river_data, type = \"o\")"
  },
  {
    "objectID": "data-cleaning.html#додаткові-прийоми-очистки-даних",
    "href": "data-cleaning.html#додаткові-прийоми-очистки-даних",
    "title": "20  Підготовка та очистка даних у R",
    "section": "20.5 Додаткові прийоми очистки даних ",
    "text": "20.5 Додаткові прийоми очистки даних \n\n20.5.1 Видалення дублікатів\n\ndf <- data.frame(X = c(1,1,2,1,3,2,1), Y = c(\"A\", \"B\", \"C\", \"A\", \"B\", \"C\", \"A\"))\ndf\n\n\n\nA data.frame: 7 × 2\n\n    XY\n    <dbl><chr>\n\n\n    1A\n    1B\n    2C\n    1A\n    3B\n    2C\n    1A\n\n\n\n\n\ndf |> distinct()\n\n\n\nA data.frame: 4 × 2\n\n    XY\n    <dbl><chr>\n\n\n    1A\n    1B\n    2C\n    3B"
  },
  {
    "objectID": "data-cleaning.html#завдання-для-практики",
    "href": "data-cleaning.html#завдання-для-практики",
    "title": "20  Підготовка та очистка даних у R",
    "section": "20.6 Завдання для практики",
    "text": "20.6 Завдання для практики\n!!!"
  },
  {
    "objectID": "data-cleaning.html#набори-даних",
    "href": "data-cleaning.html#набори-даних",
    "title": "20  Підготовка та очистка даних у R",
    "section": "20.7 Набори даних",
    "text": "20.7 Набори даних\n\nhttps://github.com/kleban/r-book-published/tree/main/datasets/untitled.csv\nhttps://github.com/kleban/r-book-published/tree/main/datasets/badtitled.csv\nhttps://github.com/kleban/r-book-published/tree/main/datasets/cleaned_titled.csv\nhttps://github.com/kleban/r-book-published/tree/main/datasets/cleaned_titled2.csv\nhttps://github.com/kleban/r-book-published/tree/main/datasets/river_eco.csv"
  },
  {
    "objectID": "data-cleaning.html#використані-та-додаткові-джерела",
    "href": "data-cleaning.html#використані-та-додаткові-джерела",
    "title": "20  Підготовка та очистка даних у R",
    "section": "20.8 Використані та додаткові джерела",
    "text": "20.8 Використані та додаткові джерела\n\nKPMG Virtual Internship\nAn introduction to data cleaning with R / Edwin de Jonge, Mark van der Loo, 2013\nAnomaly Detection in R\nK-nearest Neighbor: The maths behind it, how it works and an example\nQuantile. Wikipedia"
  },
  {
    "objectID": "30-r-what-is-dplyr.html",
    "href": "30-r-what-is-dplyr.html",
    "title": "10  What’s dplyr package [EN]",
    "section": "",
    "text": "author: Юрій Клебан\nThe dplyr package is one of the most powerful and popular package in R for data manipulation.\nWorking with data:\nThe dplyr package makes these steps fast and easy:\nBefore use you should install package:\nNext step is loading package:\ndplyr functions work with pipes and expect tidy data. In tidy data:\nAlternative way is to load tidyverse package with other attached:"
  },
  {
    "objectID": "30-r-what-is-dplyr.html#refences",
    "href": "30-r-what-is-dplyr.html#refences",
    "title": "10  What’s dplyr package [EN]",
    "section": "10.1 Refences",
    "text": "10.1 Refences\n\ndplyr: A Grammar of Data Manipulation on https://cran.r-project.org/.\nData Transformation with splyr::cheat sheet.\nDPLYR TUTORIAL : DATA MANIPULATION (50 EXAMPLES) by Deepanshu Bhalla.\nDplyr Intro by Stat 545. 6.R Dplyr Tutorial: Data Manipulation(Join) & Cleaning(Spread). Introduction to Data Analysis\nLoan Default Prediction. Beginners data set for financial analytics Kaggle"
  },
  {
    "objectID": "31-r-data-explore.html",
    "href": "31-r-data-explore.html",
    "title": "11  Exploring data with dplyr",
    "section": "",
    "text": "author: Юрій Клебан"
  },
  {
    "objectID": "31-r-data-explore.html#basic-funtions-and-dataset-explore",
    "href": "31-r-data-explore.html#basic-funtions-and-dataset-explore",
    "title": "11  Exploring data with dplyr",
    "section": "11.1 Basic funtions and dataset explore",
    "text": "11.1 Basic funtions and dataset explore\nThere are most popular functions in dplyr is listed in table.\n\n\n\ndplyr Function\nDescription\nEquivalent SQL\n\n\n\n\nselect()\nSelecting columns (variables)\nSELECT\n\n\nfilter()\nFilter (subset) rows.\nWHERE\n\n\ngroup_by()\nGroup the data\nGROUP BY\n\n\nsummarise()\nSummarise (or aggregate) data\n-\n\n\narrange()\nSort the data\nORDER BY\n\n\njoin()\nJoining data frames (tables)\nJOIN\n\n\nmutate()\nCreating New Variables\nCOLUMN ALIAS\n\n\n\nFor the next sample we are going to use gapminder dataset. Go to gapminder dataset description\nThe gapminder data frame include six variables:\n\n\n\nvariable\nmeaning\n\n\n\n\ncountry\n-\n\n\ncontinent\n-\n\n\nyear\n-\n\n\nlifeExp\nlife expectancy at birth\n\n\npop\ntotal population\n\n\ngdpPercap\nper-capita GDP\n\n\n\nPer-capita GDP (Gross domestic product) is given in units of international dollars, a hypothetical unit of currency that has the same purchasing power parity that the U.S. dollar had in the United States at a given point in time – 2005, in this case.\nThe gapminder data frame is a special kind of data frame: a tibble.\n\nlibrary(dplyr) # for demos\n#install.packages(\"gapminder\")\nlibrary(gapminder)  # load package and dataset\nclass(gapminder)\n\n\n'tbl_df''tbl''data.frame'\n\n\nLet’s preview it with functions str(), glimpse(), head(), tail(), summary().\n\nstr(gapminder)\n\ntibble [1,704 x 6] (S3: tbl_df/tbl/data.frame)\n $ country  : Factor w/ 142 levels \"Afghanistan\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ continent: Factor w/ 5 levels \"Africa\",\"Americas\",..: 3 3 3 3 3 3 3 3 3 3 ...\n $ year     : int [1:1704] 1952 1957 1962 1967 1972 1977 1982 1987 1992 1997 ...\n $ lifeExp  : num [1:1704] 28.8 30.3 32 34 36.1 ...\n $ pop      : int [1:1704] 8425333 9240934 10267083 11537966 13079460 14880372 12881816 13867957 16317921 22227415 ...\n $ gdpPercap: num [1:1704] 779 821 853 836 740 ...\n\n\n\nglimpse(gapminder)\n\nRows: 1,704\nColumns: 6\n$ country   <fct> \"Afghanistan\", \"Afghanistan\", \"Afghanistan\", \"Afghanistan\", ~\n$ continent <fct> Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asia, ~\n$ year      <int> 1952, 1957, 1962, 1967, 1972, 1977, 1982, 1987, 1992, 1997, ~\n$ lifeExp   <dbl> 28.801, 30.332, 31.997, 34.020, 36.088, 38.438, 39.854, 40.8~\n$ pop       <int> 8425333, 9240934, 10267083, 11537966, 13079460, 14880372, 12~\n$ gdpPercap <dbl> 779.4453, 820.8530, 853.1007, 836.1971, 739.9811, 786.1134, ~\n\n\n\nhead(gapminder) #shows first n-rows, 6 by default\n\n\n\nA tibble: 6 × 6\n\n    countrycontinentyearlifeExppopgdpPercap\n    <fct><fct><int><dbl><int><dbl>\n\n\n    AfghanistanAsia195228.801 8425333779.4453\n    AfghanistanAsia195730.332 9240934820.8530\n    AfghanistanAsia196231.99710267083853.1007\n    AfghanistanAsia196734.02011537966836.1971\n    AfghanistanAsia197236.08813079460739.9811\n    AfghanistanAsia197738.43814880372786.1134\n\n\n\n\n\ntail(gapminder) #shows last n-rows, 6 by default\n\n\n\nA tibble: 6 × 6\n\n    countrycontinentyearlifeExppopgdpPercap\n    <fct><fct><int><dbl><int><dbl>\n\n\n    ZimbabweAfrica198260.363 7636524788.8550\n    ZimbabweAfrica198762.351 9216418706.1573\n    ZimbabweAfrica199260.37710704340693.4208\n    ZimbabweAfrica199746.80911404948792.4500\n    ZimbabweAfrica200239.98911926563672.0386\n    ZimbabweAfrica200743.48712311143469.7093\n\n\n\n\n\nsummary(gapminder)\n\n        country        continent        year         lifeExp     \n Afghanistan:  12   Africa  :624   Min.   :1952   Min.   :23.60  \n Albania    :  12   Americas:300   1st Qu.:1966   1st Qu.:48.20  \n Algeria    :  12   Asia    :396   Median :1980   Median :60.71  \n Angola     :  12   Europe  :360   Mean   :1980   Mean   :59.47  \n Argentina  :  12   Oceania : 24   3rd Qu.:1993   3rd Qu.:70.85  \n Australia  :  12                  Max.   :2007   Max.   :82.60  \n (Other)    :1632                                                \n      pop              gdpPercap       \n Min.   :6.001e+04   Min.   :   241.2  \n 1st Qu.:2.794e+06   1st Qu.:  1202.1  \n Median :7.024e+06   Median :  3531.8  \n Mean   :2.960e+07   Mean   :  7215.3  \n 3rd Qu.:1.959e+07   3rd Qu.:  9325.5  \n Max.   :1.319e+09   Max.   :113523.1"
  },
  {
    "objectID": "31-r-data-explore.html#filter-function",
    "href": "31-r-data-explore.html#filter-function",
    "title": "11  Exploring data with dplyr",
    "section": "11.2 filter() function",
    "text": "11.2 filter() function\n\naustria <- filter(gapminder, country == \"Austria\")\naustria\n\n\n\nA tibble: 12 × 6\n\n    countrycontinentyearlifeExppopgdpPercap\n    <fct><fct><int><dbl><int><dbl>\n\n\n    AustriaEurope195266.8006927772 6137.076\n    AustriaEurope195767.4806965860 8842.598\n    AustriaEurope196269.540712986410750.721\n    AustriaEurope196770.140737699812834.602\n    AustriaEurope197270.630754420116661.626\n    AustriaEurope197772.170756843019749.422\n    AustriaEurope198273.180757461321597.084\n    AustriaEurope198774.940757890323687.826\n    AustriaEurope199276.040791496927042.019\n    AustriaEurope199777.510806987629095.921\n    AustriaEurope200278.980814831232417.608\n    AustriaEurope200779.829819978336126.493\n\n\n\n\nfilter() takes logical expressions and returns the rows for which all are TRUE.\n\n# task: select rows with lifeExp less than 31\nfilter(gapminder, lifeExp < 31)\n\n\n\nA tibble: 6 × 6\n\n    countrycontinentyearlifeExppopgdpPercap\n    <fct><fct><int><dbl><int><dbl>\n\n\n    Afghanistan Asia  195228.8018425333 779.4453\n    Afghanistan Asia  195730.3329240934 820.8530\n    Angola      Africa195230.01542320953520.6103\n    Gambia      Africa195230.000 284320 485.2307\n    Rwanda      Africa199223.5997290203 737.0686\n    Sierra LeoneAfrica195230.3312143249 879.7877\n\n\n\n\n\n# task: select Austria only and year after 1980\nfilter(gapminder, country == \"Austria\", year > 1980)\n\n\n\nA tibble: 6 × 6\n\n    countrycontinentyearlifeExppopgdpPercap\n    <fct><fct><int><dbl><int><dbl>\n\n\n    AustriaEurope198273.180757461321597.08\n    AustriaEurope198774.940757890323687.83\n    AustriaEurope199276.040791496927042.02\n    AustriaEurope199777.510806987629095.92\n    AustriaEurope200278.980814831232417.61\n    AustriaEurope200779.829819978336126.49\n\n\n\n\n\n# task: select Austria and Belgium\nfilter(gapminder, country %in% c(\"Austria\", \"Belgium\"))\n\n\n\nA tibble: 24 × 6\n\n    countrycontinentyearlifeExppopgdpPercap\n    <fct><fct><int><dbl><int><dbl>\n\n\n    AustriaEurope195266.800 6927772 6137.076\n    AustriaEurope195767.480 6965860 8842.598\n    AustriaEurope196269.540 712986410750.721\n    AustriaEurope196770.140 737699812834.602\n    AustriaEurope197270.630 754420116661.626\n    AustriaEurope197772.170 756843019749.422\n    AustriaEurope198273.180 757461321597.084\n    AustriaEurope198774.940 757890323687.826\n    AustriaEurope199276.040 791496927042.019\n    AustriaEurope199777.510 806987629095.921\n    AustriaEurope200278.980 814831232417.608\n    AustriaEurope200779.829 819978336126.493\n    BelgiumEurope195268.000 8730405 8343.105\n    BelgiumEurope195769.240 8989111 9714.961\n    BelgiumEurope196270.250 921840010991.207\n    BelgiumEurope196770.940 955650013149.041\n    BelgiumEurope197271.440 970910016672.144\n    BelgiumEurope197772.800 982180019117.974\n    BelgiumEurope198273.930 985630320979.846\n    BelgiumEurope198775.350 987020022525.563\n    BelgiumEurope199276.4601004562225575.571\n    BelgiumEurope199777.5301019978727561.197\n    BelgiumEurope200278.3201031197030485.884\n    BelgiumEurope200779.4411039222633692.605\n\n\n\n\nLets rewrite initial code and record it to the variable/data.frame:"
  },
  {
    "objectID": "31-r-data-explore.html#pipe-operator",
    "href": "31-r-data-explore.html#pipe-operator",
    "title": "11  Exploring data with dplyr",
    "section": "11.3 Pipe (%>%/|>) operator",
    "text": "11.3 Pipe (%>%/|>) operator\n%>% is pipe operator. The pipe operator takes the thing on the left-hand-side and pipes it into the function call on the right-hand-side – literally, drops it in as the first argument.\nhead() function without pipe and top 4 items:\n\nIn R version before 4.1.0 pipe %>% operator is not a language build-in and you should install magrittr package:\n\n\nPipe opertor in R 4.1+ |>, using this is preferable\n\n\n#install.packages(\"magrittr\") # for pipe %>% operator\nlibrary(magrittr)\n\n\nhead(gapminder, n = 4)\n\n\n\nA tibble: 4 × 6\n\n    countrycontinentyearlifeExppopgdpPercap\n    <fct><fct><int><dbl><int><dbl>\n\n\n    AfghanistanAsia195228.801 8425333779.4453\n    AfghanistanAsia195730.332 9240934820.8530\n    AfghanistanAsia196231.99710267083853.1007\n    AfghanistanAsia196734.02011537966836.1971\n\n\n\n\nhead() function with pipe and top 4 items:\n\ngapminder %>% head(4)\n\n\n\nA tibble: 4 × 6\n\n    countrycontinentyearlifeExppopgdpPercap\n    <fct><fct><int><dbl><int><dbl>\n\n\n    AfghanistanAsia195228.801 8425333779.4453\n    AfghanistanAsia195730.332 9240934820.8530\n    AfghanistanAsia196231.99710267083853.1007\n    AfghanistanAsia196734.02011537966836.1971\n\n\n\n\nOutput is the same. So, let’s rewrire filtering for Austria with pipe:\n\naustria <- gapminder |> filter(country == \"Austria\")\naustria\n\n\n\nA tibble: 12 × 6\n\n    countrycontinentyearlifeExppopgdpPercap\n    <fct><fct><int><dbl><int><dbl>\n\n\n    AustriaEurope195266.8006927772 6137.076\n    AustriaEurope195767.4806965860 8842.598\n    AustriaEurope196269.540712986410750.721\n    AustriaEurope196770.140737699812834.602\n    AustriaEurope197270.630754420116661.626\n    AustriaEurope197772.170756843019749.422\n    AustriaEurope198273.180757461321597.084\n    AustriaEurope198774.940757890323687.826\n    AustriaEurope199276.040791496927042.019\n    AustriaEurope199777.510806987629095.921\n    AustriaEurope200278.980814831232417.608\n    AustriaEurope200779.829819978336126.493\n\n\n\n\n\n# add more conditions in filter\naustria <- gapminder |> filter(country == \"Austria\", year > 2000)\naustria\n\n\n\nA tibble: 2 × 6\n\n    countrycontinentyearlifeExppopgdpPercap\n    <fct><fct><int><dbl><int><dbl>\n\n\n    AustriaEurope200278.980814831232417.61\n    AustriaEurope200779.829819978336126.49"
  },
  {
    "objectID": "31-r-data-explore.html#select-function",
    "href": "31-r-data-explore.html#select-function",
    "title": "11  Exploring data with dplyr",
    "section": "11.4 select() function",
    "text": "11.4 select() function\nUse select() to subset the data on variables/columns by names or index. You also can define order of columns with select().\n\ngapminder |> \nselect(year, country, pop) |>\nslice(1: 10)\n\n\n\nA tibble: 10 × 3\n\n    yearcountrypop\n    <int><fct><int>\n\n\n    1952Afghanistan 8425333\n    1957Afghanistan 9240934\n    1962Afghanistan10267083\n    1967Afghanistan11537966\n    1972Afghanistan13079460\n    1977Afghanistan14880372\n    1982Afghanistan12881816\n    1987Afghanistan13867957\n    1992Afghanistan16317921\n    1997Afghanistan22227415\n\n\n\n\nLets combine few functions with pipe (%>%):\nFinally, lest extend our filtering:\n\n# compare dplyr syntax with base R call\ngapminder[gapminder$country == \"Austria\", c(\"year\", \"pop\", \"lifeExp\")]\n\ngapminder |> \n    filter(country == \"Austria\") |>\n    select(year, pop, lifeExp)\n\n\n\nA tibble: 12 × 3\n\n    yearpoplifeExp\n    <int><int><dbl>\n\n\n    1952692777266.800\n    1957696586067.480\n    1962712986469.540\n    1967737699870.140\n    1972754420170.630\n    1977756843072.170\n    1982757461373.180\n    1987757890374.940\n    1992791496976.040\n    1997806987677.510\n    2002814831278.980\n    2007819978379.829\n\n\n\n\n\n\nA tibble: 12 × 3\n\n    yearpoplifeExp\n    <int><int><dbl>\n\n\n    1952692777266.800\n    1957696586067.480\n    1962712986469.540\n    1967737699870.140\n    1972754420170.630\n    1977756843072.170\n    1982757461373.180\n    1987757890374.940\n    1992791496976.040\n    1997806987677.510\n    2002814831278.980\n    2007819978379.829\n\n\n\n\nYou can remove some columns using minus(operator) and add few filter conditions:\n\naustria <- gapminder |> \n                filter(country == \"Austria\", year > 2000) |>\n                select(-continent, -gdpPercap) |>\n                head()\naustria\n\n\n\nA tibble: 2 × 4\n\n    countryyearlifeExppop\n    <fct><int><dbl><int>\n\n\n    Austria200278.9808148312\n    Austria200779.8298199783\n\n\n\n\nYou can insert different conditions about columns you need to select.\n\ngapminder |>\n    select(!where(is.numeric)) |>  # its 1704 records, because of repeating some records\n    slice(1:5)\n\n\n\nA tibble: 5 × 2\n\n    countrycontinent\n    <fct><fct>\n\n\n    AfghanistanAsia\n    AfghanistanAsia\n    AfghanistanAsia\n    AfghanistanAsia\n    AfghanistanAsia\n\n\n\n\nLet’s output all unique pairs continent -> country with distinct() function:\n\ngapminder |>\n    select(country) |>\n    distinct() # its 142 records now\n\n\n\nA tibble: 142 × 1\n\n    country\n    <fct>\n\n\n    Afghanistan             \n    Albania                 \n    Algeria                 \n    Angola                  \n    Argentina               \n    Australia               \n    Austria                 \n    Bahrain                 \n    Bangladesh              \n    Belgium                 \n    Benin                   \n    Bolivia                 \n    Bosnia and Herzegovina  \n    Botswana                \n    Brazil                  \n    Bulgaria                \n    Burkina Faso            \n    Burundi                 \n    Cambodia                \n    Cameroon                \n    Canada                  \n    Central African Republic\n    Chad                    \n    Chile                   \n    China                   \n    Colombia                \n    Comoros                 \n    Congo, Dem. Rep.        \n    Congo, Rep.             \n    Costa Rica              \n    ⋮\n    Sierra Leone       \n    Singapore          \n    Slovak Republic    \n    Slovenia           \n    Somalia            \n    South Africa       \n    Spain              \n    Sri Lanka          \n    Sudan              \n    Swaziland          \n    Sweden             \n    Switzerland        \n    Syria              \n    Taiwan             \n    Tanzania           \n    Thailand           \n    Togo               \n    Trinidad and Tobago\n    Tunisia            \n    Turkey             \n    Uganda             \n    United Kingdom     \n    United States      \n    Uruguay            \n    Venezuela          \n    Vietnam            \n    West Bank and Gaza \n    Yemen, Rep.        \n    Zambia             \n    Zimbabwe"
  },
  {
    "objectID": "31-r-data-explore.html#selecting-random-n-rows",
    "href": "31-r-data-explore.html#selecting-random-n-rows",
    "title": "11  Exploring data with dplyr",
    "section": "11.5 Selecting random \\(N\\) rows",
    "text": "11.5 Selecting random \\(N\\) rows\nThe sample_n() function selects random rows from a data frame\n\ngapminder |> sample_n(5)\n\n\n\nA tibble: 5 × 6\n\n    countrycontinentyearlifeExppopgdpPercap\n    <fct><fct><int><dbl><int><dbl>\n\n\n    Norway                  Europe  196774.080378601916361.8765\n    Central African RepublicAfrica  200243.3084048013  738.6906\n    Uruguay                 Americas200776.384344749610611.4630\n    Togo                    Africa  199758.3904320890  982.2869\n    Paraguay                Americas200270.7555884491 3783.6742\n\n\n\n\nIf you want make pseudo-random generation reprodusable use set.seed(). Seed is start point of random generation. Different seeds give different output.\n\nset.seed(2023) # example, seed = 2023\n\nThe sample_frac() function selects random fraction rows from a data frame. Let’s select \\(1\\%\\) of data\n\nset.seed(2023) # output not changing, uncomment it \ngapminder %>% sample_frac(0.1)\n\n\n\nA tibble: 170 × 6\n\n    countrycontinentyearlifeExppopgdpPercap\n    <fct><fct><int><dbl><int><dbl>\n\n\n    Switzerland          Europe  200781.701 7554661 37506.4191\n    Djibouti             Africa  200253.373  447416  1908.2609\n    Slovenia             Europe  197269.820 1694510 12383.4862\n    Sao Tome and PrincipeAfrica  199763.306  145608  1339.0760\n    Turkey               Europe  198763.10852881328  5089.0437\n    Lebanon              Asia    195759.489 1647412  6089.7869\n    Eritrea              Africa  197244.142 2260187   514.3242\n    Philippines          Asia    197258.06540850141  1989.3741\n    Tunisia              Africa  197255.602 5303507  2753.2860\n    Uganda               Africa  195239.978 5824797   734.7535\n    Oman                 Asia    197252.143  829050 10618.0385\n    Australia            Oceania 200781.23520434176 34435.3674\n    Mali                 Africa  200251.81810580176   951.4098\n    Equatorial Guinea    Africa  195735.983  232922   426.0964\n    South Africa         Africa  198258.16131140029  8568.2662\n    Burundi              Africa  196242.045 2961915   355.2032\n    Angola               Africa  199240.647 8735988  2627.8457\n    Yemen, Rep.          Asia    195232.548 4963829   781.7176\n    Croatia              Europe  200775.748 4493312 14619.2227\n    Oman                 Asia    199271.197 1915208 18616.7069\n    Thailand             Asia    196256.06129263397  1002.1992\n    Comoros              Africa  195240.715  153936  1102.9909\n    Eritrea              Africa  195738.047 1542611   344.1619\n    Zambia               Africa  200239.19310595811  1071.6139\n    Cote d'Ivoire        Africa  198754.65510761098  2156.9561\n    South Africa         Africa  195747.98516151549  5487.1042\n    Paraguay             Americas195763.196 1770902  2046.1547\n    Kuwait               Asia    195255.565  160000108382.3529\n    Brazil               Americas195250.91756602560  2108.9444\n    Canada               Americas195769.96017010154 12489.9501\n    ⋮⋮⋮⋮⋮⋮\n    Swaziland            Africa  199754.289 1054486 3876.7685\n    Myanmar              Asia    200259.90845598081  611.0000\n    Sao Tome and PrincipeAfrica  198761.728  110812 1516.5255\n    Ghana                Africa  197751.75610538093  993.2240\n    Guinea-Bissau        Africa  199744.873 1193708  796.6645\n    Guinea               Africa  199248.576 6990574  794.3484\n    Haiti                Americas195740.696 3507701 1726.8879\n    Sao Tome and PrincipeAfrica  200765.528  199579 1598.4351\n    Comoros              Africa  199760.660  527982 1173.6182\n    Equatorial Guinea    Africa  197240.516  277603  672.4123\n    Oman                 Asia    198262.728 130104812954.7910\n    Namibia              Africa  197756.437  977026 3876.4860\n    Congo, Dem. Rep.     Africa  195239.14314100005  780.5423\n    Hong Kong, China     Asia    197773.600 458370011186.1413\n    Bolivia              Americas199762.050 7693188 3326.1432\n    Panama               Americas200274.712 2990875 7356.0319\n    Nigeria              Africa  195236.32433119096 1077.2819\n    Malaysia             Asia    200774.2412482128612451.6558\n    Japan                Asia    195263.03086459025 3216.9563\n    Albania              Europe  196766.220 1984060 2760.1969\n    Portugal             Europe  199775.9701015641517641.0316\n    Uruguay              Americas195266.071 2252965 5716.7667\n    Afghanistan          Asia    197236.08813079460  739.9811\n    Syria                Asia    198766.97411242847 3116.7743\n    Libya                Africa  200272.737 5368585 9534.6775\n    Mauritania           Africa  196244.248 1146757 1055.8960\n    Trinidad and Tobago  Americas199269.862 1183669 7370.9909\n    Netherlands          Europe  196273.2301180568912790.8496\n    Reunion              Africa  200776.442  798094 7670.1226\n    Honduras             Americas195744.665 1770390 2220.4877"
  },
  {
    "objectID": "31-r-data-explore.html#refences",
    "href": "31-r-data-explore.html#refences",
    "title": "11  Exploring data with dplyr",
    "section": "11.6 Refences",
    "text": "11.6 Refences\n\ndplyr: A Grammar of Data Manipulation on https://cran.r-project.org/.\nData Transformation with splyr::cheat sheet.\nDPLYR TUTORIAL : DATA MANIPULATION (50 EXAMPLES) by Deepanshu Bhalla.\nDplyr Intro by Stat 545. 6.R Dplyr Tutorial: Data Manipulation(Join) & Cleaning(Spread). Introduction to Data Analysis\nLoan Default Prediction. Beginners data set for financial analytics Kaggle"
  },
  {
    "objectID": "32-r-data-slice.html",
    "href": "32-r-data-slice.html",
    "title": "12  Subset rows with slice()",
    "section": "",
    "text": "author: Юрій Клебан\nBefore start load packages\nDescription\nIf .data is a grouped_df, the operation will be performed on each group, so that (e.g.) slice_head(df, n = 5) will select the first five rows in each group.\nSamples\nYou can drop some recods with negative indexes:"
  },
  {
    "objectID": "32-r-data-slice.html#refences",
    "href": "32-r-data-slice.html#refences",
    "title": "12  Subset rows with slice()",
    "section": "12.1 Refences",
    "text": "12.1 Refences\n\ndplyr: A Grammar of Data Manipulation on https://cran.r-project.org/.\nData Transformation with splyr::cheat sheet.\nDPLYR TUTORIAL : DATA MANIPULATION (50 EXAMPLES) by Deepanshu Bhalla.\nDplyr Intro by Stat 545. 6.R Dplyr Tutorial: Data Manipulation(Join) & Cleaning(Spread). Introduction to Data Analysis\nLoan Default Prediction. Beginners data set for financial analytics Kaggle"
  },
  {
    "objectID": "33-r-data-sorting.html",
    "href": "33-r-data-sorting.html",
    "title": "13  Sorting with arrange()",
    "section": "",
    "text": "author: Юрій Клебан\nBefore start load packages\narrange(.data, …) function order rows by values of a column or columns (low to high)You can use with desc() to order from high to low.\nFor example, we need to select top 10 countries in 2002 by lifeExp variable."
  },
  {
    "objectID": "33-r-data-sorting.html#refences",
    "href": "33-r-data-sorting.html#refences",
    "title": "13  Sorting with arrange()",
    "section": "13.1 Refences",
    "text": "13.1 Refences\n\ndplyr: A Grammar of Data Manipulation on https://cran.r-project.org/.\nData Transformation with splyr::cheat sheet.\nDPLYR TUTORIAL : DATA MANIPULATION (50 EXAMPLES) by Deepanshu Bhalla.\nDplyr Intro by Stat 545. 6.R Dplyr Tutorial: Data Manipulation(Join) & Cleaning(Spread). Introduction to Data Analysis\nLoan Default Prediction. Beginners data set for financial analytics Kaggle"
  },
  {
    "objectID": "34-r-data-mutating.html",
    "href": "34-r-data-mutating.html",
    "title": "14  Create new variables with mutate()",
    "section": "",
    "text": "author: Юрій Клебан\nBefore start load packages\nmutate(.data, …) compute new column(s). Lets compute new column for gapminder\n\\(gdpTotal = gdpPercap * pop / 1000000\\).\ntransmute(.data, …) compute new column(s), drop others.\nYou can mutate many columns at once:\nYou also can edit existing column (let’s change continent Europe to EU in dataframe):"
  },
  {
    "objectID": "34-r-data-mutating.html#refences",
    "href": "34-r-data-mutating.html#refences",
    "title": "14  Create new variables with mutate()",
    "section": "14.1 Refences",
    "text": "14.1 Refences\n\ndplyr: A Grammar of Data Manipulation on https://cran.r-project.org/.\nData Transformation with splyr::cheat sheet.\nDPLYR TUTORIAL : DATA MANIPULATION (50 EXAMPLES) by Deepanshu Bhalla.\nDplyr Intro by Stat 545. 6.R Dplyr Tutorial: Data Manipulation(Join) & Cleaning(Spread). Introduction to Data Analysis\nLoan Default Prediction. Beginners data set for financial analytics Kaggle"
  },
  {
    "objectID": "35-r-data-rename.html",
    "href": "35-r-data-rename.html",
    "title": "15  Renaming columns with rename()",
    "section": "",
    "text": "author: Юрій Клебан\nBefore start load packages\nrename(.data, …) rename columns. Let’s rename column pop to poulation:\nAlso check functions rename_if and rename_at."
  },
  {
    "objectID": "35-r-data-rename.html#refences",
    "href": "35-r-data-rename.html#refences",
    "title": "15  Renaming columns with rename()",
    "section": "15.1 Refences",
    "text": "15.1 Refences\n\ndplyr: A Grammar of Data Manipulation on https://cran.r-project.org/.\nData Transformation with splyr::cheat sheet.\nDPLYR TUTORIAL : DATA MANIPULATION (50 EXAMPLES) by Deepanshu Bhalla.\nDplyr Intro by Stat 545. 6.R Dplyr Tutorial: Data Manipulation(Join) & Cleaning(Spread). Introduction to Data Analysis\nLoan Default Prediction. Beginners data set for financial analytics Kaggle"
  },
  {
    "objectID": "36-r-data-grouping.html",
    "href": "36-r-data-grouping.html",
    "title": "16  Grouping columns with dplyr",
    "section": "",
    "text": "author: Юрій Клебан\nBefore start load packages"
  },
  {
    "objectID": "36-r-data-grouping.html#group_by-summarise",
    "href": "36-r-data-grouping.html#group_by-summarise",
    "title": "16  Grouping columns with dplyr",
    "section": "16.1 group_by() + summarise()",
    "text": "16.1 group_by() + summarise()\ngroup_by(.data, ..., add = FALSE) returns copy of table grouped by defined columns.\nLet’s find average by lifeExp for each continent in 2002 (ouput is continent, lifeExpAvg2002, countriesCount, year = 2002):\n\ngapminder |>\n    filter(year == 2002) |> # year\n    group_by(continent) |> # grouping condition, you ca\n    summarise(\n        lifeExpAvg2002 = mean(lifeExp),\n        countriesCount = n() # n() count of rows in group  \n        ) \n\n\n\nA tibble: 5 × 3\n\n    continentlifeExpAvg2002countriesCount\n    <fct><dbl><int>\n\n\n    Africa  53.3252352\n    Americas72.4220425\n    Asia    69.2338833\n    Europe  76.7006030\n    Oceania 79.74000 2\n\n\n\n\nLet’s find total population for each continent in 2002 (ouput is continent, totalPop, year):\n\ngapminder |>\n    filter(year == 2002) |> # year\n    group_by(continent, year) |> # grouping condition\n    summarise(totalPop = sum(pop), .groups = \"keep\") \n\n\n\nA grouped_df: 5 × 3\n\n    continentyeartotalPop\n    <fct><int><dbl>\n\n\n    Africa  2002 833723916\n    Americas2002 849772762\n    Asia    20023601802203\n    Europe  2002 578223869\n    Oceania 2002  23454829\n\n\n\n\nThere are additional variations of summarise():\n\nsummarise_all() - Apply funs to every column.\nsummarise_at() - Apply funs to specific columns.\n\nsummarise_if() - Apply funs to all cols of one type.\n\n\n\n16.1.1 Task on Credits (rewrite it)\n\nlibrary(ISLR)\n\ngroup_inc <- aggregate(Income ~ Age + Gender, data = Credit, mean)\n\nm_data <- group_inc[group_inc$Gender == \" Male\", ]\nnrow(m_data)\n\nf_data <- group_inc[group_inc$Gender == \"Female\", ]\nnrow(f_data)\nwith(m_data, plot(Age, Income, type = \"l\", col=\"red\"))\nwith(f_data, lines(Age, Income, type = \"l\", col =\"blue\"))\n\n63\n\n\n62\n\n\n\n\n\n\ncd <- Credit %>%\nselect(Income, Age, Gender) %>%\ngroup_by(Age, Gender) %>%\nsummarize(Income = mean(Income))\n\nm_data <- cd %>% filter(Gender == \" Male\")\nnrow(m_data)\n\nf_data <- cd %>% filter(Gender == \"Female\")\nnrow(f_data)\n\nwith(m_data, plot(Age, Income, type = \"l\", col=\"red\"))\nwith(f_data, lines(Age, Income, type = \"l\", col =\"blue\"))\n\n`summarise()` has grouped output by 'Age'. You can override using the `.groups`\nargument.\n\n\n63\n\n\n62"
  },
  {
    "objectID": "36-r-data-grouping.html#refences",
    "href": "36-r-data-grouping.html#refences",
    "title": "16  Grouping columns with dplyr",
    "section": "16.2 Refences",
    "text": "16.2 Refences\n\ndplyr: A Grammar of Data Manipulation on https://cran.r-project.org/.\nData Transformation with splyr::cheat sheet.\nDPLYR TUTORIAL : DATA MANIPULATION (50 EXAMPLES) by Deepanshu Bhalla.\nDplyr Intro by Stat 545. 6.R Dplyr Tutorial: Data Manipulation(Join) & Cleaning(Spread). Introduction to Data Analysis\nLoan Default Prediction. Beginners data set for financial analytics Kaggle"
  },
  {
    "objectID": "37-r-data-bind.html",
    "href": "37-r-data-bind.html",
    "title": "17  Binding rows and columns",
    "section": "",
    "text": "author: Юрій Клебан\nBefore start load packages"
  },
  {
    "objectID": "37-r-data-bind.html#bind_rows",
    "href": "37-r-data-bind.html#bind_rows",
    "title": "17  Binding rows and columns",
    "section": "17.1 bind_rows",
    "text": "17.1 bind_rows\nbind_rows(.data, …) helps to unite two dataframes with the same columns order and names.\nSo, if we need add one data frame to an other vertically (bind rows) we shoul use bind_rows:\n\nd2002 <- gapminder %>%\n            filter(year == 2002) %>% # year\n            group_by(continent, year) %>% # grouping condition\n            summarise(\n                lifeExpAvg = mean(lifeExp),\n                countriesCount = n(), # n() count of rows in group \n                .groups = 'drop'\n            )\nhead(d2002)\n\n\n\nA tibble: 5 × 4\n\n    continentyearlifeExpAvgcountriesCount\n    <fct><int><dbl><int>\n\n\n    Africa  200253.3252352\n    Americas200272.4220425\n    Asia    200269.2338833\n    Europe  200276.7006030\n    Oceania 200279.74000 2\n\n\n\n\n\nd2007 <- gapminder %>%\n            filter(year == 2007) %>% # year\n            group_by(continent, year) %>% # grouping condition\n            summarise(\n                lifeExpAvg = mean(lifeExp),\n                countriesCount = n() # n() count of rows in group                \n            )\nhead(d2007)\n\n`summarise()` has grouped output by 'continent'. You can override using the `.groups` argument.\n\n\n\n\nA grouped_df: 5 × 4\n\n    continentyearlifeExpAvgcountriesCount\n    <fct><int><dbl><int>\n\n\n    Africa  200754.8060452\n    Americas200773.6081225\n    Asia    200770.7284833\n    Europe  200777.6486030\n    Oceania 200780.71950 2\n\n\n\n\nUnite them:\n\nd2002 %>% bind_rows(d2007) ## bind rows\n\n\n\nA tibble: 10 × 4\n\n    continentyearlifeExpAvgcountriesCount\n    <fct><int><dbl><int>\n\n\n    Africa  200253.3252352\n    Americas200272.4220425\n    Asia    200269.2338833\n    Europe  200276.7006030\n    Oceania 200279.74000 2\n    Africa  200754.8060452\n    Americas200773.6081225\n    Asia    200770.7284833\n    Europe  200777.6486030\n    Oceania 200780.71950 2"
  },
  {
    "objectID": "37-r-data-bind.html#bind_cols",
    "href": "37-r-data-bind.html#bind_cols",
    "title": "17  Binding rows and columns",
    "section": "17.2 bind_cols",
    "text": "17.2 bind_cols\nbind_cols(.data, …) helps to unite two dataframes with the same rows count.\n\ngrouped_data2002pop <- gapminder %>%\n    filter(year == 2002) %>% # year\n    group_by(continent) %>% # grouping condition\n    summarise(totalPop = sum(pop)) %>%\n    mutate(year = 2002)\ngrouped_data2002pop\n\n\n\nA tibble: 5 × 3\n\n    continenttotalPopyear\n    <fct><dbl><dbl>\n\n\n    Africa   8337239162002\n    Americas 8497727622002\n    Asia    36018022032002\n    Europe   5782238692002\n    Oceania   234548292002\n\n\n\n\nLet’s combine d2002 and grouped_data2002pop:\n\ngrouped_data <- d2002 %>% \n    bind_cols(grouped_data2002pop)\ngrouped_data\n\n# columns with the same name were renamed!\n\nNew names:\n* `continent` -> `continent...1`\n* `year` -> `year...2`\n* `continent` -> `continent...5`\n* `year` -> `year...7`\n\n\n\n\nA tibble: 5 × 7\n\n    continent...1year...2lifeExpAvgcountriesCountcontinent...5totalPopyear...7\n    <fct><int><dbl><int><fct><dbl><dbl>\n\n\n    Africa  200253.3252352Africa   8337239162002\n    Americas200272.4220425Americas 8497727622002\n    Asia    200269.2338833Asia    36018022032002\n    Europe  200276.7006030Europe   5782238692002\n    Oceania 200279.74000 2Oceania   234548292002\n\n\n\n\nYou can remove same named variables before binding:\n\ngrouped_data <- d2002 %>% \n    bind_cols(grouped_data2002pop %>%\n              select(-continent, -year))\ngrouped_data\n\n# better, but continents order is not the same in both frames \n# your data is going to be damaged\n\n\n\nA tibble: 5 × 5\n\n    continentyearlifeExpAvgcountriesCounttotalPop\n    <fct><int><dbl><int><dbl>\n\n\n    Africa  200253.3252352 833723916\n    Americas200272.4220425 849772762\n    Asia    200269.23388333601802203\n    Europe  200276.7006030 578223869\n    Oceania 200279.74000 2  23454829\n\n\n\n\n\ngrouped_data2002pop <- grouped_data2002pop %>% \n    arrange(totalPop)\n\ngrouped_data <- d2002 %>% \n    bind_cols(grouped_data2002pop)\ngrouped_data\n\n# you can see that continent fields different in the same row\n\nNew names:\n* `continent` -> `continent...1`\n* `year` -> `year...2`\n* `continent` -> `continent...5`\n* `year` -> `year...7`\n\n\n\n\nA tibble: 5 × 7\n\n    continent...1year...2lifeExpAvgcountriesCountcontinent...5totalPopyear...7\n    <fct><int><dbl><int><fct><dbl><dbl>\n\n\n    Africa  200253.3252352Oceania   234548292002\n    Americas200272.4220425Europe   5782238692002\n    Asia    200269.2338833Africa   8337239162002\n    Europe  200276.7006030Americas 8497727622002\n    Oceania 200279.74000 2Asia    36018022032002\n\n\n\n\nHow to solve this? Join functions issolution."
  },
  {
    "objectID": "37-r-data-bind.html#refences",
    "href": "37-r-data-bind.html#refences",
    "title": "17  Binding rows and columns",
    "section": "17.3 Refences",
    "text": "17.3 Refences\n\ndplyr: A Grammar of Data Manipulation on https://cran.r-project.org/.\nData Transformation with splyr::cheat sheet.\nDPLYR TUTORIAL : DATA MANIPULATION (50 EXAMPLES) by Deepanshu Bhalla.\nDplyr Intro by Stat 545. 6.R Dplyr Tutorial: Data Manipulation(Join) & Cleaning(Spread). Introduction to Data Analysis\nLoan Default Prediction. Beginners data set for financial analytics Kaggle"
  },
  {
    "objectID": "38-r-data-join.html",
    "href": "38-r-data-join.html",
    "title": "18  Join()-ing data",
    "section": "",
    "text": "author: Юрій Клебан\nBefore start load packages"
  },
  {
    "objectID": "38-r-data-join.html#join-types",
    "href": "38-r-data-join.html#join-types",
    "title": "18  Join()-ing data",
    "section": "18.1 Join types",
    "text": "18.1 Join types\nLets check join operations as set opretations\n\nJoins on table are look like this:\n\n\n\n\n\nSource: https://marcus116.blogspot.com/2019/07/cheatsheets-sql-join-cheat-sheets.html"
  },
  {
    "objectID": "38-r-data-join.html#join-functions",
    "href": "38-r-data-join.html#join-functions",
    "title": "18  Join()-ing data",
    "section": "18.2 Join functions",
    "text": "18.2 Join functions\nTo solve previous problem you can use set of join()-functions. left_join() can solve our previous example:\n\nd2002 <- gapminder %>%\n            filter(year == 2002) %>% # year\n            group_by(continent, year) %>% # grouping condition\n            summarise(\n                lifeExpAvg = mean(lifeExp),\n                countriesCount = n(), # n() count of rows in group \n                .groups = 'drop'\n            )\nd2002 |> head()\n\n\n\nA tibble: 5 × 4\n\n    continentyearlifeExpAvgcountriesCount\n    <fct><int><dbl><int>\n\n\n    Africa  200253.3252352\n    Americas200272.4220425\n    Asia    200269.2338833\n    Europe  200276.7006030\n    Oceania 200279.74000 2\n\n\n\n\n\ngrouped_data2002pop <- gapminder %>%\n    filter(year == 2002) %>% # year\n    group_by(continent) %>% # grouping condition\n    summarise(totalPop = sum(pop),\n             year = min(year))\n\ngrouped_data2002pop |> head()\n\n\n\nA tibble: 5 × 3\n\n    continenttotalPopyear\n    <fct><dbl><int>\n\n\n    Africa   8337239162002\n    Americas 8497727622002\n    Asia    36018022032002\n    Europe   5782238692002\n    Oceania   234548292002\n\n\n\n\n\ngrouped_data2002pop <- grouped_data2002pop %>% \n    arrange(totalPop)\n\ngrouped_data <- d2002 %>% \n    left_join(grouped_data2002pop, by = \"continent\")\ngrouped_data\n\n# but we have duplicated year\n\n\n\nA tibble: 5 × 6\n\n    continentyear.xlifeExpAvgcountriesCounttotalPopyear.y\n    <fct><int><dbl><int><dbl><int>\n\n\n    Africa  200253.3252352 8337239162002\n    Americas200272.4220425 8497727622002\n    Asia    200269.233883336018022032002\n    Europe  200276.7006030 5782238692002\n    Oceania 200279.74000 2  234548292002\n\n\n\n\n\ngrouped_data2002pop <- grouped_data2002pop %>% \n    arrange(totalPop)\n\ngrouped_data <- d2002 %>% \n    left_join(grouped_data2002pop, by = c(\"continent\", \"year\"))\ngrouped_data\n\n#ok\n\n\n\nA tibble: 5 × 5\n\n    continentyearlifeExpAvgcountriesCounttotalPop\n    <fct><int><dbl><int><dbl>\n\n\n    Africa  200253.3252352 833723916\n    Americas200272.4220425 849772762\n    Asia    200269.23388333601802203\n    Europe  200276.7006030 578223869\n    Oceania 200279.74000 2  23454829\n\n\n\n\nLet’s make a different data sets for testing join() fucntions:\n\nfirst_df <- data.frame(Letter = c(\"A\", \"B\", \"C\", \"D\", \"E\"),\n                      Value = c(1:5))\n\nsecond_df <- data.frame(Letter = c(\"A\", \"B\", \"C\", \"D\", \"F\"),\n                      Value = c(12, 7, 4, 1, 5))\nfirst_df\nsecond_df \n\n\n\nA data.frame: 5 × 2\n\n    LetterValue\n    <chr><int>\n\n\n    A1\n    B2\n    C3\n    D4\n    E5\n\n\n\n\n\n\nA data.frame: 5 × 2\n\n    LetterValue\n    <chr><dbl>\n\n\n    A12\n    B 7\n    C 4\n    D 1\n    F 5\n\n\n\n\nYou can see that the last row Letter is different in dataframes. left_join() test is next.\n\nfirst_df %>% \n    left_join(second_df, by = \"Letter\")\n# there is no F letter, becouse first_db joined only known first_df Letters.\n\n\n\nA data.frame: 5 × 3\n\n    LetterValue.xValue.y\n    <chr><int><dbl>\n\n\n    A112\n    B2 7\n    C3 4\n    D4 1\n    E5NA\n\n\n\n\n\nfirst_df %>% \n    right_join(second_df, by = \"Letter\")\n# right_join! there is no E letter, becouse first_db joined only known second_df Letters.\n\n\n\nA data.frame: 5 × 3\n\n    LetterValue.xValue.y\n    <chr><int><dbl>\n\n\n    A 112\n    B 2 7\n    C 3 4\n    D 4 1\n    FNA 5\n\n\n\n\n\nfirst_df %>% \n    inner_join(second_df, by = \"Letter\")\n# inner_join! there is no E and F Letters, \n# only known both first_df and second_df are left here.\n\n\n\nA data.frame: 4 × 3\n\n    LetterValue.xValue.y\n    <chr><int><dbl>\n\n\n    A112\n    B2 7\n    C3 4\n    D4 1\n\n\n\n\n\nfirst_df %>% \n    full_join(second_df, by = \"Letter\")\n# all are here, but unknown values replaced by NA, it's ok.\n\n\n\nA data.frame: 6 × 3\n\n    LetterValue.xValue.y\n    <chr><int><dbl>\n\n\n    A 112\n    B 2 7\n    C 3 4\n    D 4 1\n    E 5NA\n    FNA 5\n\n\n\n\nShort description of reviewed functions:\n\n\n\n\n\n\n\n\n\nFunction\nObjectives\nArguments\nMultiple keys\n\n\n\n\nleft_join()\nMerge two datasets. Keep all observations from the origin table\ndata, origin, destination, by = “ID”\norigin, destination, by = c(“ID”, “ID2”)\n\n\nright_join()\nMerge two datasets. Keep all observations from the destination table\ndata, origin, destination, by = “ID”\norigin, destination, by = c(“ID”, “ID2”)\n\n\ninner_join()\nMerge two datasets. Excludes all unmatched rows\ndata, origin, destination, by = “ID”\norigin, destination, by = c(“ID”, “ID2”)\n\n\nfull_join()\nMerge two datasets. Keeps all observations\ndata, origin, destination, by = “ID”\norigin, destination, by = c(“ID”, “ID2”)"
  },
  {
    "objectID": "38-r-data-join.html#refences",
    "href": "38-r-data-join.html#refences",
    "title": "18  Join()-ing data",
    "section": "18.3 Refences",
    "text": "18.3 Refences\n\ndplyr: A Grammar of Data Manipulation on https://cran.r-project.org/.\nData Transformation with splyr::cheat sheet.\nDPLYR TUTORIAL : DATA MANIPULATION (50 EXAMPLES) by Deepanshu Bhalla.\nDplyr Intro by Stat 545. 6.R Dplyr Tutorial: Data Manipulation(Join) & Cleaning(Spread). Introduction to Data Analysis\nLoan Default Prediction. Beginners data set for financial analytics Kaggle"
  },
  {
    "objectID": "39-r-wide-to-long.html",
    "href": "39-r-wide-to-long.html",
    "title": "19  Wide-to-long tables",
    "section": "",
    "text": "author: Юрій Клебан\nBefore start load packages\nSome times your data is not in tidy format. Peole can collect data year by year in each column. It’s problem to use such data for feature engeniering and building prediction models. Let’s generate such data sample (quaterly salary of some people).\nTo make our data tidier separate() can split quater column into 2 (quater and year):\nThe unite() function concanates two columns into one:\nIf you need to make table like initial use spread() function:\nLet’s try to spread() feild pop of gapminder by year:\nFunctions table:"
  },
  {
    "objectID": "39-r-wide-to-long.html#refences",
    "href": "39-r-wide-to-long.html#refences",
    "title": "19  Wide-to-long tables",
    "section": "19.1 Refences",
    "text": "19.1 Refences\n\ndplyr: A Grammar of Data Manipulation on https://cran.r-project.org/.\nData Transformation with splyr::cheat sheet.\nDPLYR TUTORIAL : DATA MANIPULATION (50 EXAMPLES) by Deepanshu Bhalla.\nDplyr Intro by Stat 545. 6.R Dplyr Tutorial: Data Manipulation(Join) & Cleaning(Spread). Introduction to Data Analysis\nLoan Default Prediction. Beginners data set for financial analytics Kaggle"
  }
]